# 오답노트
You are managing a retail inventory system where products are stored in a MongoDB collection called inventory. Each product document has fields _id, item, quantity, and price. You need to increase the quantity of a product if it exists or insert a new product with a specific quantity and price if it does not exist. The product is identified by the item field. Which of the following updateOne commands should you use to accomplish this?
---
db.inventory.updateOne(
  { item: "notebook" },
  { $inc: { quantity: 10 }, $setOnInsert: { price: 5.99 } },
  { upsert: true }
)

setOnInsert -> set the price only when a new document is inserted.
upsert


MongoDB insertMany 명령어 오답노트
1. 문제
다음 중 비어있는 companies 컬렉션에 정확히 두 개의 새 문서를 성공적으로 삽입하는 MongoDB 명령어는 무엇입니까?

명령어 예시:

db.companies.insertMany([
    {"_id": 1, "name": "Facebook"},
    {"_id": 2, "name": "Twitter"},
    {"_id": 2, "name": "Tesla"}
])

출제자 의도
insertMany 명령어의 기본 동작(ordered: true)과 오류 발생 시 이전 작업은 롤백되지 않는다는 점을 이해하고 있는지 평가합니다.

2. 나의 오답 예상 (잘못된 생각)
"_id 필드는 고유(unique)해야 하는 기본 키(Primary Key)이므로, 배열 안에 _id 값이 2로 중복되는 문서가 포함되어 있으면 오류가 발생할 것이다. 따라서 insertMany 명령어 전체가 실패하고 아무 문서도 삽입되지 않을 것이다."

이 생각은 _id의 고유성 제약 조건은 정확히 이해했지만, insertMany 명령어의 동작 방식에 대한 이해가 부족해서 발생한 오해입니다.

3. 정답 및 상세 해설
정답: 위 명령어는 정확히 두 개의 문서를 삽입합니다.

해설:
db.collection.insertMany() 명령어는 기본적으로 순서가 있는(ordered) 방식으로 동작합니다. 이는 명령어에 전달된 배열의 문서들을 순서대로 하나씩 삽입을 시도한다는 의미입니다.

동작 과정은 다음과 같습니다.

첫 번째 문서 삽입 시도: {"_id": 1, "name": "Facebook"}

_id가 1인 문서가 없으므로 성공적으로 삽입됩니다.

두 번째 문서 삽입 시도: {"_id": 2, "name": "Twitter"}

_id가 2인 문서가 없으므로 성공적으로 삽입됩니다.

세 번째 문서 삽입 시도: {"_id": 2, "name": "Tesla"}

_id가 2인 문서가 이미 존재하므로 '중복 키 오류(duplicate key error)'가 발생합니다.

insertMany는 기본적으로 ordered: true 옵션을 사용하기 때문에, 오류가 발생하는 즉시 전체 작업을 중단합니다. 하지만 중요한 점은 오류 발생 이전에 성공적으로 삽입된 문서들은 롤백(취소)되지 않고 그대로 컬렉션에 남는다는 것입니다.

따라서 이 명령어의 최종 결과로 companies 컬렉션에는 첫 번째와 두 번째 문서, 즉 총 2개의 문서만 남게 됩니다.

4. 핵심 개념 정리
insertMany 명령어의 ordered 옵션
insertMany 명령어는 동작 방식을 제어하는 ordered 옵션을 가지고 있습니다.

ordered: true (기본값)

배열의 순서대로 문서를 삽입합니다.

중간에 오류가 발생하면, 그 즉시 작업을 중단합니다.

오류 발생 전까지 삽입된 문서는 그대로 유지됩니다.

ordered: false

배열의 순서와 상관없이 MongoDB가 최적화된 방식으로 모든 문서의 삽입을 시도합니다.

중간에 오류가 발생하더라도 작업을 중단하지 않고, 오류가 없는 다른 모든 문서의 삽입을 계속 시도합니다.

(만약 위 예제를 ordered: false로 실행했더라도, 결과는 동일하게 2개의 문서가 삽입됩니다. 오류가 난 세 번째 문서를 제외한 나머지 문서들의 삽입을 시도하기 때문입니다.)

5. 결론 및 교훈
insertMany 명령어는 기본적으로 순차적으로 실행되며, 오류가 발생하면 그 지점에서 멈춘다. 데이터베이스 트랜잭션처럼 전체 작업이 취소되는 것이 아니라, 오류 발생 직전까지의 성공한 작업은 그대로 유지된다는 점을 반드시 기억해야 합니다.

이 개념을 이해하면 여러 문서를 한 번에 삽입할 때 발생할 수 있는 문제를 정확히 예측하고 해결할 수 있습니다.

6. 추가 개념: Capped Collection 생성하기
문제
latest_news라는 이름의 Capped Collection을 생성하려고 합니다. 이 컬렉션은 최대 3개의 문서와 10,000바이트의 크기 제한을 가져야 합니다. 올바른 명령어는 무엇입니까?

출제자 의도
Capped Collection을 생성하는 db.createCollection 명령어의 기본 문법과 주요 옵션(capped, size, max)을 알고 있는지 평가합니다.

정답 명령어
db.createCollection('latest_news', {'capped': true, 'size': 10000, 'max': 3})

해설
이 명령어는 latest_news라는 이름의 Capped Collection을 생성하는 올바른 방법입니다.

'capped': true: 해당 컬렉션이 고정된 크기를 가지며, 오래된 데이터가 자동으로 삭제되는 FIFO(First-In-First-Out) 방식으로 동작하도록 설정합니다.

'size': 10000: 컬렉션의 최대 크기를 바이트 단위로 지정합니다.

'max': 3: 컬렉션에 저장될 수 있는 최대 문서 수를 지정합니다.

Capped Collection은 이 두 가지 제한 (size와 max) 중 하나라도 먼저 도달하면 가장 오래된 문서를 삭제하고 새 문서를 위한 공간을 확보합니다. 주로 실시간 로그 데이터 저장과 같이 최신 데이터를 유지하는 것이 중요한 경우에 유용하게 사용됩니다.

7. 추가 개념: Aggregation - 전체 평균 vs 그룹별 평균
문제
sales 컬렉션에 아래와 같은 구조의 문서들이 저장되어 있습니다. 이 컬렉션에 있는 모든 상품의 amount 필드의 전체 평균을 계산하는 올바른 Aggregation 쿼리는 무엇입니까?

출제자 의도
$group 스테이지에서 특정 필드로 그룹화(_id: "$field")하는 것과 전체 문서 대상(_id: null)으로 집계하는 것의 차이점을 이해하는지 평가합니다.

예시 데이터:

[
  { "product": "Laptop", "amount": 1200 },
  { "product": "Mouse", "amount": 25 },
  { "product": "Laptop", "amount": 1000 },
  { "product": "Keyboard", "amount": 75 },
  { "product": "Mouse", "amount": 30 }
]

나의 오답
db.sales.aggregate([
  { $group: { _id: "$product", avgAmount: { $avg: "$amount" } } }
])

오답 분석:
이 쿼리는 product 필드를 기준으로 문서를 그룹화합니다. 따라서 "Laptop", "Mouse" 등 각 상품별 amount의 평균을 계산하게 됩니다. 문제에서 요구하는 것은 '모든 상품을 합친 전체 평균'이므로, 이 쿼리는 요구사항과 맞지 않습니다.

쿼리 실행 결과 (오답):

[
  { "_id": "Laptop", "avgAmount": 1100 },
  { "_id": "Mouse", "avgAmount": 27.5 },
  { "_id": "Keyboard", "avgAmount": 75 }
]

정답
db.sales.aggregate([
  { $group: { _id: null, avgAmount: { $avg: "$amount" } } }
])

정답 해설:
이 쿼리가 컬렉션 전체의 평균을 정확하게 계산합니다.

$group: 문서를 특정 기준에 따라 그룹화하는 스테이지입니다.

_id: null: 이 부분이 핵심입니다. $group 스테이지에서 _id 값을 null로 지정하면, 특정 필드를 기준으로 그룹을 나누지 않고 컬렉션의 모든 문서를 하나의 그룹으로 묶어서 집계하라는 의미입니다.

avgAmount: { $avg: "$amount" }: 이렇게 하나의 그룹으로 묶인 모든 문서들의 $amount 필드 값을 가져와 평균($avg)을 계산하고, 그 결과를 avgAmount라는 새로운 필드에 저장합니다.

쿼리 실행 결과 (정답):
(1200 + 25 + 1000 + 75 + 30) / 5 = 466

[
  { "_id": null, "avgAmount": 466 }
]

핵심 개념 정리: $group 스테이지의 _id 필드
$group 스테이지에서 _id 필드는 그룹화의 기준을 정의합니다.

_id: "$field_name": field_name의 고유한 값마다 별도의 그룹을 생성합니다. (예: 상품별, 카테고리별 집계)

_id: null: 모든 문서를 단일 그룹으로 취급하여 전체에 대한 집계를 수행합니다. (예: 전체 합계, 전체 평균)

8. 추가 개념: 쓰기(Write) 성능 최적화
문제
애플리케이션 개발에서 쓰기(write) 성능이 매우 중요합니다. 주로 삽입(insert) 작업이 발생하고 업데이트나 삭제는 거의 없는 시나리오에서, 대용량의 쓰기 작업을 최적화하는 데 가장 적합한 MongoDB 기능은 무엇입니까?

출제자 의도
대규모 데이터 처리 시 수직 확장과 수평 확장(샤딩)의 차이를 이해하고, 쓰기 중심 워크로드에 샤딩이 적합하다는 것을 아는지 평가합니다.

나의 오답
Aggregation Pipeline

오답 분석:
Aggregation Pipeline은 데이터 처리 파이프라인 개념을 모델로 한 데이터 집계 프레임워크입니다. 여러 단계(stage)를 거쳐 데이터를 변환하고 요약하는 등 데이터를 조회하고 분석하는 데 주로 사용됩니다. 쓰기 성능에 직접적인 영향을 주는 기능이 아니므로, 이 문제의 답으로는 적절하지 않습니다.

정답
Sharding (샤딩)

정답 해설:
샤딩은 데이터를 여러 머신(서버)에 분산하여 저장하는 방법입니다. MongoDB는 샤딩을 통해 매우 큰 데이터 세트와 높은 처리량의 작업을 지원합니다.

애플리케이션의 쓰기 요청이 폭주할 경우, 단일 서버는 결국 CPU, RAM, 디스크 I/O 등 하드웨어의 한계에 도달하게 됩니다. 샤딩은 이 문제를 해결하기 위해 데이터를 여러 **샤드(Shard)**라고 불리는 서버 그룹에 분산시킵니다.

이렇게 하면 쓰기 작업 또한 여러 서버로 분산되어 처리됩니다. 즉, 한 서버에 집중되던 쓰기 부하가 여러 서버로 나뉘면서 전체적인 쓰기 처리량이 크게 향상됩니다. 따라서 대용량의 쓰기 작업이 많은(write-heavy) 워크로드에 가장 효과적인 확장 솔루션입니다.

핵심 개념 정리: 수직 확장 vs 수평 확장(샤딩)
수직 확장 (Scaling Up): 단일 서버의 하드웨어 사양(CPU, RAM 등)을 업그레이드하는 방식입니다. 비용이 많이 들고, 결국 물리적인 한계에 부딪힙니다.

수평 확장 (Scaling Out / Sharding): 더 많은 서버를 추가하여 전체 시스템의 용량과 성능을 높이는 방식입니다. 샤딩이 바로 여기에 해당하며, 대규모 시스템을 구축하는 데 훨씬 유연하고 비용 효율적입니다.

9. 추가 개념: 정규식(Regex)을 이용한 텍스트 검색
문제
books 컬렉션에 title 필드가 있습니다. title이 'ian'으로 끝나는 모든 책을 반환하는 쿼리는 무엇입니까?

출제자 의도
정규식(Regex)을 사용하여 텍스트를 검색할 때, 문자열의 끝을 의미하는 앵커($)의 역할을 정확히 이해하고 있는지 평가합니다.

나의 오답
db.books.find( { title: { $regex: /.*ian/ } } )

오답 분석:
이 쿼리는 title 필드에 'ian'이 어디든 포함되기만 하면 문서를 찾아냅니다. 예를 들어, "The Martian", "Guardians of the Galaxy", "Librarian's Choice"와 같은 제목을 모두 반환할 수 있습니다. 문제에서는 'ian'으로 끝나는 경우만 요구했으므로, 이 쿼리는 너무 광범위한 결과를 반환합니다.

정답
db.books.find( { title: { $regex: /.*ian$/ } } )

정답 해설:
이 쿼리는 $regex 연산자와 함께 정규식 패턴을 사용하여 title 필드가 'ian'으로 끝나는 문서를 정확히 찾아냅니다.

 /.*ian$/: 이 정규식 패턴에서 각 부분의 의미는 다음과 같습니다.

.*: .은 어떤 문자든 하나를 의미하고, *는 0번 이상 반복을 의미합니다. 즉, .*는 'ian' 앞에 어떤 문자열이 오든 상관없다는 뜻입니다.

ian: 'ian'이라는 문자열과 정확히 일치해야 합니다.

$: 이 부분이 핵심입니다. $는 문자열의 끝을 의미하는 **앵커(anchor)**입니다. 따라서 'ian'이 반드시 문자열의 맨 끝에 위치해야만 조건에 부합하게 됩니다.

이 쿼리를 사용하면 "The Martian"은 반환하지만, "Guardians of the Galaxy"나 "Librarian's Choice"는 반환하지 않습니다.

핵심 개념 정리: 정규식의 기본 앵커
정규식에서 특정 위치를 지정하는 문자를 '앵커'라고 합니다.

^: 문자열의 시작을 의미합니다. (예: /^The/ -> 'The'로 시작하는 문자열)

$: 문자열의 끝을 의미합니다. (예: /story$/ -> 'story'로 끝나는 문자열)

10. 추가 개념: 데이터 모델링 - 아웃라이어 패턴 (Outlier Pattern)
문제
소셜 미디어 회사에서 사용자 간의 관계를 설명하는 데이터 모델을 구현해야 합니다. 실제 데이터를 시스템에 로드할 때, 한 사용자가 너무 많은 연락처를 가지고 있어 지정된 배열에 모두 저장할 수 없는 문제가 발생했습니다. 전체 시스템을 재설계하는 대신 어떤 패턴을 사용할 수 있습니까?

출제자 의도
일반적인 규칙에서 벗어나는 예외적인 데이터를 효율적으로 처리하기 위한 고급 데이터 모델링 패턴(아웃라이어 패턴)을 알고 있는지 평가합니다.

나의 오답
The Extended Reference Pattern (확장 참조 패턴)

오답 분석:
확장 참조 패턴은 엔티티 간의 관계가 너무 복잡하여 단순한 참조나 외래 키로 표현하기 어려울 때 사용됩니다. 하지만 이 문제의 핵심은 관계의 복잡성이 아니라, 특정 사용자 한 명의 연락처 데이터 양이 너무 많아 배열의 저장 용량을 초과하는 것입니다. 따라서 이 패턴은 가장 적합한 해결책이 아닙니다.

정답
The Outlier Pattern (아웃라이어 패턴)

정답 해설:
이 패턴은 표준 데이터 모델에 맞지 않는 예외적인 경우, 즉 **'아웃라이어(outlier)'**를 처리하는 데 사용됩니다. 문제의 경우처럼, 대부분의 사용자는 연락처를 배열에 저장할 수 있지만, 유독 한 명의 사용자가 비정상적으로 많은 연락처를 가져서 배열에 담을 수 없을 때 아웃라이어 패턴을 적용할 수 있습니다.

이 패턴은 시스템 전체를 바꾸는 대신, 해당 예외적인 사용자에 대해서만 대체 데이터 저장 방식을 사용하는 방식으로 문제를 해결합니다. 예를 들어, 일반 사용자는 기존처럼 user 문서 내의 contacts 배열에 연락처를 저장하고, 아웃라이어 사용자의 경우 user 문서에 플래그(has_extra_contacts: true)를 추가하고, 실제 연락처 목록은 별도의 컬렉션(user_123_contacts)에 저장하는 방식입니다.

이렇게 하면 99%의 일반적인 케이스는 기존 모델을 그대로 유지하면서, 1%의 특수한 케이스만 효율적으로 처리할 수 있어 시스템 전체의 설계를 변경하는 비용을 피할 수 있습니다.

11. 추가 개념: 배열(Array)에서 특정 값 찾기
문제
movies 컬렉션에 다음과 같은 구조의 문서가 있습니다. 이 컬렉션에서 장르(genres)에 'Crime'이 포함된 모든 영화를 추출하는 올바른 쿼리는 무엇입니까? (2개 선택)

출제자 의도
배열 필드에서 특정 요소를 조회하는 다양한 방법(단순 일치, $in, $all)의 차이점과 올바른 사용법을 이해하고 있는지 평가합니다.

문서 구조:

{
    "_id": ObjectId("..."),
    "genres": [ "Comedy", "Drama", "Family" ],
    "title": "The Poor Little Rich Girl",
    "year": 1917,
    ...
}

정답 및 오답 분석
정답 쿼리 1
db.movies.find( { "genres": "Crime" } )

해설:
가장 간단하고 직관적인 방법입니다. MongoDB에서 배열 필드에 대해 단일 값으로 동등 비교(:)를 수행하면, 해당 값이 배열 안에 하나의 요소로서 포함되어 있는 모든 문서를 찾아줍니다.

정답 쿼리 2
db.movies.find( { "genres": { "$in" : ["Crime"] } } )

해설:
$in 연산자는 필드의 값이 지정된 배열 안의 값 중 하나라도 일치하는 문서를 찾습니다. 이 경우는 ["Crime"] 배열에 있는 'Crime'이라는 값 하나만 확인하므로, 위 쿼리와 동일한 결과를 반환합니다. $in은 'Crime' 또는 'Thriller' 장르를 찾고 싶을 때 ["Crime", "Thriller"] 와 같이 여러 값을 지정하는 데 더 유용합니다.

오답 쿼리 1
db.movies.find( { "genres": { "$all" : ["Crime"] } } )

해설:
$all 연산자는 지정된 배열의 모든 요소를 포함하는 문서를 찾습니다. 'Crime' 하나만 지정했을 때는 $in과 결과가 같지만, 개념적으로는 과하며 혼동을 줄 수 있습니다. $all은 'Crime'과 'Drama' 장르가 둘 다 포함된 영화를 찾을 때 ["Crime", "Drama"]와 같이 사용하는 것이 올바른 용법입니다.

오답 쿼리 2
db.movies.find( { "genres": { "$equal" : ["Crime"] } } )

해설:
MongoDB에는 $equal이라는 쿼리 연산자가 존재하지 않습니다. 동등 비교를 위해서는 $eq를 사용하거나, 위 정답 쿼리 1처럼 :를 사용해야 합니다.

핵심 개념 정리
배열 필드에서 특정 단일 요소를 포함하는 문서를 찾을 때는 find({ array_field: "value" }) 형태의 간단한 쿼리를 사용하는 것이 가장 효율적입니다. $in은 여러 값 중 하나라도 포함되는 경우를 찾을 때, $all은 여러 값이 모두 포함되는 경우를 찾을 때 사용합니다.

12. 추가 개념: 레플리카 셋 (Replica Set)
문제
MongoDB 레플리카 셋은 무엇이며 그 목적은 무엇입니까?

출제자 의도
MongoDB의 고가용성 핵심 기능인 레플리카 셋이 '여러' mongod 인스턴스 그룹이라는 근본적인 개념을 이해하고 있는지 평가합니다.

나의 오답
"MongoDB 레플리카 셋은 노드 장애 시 자동 장애 조치(failover)를 제공하는 단일 mongod 인스턴스입니다. 레플리카 셋의 목적은 독립 실행형 mongod 인스턴스에 대한 이중화 및 고가용성을 제공하는 것입니다."

오답 분석:
가장 결정적인 오해는 레플리카 셋을 단일 mongod 인스턴스라고 생각한 점입니다. 자동 장애 조치와 이중화는 여러 개의 노드가 있어야만 가능하므로, 단일 인스턴스는 레플리카 셋을 구성할 수 없습니다.

정답
"MongoDB 레플리카 셋은 동일한 데이터 셋을 호스팅하는 mongod 인스턴스 그룹입니다. 레플리카 셋의 목적은 이중화(redundancy)와 고가용성(high availability)을 제공하고, 노드 장애 시 자동 장애 조치(failover)를 허용하는 것입니다."

정답 해설:
이 설명은 MongoDB 레플리카 셋을 정확하게 기술합니다. 핵심은 여러 mongod 인스턴스가 하나의 그룹을 이루어 동일한 데이터를 복제함으로써 이중화와 고가용성을 보장한다는 점입니다. 주 노드(Primary)에 장애가 발생하면, 레플리카 셋이 자동으로 다른 노드(Secondary)를 새로운 주 노드로 승격시켜 서비스 중단을 최소화합니다.

핵심 개념 정리
레플리카 셋(Replica Set): 동일한 데이터를 유지하는 둘 이상의 MongoDB 서버(노드)들의 모음입니다.

목적: 데이터 이중화, 고가용성.

구성 요소:

Primary (주 노드): 레플리카 셋에서 오직 하나만 존재하며, 모든 쓰기(write) 작업을 처리합니다.

Secondaries (보조 노드): Primary의 데이터를 비동기적으로 복제(replicate)합니다. 읽기(read) 작업을 분산 처리할 수도 있습니다.

자동 장애 조치(Automatic Failover): Primary 노드가 응답하지 않으면, 남은 Secondary 노드들이 투표를 통해 새로운 Primary를 선출하여 서비스를 계속 이어나갑니다. 이 과정은 애플리케이션의 개입 없이 자동으로 이루어집니다.

13. 추가 개념: Replica Set 연결 URI 구성하기
문제
여러 서버에 분산된 MongoDB 레플리카 셋에 연결해야 하는 JavaScript 애플리케이션을 작업 중입니다. 레플리카 셋은 SSL/TLS 암호화가 필요하며, 애플리케이션이 주 노드에 안전하고 최적으로 연결되도록 해야 합니다. 레플리카 셋의 이름은 myReplica이고, 노드는 node1.example.com, node2.example.com, node3.example.com입니다. 또한 쓰기 고려(write concern)를 majority로 설정하여 쓰기 작업이 레플리카 셋 멤버의 과반수로부터 확인되도록 해야 합니다. 다음 중 MongoClient가 SSL/TLS 및 majority 쓰기 고려로 레플리카 셋에 연결하도록 올바르게 구성하는 URI 문자열은 무엇입니까?

출제자 의도
레플리카 셋 연결 시, 드라이버의 장애 조치 기능을 활성화하는 필수 옵션(replicaSet)을 포함하여 올바른 URI를 구성할 수 있는지 평가합니다.

나의 오답 (예상)
mongodb://node1.example.com,node2.example.com,[node3.example.com/?ssl=true&w=majority](https://node3.example.com/?ssl=true&w=majority)

오답 분석:
이 URI는 SSL과 majority 쓰기 고려를 올바르게 설정했지만, 가장 중요한 replicaSet=myReplica 옵션이 빠져있습니다. 이 옵션이 없으면 드라이버는 이 세 개의 노드를 독립적인 서버로 인식할 뿐, 하나의 레플리카 셋으로 인식하지 못합니다. 따라서 드라이버는 주 노드를 자동으로 찾아내거나 장애 조치를 처리할 수 없게 되어 레플리카 셋의 이점을 전혀 활용하지 못합니다.

정답
mongodb://node1.example.com,node2.example.com,[node3.example.com/?replicaSet=myReplica&ssl=true&w=majority](https://node3.example.com/?replicaSet=myReplica&ssl=true&w=majority)

정답 해설
이 URI 문자열은 주어진 모든 요구사항을 정확하게 충족합니다.

mongodb://node1.example.com,node2.example.com,node3.example.com/: 연결할 레플리카 셋의 멤버(seed list)를 지정합니다. 드라이버는 이 목록을 사용하여 셋의 모든 멤버를 발견하고 현재의 주 노드가 어떤 것인지 확인합니다. 모든 노드를 명시하는 것이 고가용성을 위해 권장됩니다.

?: 호스트 목록이 끝나고 옵션이 시작됨을 나타냅니다.

replicaSet=myReplica: 이 부분이 핵심입니다. 드라이버에게 myReplica라는 이름의 레플리카 셋에 연결하도록 지시합니다. 이 옵션을 통해 드라이버는 주 노드 자동 탐색 및 장애 조치를 수행할 수 있습니다.

&ssl=true: 드라이버와 MongoDB 서버 간의 통신에 SSL/TLS 암호화를 사용하도록 설정합니다. (tls=true도 동일한 의미로 사용됩니다.)

&w=majority: 쓰기 고려(Write Concern)를 majority로 설정합니다. 이 설정은 쓰기 작업이 레플리카 셋의 과반수 노드(주 노드 포함)에 적용되었을 때 애플리케이션에 성공을 알리도록 보장하여 데이터의 내구성을 높입니다.

핵심 개념 정리
MongoDB 레플리카 셋에 연결할 때는 하나 이상의 호스트와 함께 replicaSet 옵션을 반드시 명시해야 합니다. 이를 통해 드라이버는 고가용성 및 장애 조치 기능을 올바르게 활성화할 수 있습니다. 추가적인 보안 및 데이터 내구성 요구사항은 ssl, w와 같은 옵션을 통해 URI에 명시합니다.

14. 추가 개념: 샤딩 키(Shard Key)를 이용한 쿼리 최적화
문제
MongoDB 샤드 클러스터에서 개발자는 여러 샤드에 분산된 대규모 고객 데이터 컬렉션을 가지고 있습니다. 개발자는 문서 필드 중 하나인 고객의 거주 주(state)를 기반으로 문서를 효율적으로 쿼리하고 싶어합니다. 현재 컬렉션은 state 필드로 샤딩되어 있지 않습니다. 개발자는 다음 중 어떤 조치를 취해야 할까요?

출제자 의도
샤드 클러스터에서 쿼리 성능을 좌우하는 샤드 키의 중요성과, 타겟 쿼리를 유도하기 위한 샤드 키 선택의 원리를 이해하는지 평가합니다.

나의 오답
_id와 state 필드에 복합 인덱스(compound index)를 생성해야 한다.

오답 분석:
복합 인덱스는 특정 유형의 쿼리 성능을 향상시킬 수 있지만, 샤드 클러스터에서 샤드 간에 데이터를 분산시키는 데는 도움이 되지 않습니다. 인덱스는 단일 샤드 내에서 데이터를 더 빨리 찾는 데 도움을 주지만, 쿼리가 모든 샤드로 전송되는 것(scatter-gather)을 막지는 못합니다.

정답
state 필드를 기준으로 컬렉션을 샤딩해야 한다.

정답 해설:
state 필드를 기준으로 컬렉션을 샤딩하면 state 값에 따라 문서가 샤드 전체에 분산됩니다. 이렇게 하면 MongoDB는 특정 주에 대한 쿼리를 관련된 샤드에만 직접 보낼 수 있습니다. 예를 들어, "California"에 대한 쿼리는 "California" 데이터를 가지고 있는 샤드로만 라우팅되고, 다른 샤드는 검색할 필요가 없어집니다. 이러한 타겟 쿼리(targeted query)는 불필요한 네트워크 트래픽과 샤드 부하를 줄여 쿼리 성능을 크게 향상시킵니다.

핵심 개념 정리
샤드 키 (Shard Key): MongoDB가 샤드 클러스터에서 문서를 분산시키는 기준이 되는 필드 또는 필드들의 조합입니다.

쿼리 라우터 (Query Router / mongos): 클라이언트의 쿼리를 수신하여 샤드 키를 기반으로 어떤 샤드가 해당 데이터를 가지고 있는지 판단하고, 쿼리를 해당 샤드로만 전달하는 역할을 합니다.

타겟 쿼리 (Targeted Query): 쿼리 조건에 샤드 키가 포함되어 있어 mongos가 특정 샤드로 쿼리를 직접 보낼 수 있는 매우 효율적인 쿼리입니다.

분산/수집 쿼리 (Scatter-Gather Query): 쿼리 조건에 샤드 키가 없으면 mongos는 쿼리를 모든 샤드로 보내고 결과를 취합해야 합니다. 이는 성능이 저하되는 원인이 됩니다.

따라서 샤드 클러스터의 성능을 최적화하려면 자주 사용되는 쿼리 필드를 샤드 키로 선택하는 것이 매우 중요합니다.

15. 추가 개념: 배열 요소(Array Element)를 기준으로 정렬하기
문제
products 컬렉션이 있고, 각 문서에는 정수 배열인 ratings 필드가 포함되어 있습니다. ratings 배열의 첫 번째 요소를 기준으로 제품을 내림차순으로 정렬하고 싶습니다. 다음 중 이를 올바르게 수행하는 쿼리는 무엇입니까?

출제자 의도
배열의 특정 위치에 있는 요소를 기준으로 정렬하기 위해 점 표기법("field.index")을 사용할 수 있다는 것을 알고 있는지 평가합니다.

나의 오답
db.products.aggregate([
  { $sort: { "ratings": -1 } }
])

오답 분석:
집계 파이프라인의 $sort를 전체 배열인 "ratings"에 사용하면 첫 번째 요소를 특정하여 정렬하지 않습니다. MongoDB는 배열 전체를 정렬할 때, 내림차순(-1)의 경우 배열의 가장 큰 요소를 기준으로 정렬하는 등 다른 규칙을 적용합니다. 따라서 이 쿼리는 문제의 요구사항을 충족하지 못합니다.

정답
db.products.find().sort({ "ratings.0": -1 })

정답 해설:
"ratings.0"은 점 표기법(dot notation)을 사용하여 배열의 첫 번째 요소(0번 인덱스)를 구체적으로 지정합니다. MongoDB는 find().sort() 메서드에서 배열 내부 요소에 대한 점 표기법을 완벽하게 지원하므로, 이 쿼리는 ratings 배열의 첫 번째 값을 기준으로 문서를 정확하게 내림차순으로 정렬합니다.

핵심 개념 정리
점 표기법 (Dot Notation) for Arrays: MongoDB에서 배열의 특정 인덱스에 있는 요소에 접근하려면 "배열필드명.인덱스"와 같은 점 표기법을 사용합니다. 이는 쿼리 조건(find), 정렬(sort), 프로젝션(결과 필드 선택) 등 다양한 곳에서 매우 유용하게 사용됩니다.

Array Sort vs. Array Element Sort: 배열 필드 자체("ratings")를 기준으로 정렬하는 것과 배열 내 특정 요소("ratings.0")를 기준으로 정렬하는 것은 완전히 다른 결과를 낳습니다. 원하는 정렬 결과를 얻기 위해서는 의도에 맞게 점 표기법을 정확히 사용해야 합니다.

16. 추가 개념: 데이터 모델링 - 임베딩(Embedding) 패턴
문제
MongoDB 데이터 모델링과 관련하여, 개발자는 블로깅 플랫폼을 위한 데이터 모델을 설계해야 합니다. 각 블로그 게시물은 여러 태그와 여러 댓글을 가질 수 있으며, 각 댓글은 여러 사용자에 의해 추천될 수 있습니다. 다음 중 MongoDB에서 이 데이터를 모델링하는 가장 효율적인 방법은 무엇입니까?

출제자 의도
1:N 관계에서 데이터를 효율적으로 모델링하는 임베딩 패턴과 참조 패턴의 차이점을 이해하고, 언제 임베딩이 유리한지 판단할 수 있는지 평가합니다.

나의 오답
블로그 게시물 문서 내에 태그를 임베드하고, 댓글과 추천은 별도의 컬렉션에 저장한다.

오답 분석: 댓글과 추천을 별도의 컬렉션에 저장하면 데이터 모델이 덜 효율적일 수 있습니다. 게시물 하나를 읽을 때마다 댓글과 추천 정보를 가져오기 위해 여러 번의 추가 쿼리가 필요하기 때문입니다. 또한, 태그는 일반적으로 블로그 게시물의 일부이므로 직접 임베드하는 것이 모델을 최적화할 수 있습니다.

정답
블로그 게시물 문서 내에 댓글과 태그를 임베드하고, 각 댓글 문서 내에 사용자 추천을 저장한다.

정답 해설: MongoDB는 풍부한 구조의 문서(rich documents)를 지원하므로, 댓글, 태그, 추천을 블로그 게시물 문서에 직접 임베드하는 것이 데이터를 모델링하는 효율적인 방법입니다. 이 방법을 사용하면 단일 쿼리로 블로그 게시물에 대한 모든 데이터를 검색할 수 있으며, 게시물, 댓글, 태그, 추천에 대한 업데이트는 단일 문서에만 영향을 미칩니다.

핵심 개념 정리
임베딩 패턴 (Embedding Pattern): 관련된 데이터를 부모 문서 내에 배열이나 하위 문서(sub-document) 형태로 포함시키는 방법입니다. 데이터가 함께 조회되는 경우가 많고, 자식 데이터의 양이 너무 많지 않은 '1 대 소수(one-to-few)' 관계에 적합합니다.

장점: 단일 읽기 작업으로 모든 관련 데이터를 가져올 수 있어 읽기 성능이 매우 좋습니다. 데이터의 원자성(atomic)을 보장하기 쉽습니다.

단점: 문서 크기가 16MB 제한을 넘을 수 있고, 자식 데이터만 개별적으로 자주 업데이트되면 비효율적일 수 있습니다.

참조 패턴 (Reference Pattern): 관련된 데이터의 _id 값만 부모 문서에 저장하고, 실제 데이터는 별도의 컬렉션에 두는 방법입니다. (관계형 데이터베이스의 정규화와 유사) '1 대 다수(one-to-many)' 관계나 데이터가 독립적으로 자주 조회될 때 적합합니다.

장점: 문서 크기 제한을 피할 수 있고, 데이터 중복을 줄일 수 있습니다.

단점: 관련 데이터를 가져오려면 애플리케이션 레벨에서 추가 쿼리($lookup 또는 여러 find)가 필요하여 읽기 성능이 저하될 수 있습니다.

블로그 게시물과 댓글/태그의 관계는 전형적인 '1 대 소수' 관계이므로, 임베딩 패턴이 더 효율적인 선택입니다.

17. 추가 개념: Capped Collection 관리 및 확장
문제
한 회사의 애플리케이션 로그가 appData 데이터베이스의 appLogs라는 Capped Collection에 저장됩니다. 각 문서에는 로그 메시지를 저장하는 event 필드와 로그 생성 시간을 기록하는 timestamp 필드가 있습니다. Capped Collection의 크기 제한은 10GB입니다. 회사는 더 많은 로그 데이터를 생성할 새로운 기능을 도입하면서, 최소한 가장 최근 하루 동안의 로그 데이터가 항상 컬렉션에 있도록 보장하고 싶어합니다. 다음 중 최소 하루 분량의 로그 데이터를 항상 사용할 수 있도록 보장하는 전략은 무엇입니까?

출제자 의도
Capped Collection의 고정 크기(fixed-size) 특성과 크기 조절이 불가능하다는 점, 그리고 TTL 인덱스와는 호환되지 않는다는 점을 이해하는지 평가합니다.

나의 오답
모든 문서에 24시간 후 삭제되도록 표시하는 'expiry' 필드를 새로 생성한다.

오답 분석: 'expiry' 필드를 추가한다고 해서 Capped Collection의 문서가 24시간 후에 삭제되지는 않습니다. 만료 필드를 기반으로 한 자동 삭제는 TTL(Time-To-Live) 인덱스의 기능인데, TTL 인덱스는 Capped Collection에서 지원되지 않습니다.

정답
새롭고 더 큰 Capped Collection으로 마이그레이션하고 모든 기존 문서를 복사한다.

정답 해설: 가장 좋은 해결책은 더 큰 크기의 새로운 Capped Collection을 만들고 기존 문서를 복사하는 것입니다. 이 새로운 컬렉션은 하루 이상의 로그 데이터를 담을 수 있는 충분한 공간을 가지게 됩니다. 데이터는 크기 제한에 도달했을 때 여전히 FIFO(선입선출) 규칙에 따라 가장 오래된 데이터부터 삭제되므로, 가장 최신 로그 데이터가 유지되는 것이 보장됩니다. Capped Collection은 크기 변경이 불가능하므로, 용량을 늘리는 유일한 방법은 새로 더 큰 컬렉션을 만들어 데이터를 이전하는 것입니다.

핵심 개념 정리
Capped Collection의 고정 크기: Capped Collection은 생성 시 지정된 크기가 고정되며, 나중에 크기를 변경할 수 없습니다.

확장 전략: Capped Collection의 용량을 늘려야 할 경우, 원하는 크기로 새 컬렉션을 생성한 다음 기존 데이터를 새 컬렉션으로 마이그레이션(이전)해야 합니다.

TTL 인덱스와의 비호환성: Capped Collection은 TTL 인덱스를 지원하지 않습니다. 데이터 삭제는 오직 컬렉션의 크기나 문서 수 제한에 도달했을 때 FIFO 방식으로만 이루어집니다.

18. 추가 개념: updateOne과 upsert를 이용한 조건부 업데이트/삽입
문제
inventory라는 MongoDB 컬렉션에 제품이 저장된 소매 재고 시스템을 관리하고 있습니다. 각 제품 문서에는 _id, item, quantity, price 필드가 있습니다. 제품이 존재하면 수량을 늘리고, 존재하지 않으면 특정 수량과 가격으로 새 제품을 삽입해야 합니다. 제품은 item 필드로 식별됩니다. 이 작업을 수행하려면 다음 updateOne 명령 중 어떤 것을 사용해야 할까요?

출제자 의도
upsert: true 옵션과 함께 사용될 때, 문서가 업데이트될 때와 삽입될 때의 동작이 다른 $set과 $setOnInsert 연산자의 미묘한 차이를 이해하는지 평가합니다.

나의 오답
db.inventory.updateOne(
  { item: "notebook" },
  { $inc: { quantity: 10 }, $set: { price: 5.99 } },
  { upsert: true }
)

오답 분석:
이 옵션은 quantity에 대해 $inc를 올바르게 사용하지만, $set은 문서가 이미 존재하는 경우에도 항상 price를 업데이트합니다. 가격을 삽입 시에만 설정하려는 의도였다면, 이 동작은 바람직하지 않을 수 있습니다.

정답
db.inventory.updateOne(
  { item: "notebook" },
  { $inc: { quantity: 10 }, $setOnInsert: { price: 5.99 } },
  { upsert: true }
)

정답 해설:
이 옵션은 notebook이 존재하면 $inc를 사용하여 수량을 늘리고, 새 문서가 삽입될 때만 $setOnInsert를 사용하여 가격을 설정합니다. upsert: true 옵션은 item이 컬렉션에 존재하지 않을 경우 새 문서가 삽입되도록 보장합니다. 이는 시나리오에 기반한 정확하고 의도된 동작입니다.

핵심 개념 정리
upsert: true: updateOne이나 updateMany와 함께 사용되는 옵션입니다. 필터와 일치하는 문서가 있으면 업데이트(UPdate)하고, 없으면 새 문서를 삽입(INSERT)합니다.

$inc: 지정된 만큼 필드 값을 증가(INCrement)시킵니다. 필드가 없으면 새로 만들고 지정된 값을 설정합니다.

$set: 필드의 값을 지정된 값으로 설정(SET)합니다. 문서가 업데이트되든 삽입되든 항상 적용됩니다.

$setOnInsert: 필드의 값을 지정된 값으로 설정하되, 오직 새로운 문서가 삽입될 때만(SET on INSERT) 적용됩니다. 기존 문서가 업데이트될 때는 이 연산이 무시됩니다.

19. 추가 개념: 데이터 모델링 - 참조(Reference) 패턴
문제
도서관 시스템을 위한 MongoDB 스키마를 설계하고 있습니다. 시스템에는 Books, Authors, Reviews 세 개의 컬렉션이 있습니다.

Books 컬렉션: 제목, 장르, 출판 연도 및 Authors 컬렉션을 참조하는 authorIds 배열 등 각 책에 대한 정보를 포함합니다.

Authors 컬렉션: 이름, 생년월일, 국적 등 각 저자에 대한 정보를 포함합니다.

Reviews 컬렉션: Books 컬렉션을 참조하는 bookId, reviewText, rating 등 책에 대한 사용자 리뷰를 포함합니다.

이 시나리오에서 Books, Authors, Reviews 컬렉션 간의 관계는 MongoDB에서 어떻게 모델링되어야 할까요?

출제자 의도
데이터 중복과 거대 문서 문제를 피하기 위해, 다대다(M:N) 및 확장 가능한 일대다(1:N) 관계에서 언제 참조(Reference) 패턴을 사용해야 하는지 이해하고 있는지 평가합니다.

나의 오답
Authors를 Books 컬렉션 내에 문서 배열로 직접 임베드한다.

오답 분석:
Authors를 Books에 직접 임베드하는 것은 저자가 여러 권의 책을 집필하는 시나리오에서 문제가 됩니다. 이는 데이터 중복으로 이어지며, 저자 정보를 업데이트해야 할 때 해당 저자가 쓴 모든 책 문서를 찾아서 수정해야 하는 복잡성을 야기합니다.

정답
Books 컬렉션에서 authorIds를 사용하여 Authors를 참조하고, Reviews 컬렉션에서 bookId를 사용하여 Books를 참조한다.

정답 해설:
Books에서 authorIds를 사용하여 Authors를 참조하는 것은 저자가 여러 권의 책을 쓸 수 있고, 책 한 권에 여러 명의 저자가 있을 수 있기 때문에 적절합니다. 이러한 다대다(many-to-many) 관계는 참조로 모델링하는 것이 가장 좋습니다. 마찬가지로, Reviews에서 bookId를 사용하여 Books를 참조하는 것도 올바른 방법입니다. 왜냐하면 한 권의 책에는 수많은 리뷰가 달릴 수 있으며, 모든 리뷰를 책 문서 내에 임베드하면 리뷰 수가 증가함에 따라 문서가 지나치게 커지고 비효율적이 될 수 있기 때문입니다.

핵심 개념 정리
참조(Reference) 패턴의 사용 시점:

다대다(Many-to-Many) 관계: Books와 Authors처럼 양쪽 엔티티가 서로에게 '다수'의 관계를 가질 때 참조를 사용해야 데이터 중복을 피할 수 있습니다.

'1 대 다수(One-to-Many)' 관계: Books와 Reviews처럼 한쪽이 매우 많거나, 그 수가 계속해서 무한정 늘어날 가능성이 있을 때 참조를 사용합니다. 이는 단일 문서 크기 제한(16MB)을 피하고 성능을 유지하는 데 도움이 됩니다.

데이터의 독립적 접근/수정: 참조되는 데이터(예: 저자 정보)가 참조하는 데이터(예: 책)와 별개로 자주 조회되거나 수정될 때 참조 모델이 더 효율적입니다.

20. 추가 개념: MongoDB 뷰(View) 생성하기
문제
다음과 같은 상황을 고려해보세요: 당신은 MongoDB 개발자이며 현재 대량의 데이터에 대한 복잡한 리포팅이 필요한 애플리케이션을 작업하고 있습니다. 애플리케이션은 MongoDB에 데이터를 저장하며, 데이터 양이 상당히 커졌습니다. 효율성과 관리 용이성을 유지하기 위해 MongoDB 뷰를 사용하기로 결정했습니다. Users 컬렉션에서 username, email, createdAt 필드만 포함하는 "UsersView"라는 뷰를 생성하려고 합니다. 다음 중 어떤 명령어를 사용해야 할까요?

출제자 의도
db.createView() 명령어의 정확한 구문을 알고 있는지, 특히 뷰가 컬렉션이 아닌 데이터베이스 수준에서 생성되며 소스 컬렉션을 인자로 받는다는 점을 이해하는지 평가합니다.

나의 오답
db.Users.createView("UsersView", {$project: {username: 1, email: 1, createdAt: 1}})

오답 분석:
이 구문은 createView가 컬렉션("Users")의 메서드가 아니기 때문에 올바르지 않습니다. 또한, createView 메서드는 두 번째 매개변수로 소스 컬렉션을 필요로 합니다.

정답
db.createView("UsersView", "Users", [{$project: {username: 1, email: 1, createdAt: 1}}])

정답 해설:
이것이 뷰를 생성하는 올바른 MongoDB 구문입니다. createView 메서드는 세 가지 인자를 받습니다: 생성할 뷰의 이름("UsersView"), 소스 컬렉션의 이름("Users"), 그리고 집계 파이프라인 단계의 배열([{$project: {username: 1, email: 1, createdAt: 1}}])입니다.

핵심 개념 정리
MongoDB 뷰(View): 뷰는 집계 파이프라인의 결과물 위에 만들어진 가상의 읽기 전용(read-only) 컬렉션입니다. 실제 데이터를 저장하지 않으며, 뷰를 쿼리할 때마다 정의된 파이프라인이 실행됩니다.

데이터베이스 수준 명령어: 뷰는 특정 컬렉션에 종속되지 않고 데이터베이스 수준에서 db.createView() 명령어로 생성됩니다.

db.createView() 구문:

db.createView(<viewName>, <sourceCollection>, <pipeline>, <options>)

<viewName>: 생성할 뷰의 이름 (문자열)

<sourceCollection>: 뷰의 기반이 되는 컬렉션 또는 다른 뷰의 이름 (문자열)

<pipeline>: 뷰의 데이터를 정의하는 집계 파이프라인 단계의 배열

21. 추가 개념: findAndModify를 이용한 원자적 업데이트 및 반환
문제
orders 컬렉션에 다음과 같은 문서가 있습니다.

{
    "_id": 1,
    "product": "apple",
    "quantity": 50,
    "status": "processing"
}

문서의 status를 "completed"로 설정하고 quantity를 10만큼 증가시킨 다음, 업데이트된 상태의 문서를 반환하려고 합니다. 다음 중 이 작업을 수행할 findAndModify 명령어는 무엇입니까?

출제자 의도
findAndModify 명령어의 기본 구조와 업데이트된 문서를 반환하게 하는 new: true 옵션의 역할을 정확히 이해하고 있는지 평가합니다.

정답
db.orders.findAndModify({
    query: { _id: 1 },
    update: { $set: { status: "completed" }, $inc: { quantity: 10 } },
    new: true
});

정답 해설:
query는 업데이트할 문서를 찾고, update 객체 안의 $set 연산자는 status 값을 "completed"로 업데이트하며, $inc 연산자는 quantity를 10만큼 증가시킵니다. 핵심인 new: true 옵션은 이 명령이 업데이트가 완료된 후의 새로운(new) 문서를 반환하도록 지시합니다.

핵심 개념 정리
findAndModify: 문서를 찾아서 수정하는 원자적(atomic) 작업을 수행하는 명령어입니다. (참고: 최신 MongoDB 버전에서는 findOneAndUpdate 또는 findOneAndReplace 사용이 권장됩니다.)

원자성(Atomicity): 찾고 수정하는 전체 과정이 다른 어떤 작업에도 방해받지 않고 하나의 단위로 완료됨을 보장합니다.

new: true vs new: false (기본값):

new: true: 업데이트가 적용된 **후(post-modification)**의 문서를 반환합니다.

new: false (또는 생략 시): 업데이트가 적용되기 **전(pre-modification)**의 원본 문서를 반환합니다.

22. 추가 개념: upsert 시 $set과 $setOnInsert의 차이점
문제
전자 상거래 애플리케이션에서 제품 정보를 products라는 MongoDB 컬렉션에 저장하고 있습니다. 컬렉션의 각 문서에는 _id, name, price, stock 필드가 있습니다. 제품이 존재하면 가격과 재고를 업데이트하고, 존재하지 않으면 새 문서를 삽입해야 합니다. 제품은 name 필드로 식별됩니다. 주어진 시나리오에서, 필요한 upsert 작업을 올바르게 수행하는 updateOne 명령어는 다음 중 무엇입니까?

출제자 의도
upsert 작업에서 문서가 업데이트될 때와 삽입될 때 모두 필요한 필드와, 오직 삽입될 때만 필요한 필드를 구분하여 올바른 연산자($set, $setOnInsert)를 사용할 수 있는지 평가합니다.

나의 오답
db.products.updateOne(
  { name: "Laptop" },
  { $setOnInsert: { price: 1200, stock: 50 } },
  { upsert: true }
)

오답 분석:
$setOnInsert는 새 문서가 삽입될 때만 필드를 설정하는 데 사용됩니다. 하지만 price와 stock은 기존 문서에서도 업데이트되어야 하므로, $setOnInsert만 사용하면 기존 문서의 price나 stock이 업데이트되지 않는 문제가 발생합니다.

정답
db.products.updateOne(
  { name: "Laptop" },
  { $set: { price: 1200, stock: 50 } },
  { upsert: true }
)

정답 해설:
이 명령어는 name 필드로 제품을 정확하게 식별하고, 문서가 존재하는 경우 $set 연산자를 사용하여 price와 stock 필드를 업데이트합니다. upsert: true 옵션은 name 필드와 일치하는 문서가 없을 경우, 지정된 price와 stock으로 새 문서가 삽입되도록 보장합니다. 다른 옵션들은 문서를 올바르게 업데이트하지 못하거나 새 문서의 삽입을 잘못 처리합니다.

핵심 개념 정리
$set in upsert: 문서가 업데이트될 때와 삽입될 때 모두 필드 값을 설정합니다. 시나리오처럼 두 경우 모두 값을 변경하거나 설정해야 할 때 사용합니다.

$setOnInsert in upsert: 오직 문서가 삽입될 때만 필드 값을 설정합니다. 기존 문서가 업데이트될 때는 아무런 작업도 하지 않습니다. 생성 시간(createdAt)처럼 초기 설정 후에는 변경되지 않아야 하는 필드에 유용합니다.

23. 추가 개념: 최대값 자체 구하기 vs 최대값을 가진 문서 구하기
문제
다음과 같은 employees 컬렉션을 생각해보세요. "Sales" 부서 직원들 중 최대 급여(maximum salary)는 얼마인지 찾는 쿼리는 무엇입니까?

데이터 예시:

{ "_id": 1, "name": "John Doe", "department": "Sales", "salary": 5000 },
{ "_id": 2, "name": "Jane Doe", "department": "Marketing", "salary": 6000 },
{ "_id": 3, "name": "Jim Smith", "department": "Sales", "salary": 4500 }

출제자 의도
특정 값 자체를 계산하는 것(Aggregation)과 해당 값을 가진 문서를 찾는 것(find)의 차이를 이해하고, 문제의 요구사항에 맞는 올바른 방법을 선택할 수 있는지 평가합니다.

나의 오답
db.employees.find({department: "Sales"}).sort({salary: -1}).limit(1)

오답 분석:
이 쿼리는 "Sales" 부서의 모든 문서를 찾아 salary 필드를 기준으로 내림차순 정렬한 다음, 첫 번째 문서 하나만 반환합니다. 이 방법은 "Sales" 부서에서 가장 높은 급여를 받는 **'직원 정보(문서 전체)'**를 반환하는 것이지, 문제에서 요구한 '최대 급여액(값)' 자체를 반환하는 것이 아닙니다.

정답
db.employees.aggregate([
  { $match: { department: "Sales" } },
  { $group: { _id: null, max_salary: { $max: "$salary" } } }
])

24. 추가 개념: 복합 인덱스와 정렬 순서
문제
다음과 같은 쿼리가 있습니다. db.coll.find({}).sort({"product": 1, "price": 1}) 이 쿼리의 성능을 가장 크게 향상시키는 인덱스 두 개는 무엇입니까?

출제자 의도
복합 인덱스를 정렬에 활용할 때, 인덱스 필드의 순서와 방향이 쿼리의 정렬 순서와 어떻게 일치해야 하는지를 이해하고 있는지 평가합니다.

나의 오답
{ key: { price: 1, product: 1 } }

오답 분석: 이 인덱스는 쿼리의 정렬 순서와 일치하지 않습니다. 쿼리는 product를 먼저 정렬하고 그 다음에 price를 정렬하지만, 이 인덱스는 price를 먼저 정렬하고 그 다음에 product를 정렬합니다. 따라서 이 인덱스는 해당 쿼리의 정렬 작업에 최적으로 사용될 수 없습니다.

정답
{ key: { product: 1, price: 1 } }

{ key: { product: -1, price: -1 } }

정답 해설:

{ product: 1, price: 1 }: 이 인덱스는 쿼리의 정렬 필드와 순서, 그리고 방향까지 정확하게 일치하므로 쿼리 성능을 향상시킵니다.

{ product: -1, price: -1 }: 이 인덱스는 쿼리의 정렬 필드와 순서는 같지만, 모든 필드의 방향이 정반대입니다. MongoDB는 인덱스를 역순으로도 효율적으로 탐색할 수 있으므로, 이 인덱스 역시 쿼리 성능을 동일하게 향상시킵니다.

핵심 개념 정리
필드 순서: 복합 인덱스가 정렬 연산을 지원하려면, 인덱스에 나열된 필드의 순서가 쿼리의 정렬 필드 순서와 반드시 일치해야 합니다.

정렬 방향: 인덱스의 정렬 방향(오름차순 1, 내림차순 -1)은 쿼리의 정렬 방향과 모두 동일하거나, 모두 정반대여야 합니다. 필드마다 방향이 섞여 있으면({product: 1, price: -1}) 이 쿼리에는 최적으로 사용될 수 없습니다.

25. 추가 개념: MQL에서 $ 기호의 용도
문제
MQL(MongoDB Query Language)에서 $ 기호의 용도 중 일부는 무엇입니까? (2개 선택)

출제자 의도
MQL에서 $ 기호의 두 가지 주요 역할, 즉 연산자 접두사와 집계 표현식에서의 필드 값 참조를 구분할 수 있는지 평가합니다.

나의 오답
$는 쿼리 내에서 문자열을 연결하는 데 사용된다.

오답 분석: MQL에서 문자열 연결에는 $ 기호 자체가 사용되지 않습니다. 대신 $concat과 같은 특정 연산자가 사용됩니다. $ 기호는 주로 연산자의 접두사나 필드 값을 나타내는 데 사용됩니다.

정답
$는 연산자를 나타냅니다 - 모든 MQL 연산자는 $ 접두사를 가집니다.

$가 필드 이름 앞에 접두사로 붙을 때, 해당 필드에 저장된 값을 나타냅니다.

정답 해설:

연산자 접두사: MQL에서 $ 기호는 연산자를 나타내는 데 사용됩니다. 모든 MQL 연산자는 $eq(같음), $gt(보다 큼), $lt(보다 작음) 등과 같이 $ 기호로 시작합니다.

필드 값 참조: 집계 파이프라인과 같은 표현식에서 필드 이름 앞에 $를 붙이면 (예: "$fieldName"), 이는 해당 필드에 저장된 **값(value)**을 의미합니다. 이를 통해 다른 필드의 값과 비교하거나 계산에 사용할 수 있습니다.

핵심 개념 정리
MQL에서 $ 기호는 두 가지 핵심적인 역할을 합니다:

연산자(Operator) 표시: 모든 연산자(예: $set, $match, $group, $gt)는 $로 시작합니다.

필드 경로/값(Field Path/Value) 참조: 주로 집계 파이프라인에서 필드 이름을 문자열로 감싸고 $를 앞에 붙이면(예: "$salary"), 이는 해당 필드의 값을 가리키는 변수처럼 사용됩니다.


## 31\. 추가 개념: `findAndModify`를 이용한 원자적 재고 차감

### 문제

MongoDB 기반 애플리케이션을 개발하고 있습니다. `products` 컬렉션에는 `sku` 필드에 고유 인덱스가 있습니다. 특정 SKU에 대해 현재 재고(`inventory`)가 0보다 큰 경우에만 `inventory` 필드를 1만큼 감소시켜야 합니다. 이 작업을 `findAndModify` 메서드로 수행하는 가장 좋은 방법은 무엇입니까?

### 출제자 의도

> 원자적 연산에서 조건 확인(재고 \> 0)과 업데이트(재고 차감)를 하나의 쿼리에 결합하는 방법을 이해하고, 값을 감소시키는 올바른 연산자(`$inc`)를 알고 있는지 평가합니다.

### 나의 오답

```javascript
db.products.findAndModify({
    query: { sku: "ABC123", inventory: { $gt: 0 } },
    update: { $dec: { inventory: 1 } }
});
```

**오답 분석:**
MongoDB에는 `$dec`라는 연산자가 없습니다. 필드의 값을 감소시키려면 `$inc` 연산자에 음수 값을 사용해야 합니다.

### 정답

```javascript
db.products.findAndModify({
    query: { sku: "ABC123", inventory: { $gt: 0 } },
    update: { $inc: { inventory: -1 } }
});
```

**정답 해설:**
`findAndModify` 메서드는 `products` 컬렉션에서 `sku` 필드가 "ABC123"이고 `inventory` 필드가 0보다 큰 문서를 찾습니다. 그런 다음 `$inc`(증가) 연산자를 사용하여 `inventory` 필드를 -1만큼 증가시켜 효과적으로 값을 1 감소시킵니다.

### 핵심 개념 정리

  * **원자적 조건부 업데이트 (Atomic Conditional Update):** 이 쿼리의 가장 중요한 부분은 `query` 객체 안에 조건(`inventory: { $gt: 0 }`)을 포함시킨 것입니다. 이렇게 하면 MongoDB는 '재고가 0보다 큰 문서를 찾아서' '재고를 1 감소시키는' 두 가지 작업을 다른 어떤 작업에도 방해받지 않는 단일 원자적 연산으로 처리합니다. 이는 여러 요청이 동시에 재고를 차감하려고 할 때 발생하는 경쟁 조건(race condition)을 방지합니다.
  * **`$inc`를 이용한 감소:** MongoDB에서 필드 값을 감소시키는 표준 방법은 `$inc` 연산자와 함께 음수를 사용하는 것입니다. `$dec`와 같은 별도의 감소 연산자는 존재하지 않습니다.


  ## 32. 추가 개념: 일대다(One-to-Many) 관계 모델링

### 문제
MongoDB에서 사용자와 그들의 주문(orders) 간의 일대다 관계를 모델링하는 가장 좋은 방법은 무엇입니까?

### 출제자 의도
> "다수"에 해당하는 쪽(주문)이 무한히 커질 수 있는 일대다 관계에서, 임베딩 대신 참조를 사용하고 각 엔티티를 별도의 컬렉션으로 분리하는 기본 원칙을 이해하는지 평가합니다.

### 나의 오답
사용자와 주문 모두를 위한 단일 컬렉션을 사용하고, 주문 문서의 참조 필드를 사용하여 사용자 문서에 연결한다.

**오답 분석:**
사용자와 주문을 단일 컬렉션에 혼합하면 한 곳에 다른 유형의 문서가 섞이게 되어 유지 관리나 확장성 측면에서 이상적이지 않습니다. 엔티티를 다른 컬렉션으로 분리하고 참조를 통해 관계를 관리하는 것이 좋습니다.

### 정답
사용자 데이터와 주문 데이터를 별도의 컬렉션에 저장하고, 주문 문서의 참조 필드를 사용하여 사용자 문서에 연결한다.

**정답 해설:**
"다수" 측(주문)이 상당히 커질 수 있는 일대다 관계를 모델링하는 가장 좋은 접근 방식이기 때문에 이것이 올바릅니다. 사용자와 주문을 별도의 컬렉션에 저장하면 각 엔티티가 독립적으로 확장될 수 있습니다. 주문 문서의 참조 필드를 사용하여 사용자 문서에 연결하면 문서를 작고 관리하기 쉽게 유지하면서 관계를 유지할 수 있습니다.

### 핵심 개념 정리
* **엔티티별 컬렉션 분리:** 서로 다른 종류의 데이터(사용자, 주문)는 별도의 컬렉션으로 관리하는 것이 기본 원칙입니다. 이는 스키마를 명확하게 하고, 인덱싱과 쿼리를 단순화하며, 유지보수를 용이하게 합니다.
* **'1 대 다수(One-to-Many)' 관계의 참조:** 사용자의 주문처럼 '다수'에 해당하는 데이터가 무한정 늘어날 수 있는 관계에서는 **참조(Reference)** 패턴을 사용합니다. 모든 주문을 사용자 문서에 임베딩하면 문서 크기 제한(16MB)에 도달하거나 성능이 저하될 수 있습니다. 
* **자식 참조 (Child-Referencing):** '다수' 측인 자식 문서(주문)가 부모 문서(사용자)의 `_id`를 참조 필드(예: `userId`)로 가지는 방식입니다. 이 모델은 주문이 계속 추가되어도 사용자 문서의 크기에 영향을 주지 않아 확장성이 뛰어납니다.


## 33\. 추가 개념: 고유 인덱스(Unique Index)와 중복 값 처리

### 문제

고유 인덱스(unique index)가 있는 필드에 중복된 값을 가진 문서를 MongoDB는 어떻게 처리합니까?

### 출제자 의도

> 데이터 무결성을 보장하는 고유 인덱스의 핵심 기능과 제약 조건 위반 시 MongoDB의 동작 방식을 정확히 알고 있는지 평가합니다.

### 나의 오답

MongoDB는 고유 인덱스가 있는 필드에 중복된 값을 가진 여러 문서를 허용한다.

**오답 분석:**
고유 인덱스의 주된 목적은 인덱싱된 필드에 중복된 값이 들어오는 것을 막는 것입니다. MongoDB는 이 제약 조건을 강제하므로, 고유 인덱스가 있는 필드에 중복된 값을 가진 여러 문서를 허용하지 않습니다.

### 정답

MongoDB는 오류를 반환하고 고유 인덱스가 있는 필드에 해당 문서의 삽입을 막습니다.

**정답 해설:**
MongoDB는 인덱싱된 필드의 고유성을 강제합니다. 만약 중복된 값을 가진 문서의 삽입이 시도되면, MongoDB는 오류를 반환하고 문서를 삽입하지 않음으로써 고유성 제약 조건을 유지합니다.

### 예시로 보는 동작 방식

**1. `users` 컬렉션과 고유 인덱스 생성:**
`email` 필드에는 중복된 값이 들어올 수 없도록 고유 인덱스를 생성합니다.

```javascript
// db.users 컬렉션
{ "username": "Alice", "email": "alice@example.com" }

// email 필드에 고유 인덱스 생성
db.users.createIndex({ "email": 1 }, { unique: true })
```

**2. 중복된 이메일로 문서 삽입 시도:**
이미 존재하는 `alice@example.com` 이메일로 새로운 사용자를 추가하려고 시도합니다.

```javascript
db.users.insertOne({ "username": "Alice_2", "email": "alice@example.com" })
```

**3. 결과:**
MongoDB는 이 삽입 작업을 거부하고 다음과 유사한 \*\*중복 키 오류(duplicate key error)\*\*를 반환합니다. "Alice\_2" 사용자는 컬렉션에 추가되지 않습니다.

```
E11000 duplicate key error collection: test.users index: email_1 dup key: { email: "alice@example.com" }
```

### 핵심 개념 정리

  * **고유 인덱스 (Unique Index):** 인덱싱된 필드의 값이 컬렉션 내 모든 문서에서 고유해야 한다는 제약 조건을 강제합니다.
  * **데이터 무결성:** 고유 인덱스는 `_id` 필드 외에도 이메일 주소, 사용자 아이디 등 중복되어서는 안 될 데이터의 무결성을 보장하는 중요한 수단입니다.
  * **오류 처리:** 고유 제약 조건을 위반하는 쓰기 작업(삽입, 업데이트)이 시도되면, 작업은 실패하고 데이터베이스는 오류를 발생시킵니다.



## 37. 추가 개념: `admin` 데이터베이스의 역할

### 문제
MongoDB에 내장된 `admin` 데이터베이스의 용도는 무엇입니까?

### 출제자 의도
> MongoDB의 시스템 데이터베이스 중 인증, 권한 부여 및 서버 수준의 관리 명령을 담당하는 `admin` 데이터베이스의 역할을 이해하고 있는지 평가합니다.

### 정답 및 해설
`admin` 데이터베이스는 인증(authentication)과 권한 부여(authorization) 프로세스에서 중요한 역할을 합니다. 또한 관리자가 수행하는 특정 작업(예: 서버 설정, 사용자 관리)에도 이 데이터베이스에 대한 접근 권한이 필요합니다.

### 핵심 개념 정리
`admin` 데이터베이스는 특정 애플리케이션 데이터를 저장하는 곳이 아니라, MongoDB 서버 인스턴스 전체를 관리하기 위한 특별한 용도의 데이터베이스입니다. 

* **인증 및 권한 부여의 중심:**
    * 모든 데이터베이스의 사용자 정보와 역할(role)은 `admin` 데이터베이스 내의 `system.users`와 `system.roles` 컬렉션에 중앙 집중식으로 저장됩니다.
    * 사용자가 어떤 데이터베이스에 접속하든, 인증 정보는 `admin` 데이터베이스에서 조회됩니다.

* **관리자 전용 명령 실행:**
    * 데이터베이스 목록 보기(`listDatabases`), 서버 종료(`shutdown`), 복제본 세트 상태 확인 등 서버 전체에 영향을 미치는 많은 관리 명령어는 `admin` 데이터베이스에 연결된 상태에서 실행해야 합니다.

* **"루트(Root)" 접근 지점:**
    * `admin` 데이터베이스에 대한 접근 권한이 있다는 것은 사실상 MongoDB 서버 전체에 대한 관리자 권한을 갖는 것과 같습니다. 따라서 이 데이터베이스의 접근은 매우 신중하게 관리되어야 합니다.


## 52\. 추가 개념: `$group` 집계의 올바른 필드명 지정

### 문제

`movies` 컬렉션의 문서들을 `rated` 필드를 기준으로 그룹화하여, 각 등급(`rated`)별 문서의 분포(개수)를 어떻게 추출할 수 있습니까?

**데이터 예시:**

```json
{ "title": "The Great Train Robbery", "rated": "TV-G", ... },
{ "title": "The Land Beyond the Sunset", "rated": "UNRATED", ... },
{ "title": "A Corner in Wheat", "rated": "G", ... }
```

### 출제자 의도

> `$group` 집계 단계에서 결과를 담을 새로운 필드의 이름을 지정하는 올바른 구문을 알고 있는지, 특히 필드 이름이 `$`로 시작하는 연산자가 될 수 없음을 이해하는지 평가합니다.

### 나의 오답

```javascript
db.movies.aggregate( { $group: { _id: '$rated', $count: { $sum: 1 } } } )
```

**오답 분석:**
이 옵션은 구문 오류가 있습니다. `$group` 단계에서 새로 생성되는 필드의 이름(여기서는 `$count`)은 유효한 문자열이어야 하며, `$`로 시작하는 연산자 형태일 수 없습니다.

### 정답

```javascript
db.movies.aggregate( { $group: { _id: '$rated', count: { $sum: 1 } } } )
```

**정답 해설:**
이 옵션은 MongoDB 집계 프레임워크를 사용하여 문서를 `rated` 필드별로 그룹화한 다음, `$sum` 연산자를 사용하여 각 그룹의 문서 수를 계산합니다. 계산된 결과는 `count`라는 이름의 새로운 필드에 저장되며, 최종적으로 `rated` 필드의 분포(각 등급별 영화의 수)를 보여줍니다.

### 핵심 개념 정리

  * **`$group`의 필드명 지정:** `$group` 단계에서 `{ <필드명>: <누산 연산자> }` 형태로 새로운 필드를 생성할 때, `<필드명>`은 반드시 `$`로 시작하지 않는 유효한 문자열이어야 합니다.
  * **필드명 vs. 연산자:** `count`는 개발자가 지정하는 **필드의 이름**이고, `$sum`은 MongoDB가 제공하는 **연산자**입니다. 이 둘의 역할을 혼동해서는 안 됩니다. `$count`는 집계 파이프라인의 **단계(stage)** 이름으로는 존재하지만, `$group` 내에서 필드명이나 연산자로 사용될 수는 없습니다.

  최종 결과
쿼리가 완료되면 MongoDB는 다음과 같은 결과를 반환합니다. _id 필드에는 그룹화의 기준이 된 rated 값이, count 필드에는 각 그룹에 포함된 문서의 총 개수가 표시됩니다.

```json
[
  { "_id": "TV-G", "count": 1 },
  { "_id": "UNRATED", "count": 1 },
  { "_id": "G", "count": 1 }
]
```


네, 알겠습니다. 고유 인덱스와 비고유 인덱스의 차이점을 명확하게 보여주는 예시를 제공해 드리겠습니다.

-----

## 53\. 추가 개념: 고유 인덱스 vs. 비고유 인덱스 (Unique vs. Non-Unique Index)

### 문제

MongoDB에서 고유 인덱스(unique index)와 비고유 인덱스(non-unique index)의 차이점은 무엇입니까?

### 출제자 의도

> 쿼리 성능 향상이라는 공통된 목적 외에, 데이터의 무결성을 강제하는 고유 인덱스와 중복을 허용하는 비고유 인덱스의 근본적인 차이점을 이해하고 있는지 평가합니다.

### 정답

고유 인덱스는 인덱싱된 필드에 대해 고유성 제약 조건을 강제하는 반면, 비고유 인덱스는 인덱싱된 필드에 여러 문서가 동일한 값을 갖도록 허용합니다.

**해설:**
MongoDB의 고유 인덱스는 인덱싱된 필드의 모든 값이 컬렉션의 문서 전체에서 고유함을 보장합니다. 반면에 비고유 인덱스는 이러한 제약 조건을 강제하지 않으므로 인덱싱된 필드에 중복된 값을 허용합니다.

### **예시로 보는 차이점**

간단한 `employees` 컬렉션을 예로 들어 두 인덱스의 동작을 비교해 보겠습니다.

-----

### 1\. 비고유 인덱스 (Non-Unique Index) - **중복 허용**

**상황:** 직원들의 부서(`department`)를 기준으로 검색하는 경우가 많아, 이 필드에 인덱스를 생성하려고 합니다. 여러 직원이 같은 부서에 있을 수 있으므로 비고유 인덱스가 적합합니다.

**인덱스 생성:**

```javascript
// 'department' 필드에 비고유 인덱스를 생성합니다.
db.employees.createIndex({ department: 1 })
```

**데이터 삽입:**

```javascript
db.employees.insertOne({ name: "Alice", department: "Sales" })
// 성공적으로 삽입됩니다.

db.employees.insertOne({ name: "Bob", department: "Marketing" })
// 성공적으로 삽입됩니다.

db.employees.insertOne({ name: "Charlie", department: "Sales" })
// "Sales"는 이미 존재하지만, 비고유 인덱스이므로 문제없이 성공적으로 삽입됩니다.
```

**결과:**
`department` 필드는 중복된 "Sales" 값을 가질 수 있습니다. 이 인덱스는 `db.employees.find({ department: "Sales" })`와 같은 쿼리의 **성능을 향상**시키는 역할만 합니다.

-----

### 2\. 고유 인덱스 (Unique Index) - **중복 금지**

**상황:** 각 직원은 고유한 사번(`employeeId`)을 가져야 합니다. 이 규칙을 데이터베이스 수준에서 강제하고 싶습니다.

**인덱스 생성:**

```javascript
// 'employeeId' 필드에 고유 인덱스를 생성합니다. { unique: true } 옵션이 핵심입니다.
db.employees.createIndex({ employeeId: 1 }, { unique: true })
```

**데이터 삽입:**

```javascript
db.employees.insertOne({ name: "David", employeeId: 101 })
// 성공적으로 삽입됩니다.

db.employees.insertOne({ name: "Eve", employeeId: 102 })
// 성공적으로 삽입됩니다.

db.employees.insertOne({ name: "Frank", employeeId: 101 })
// 실패! employeeId 101은 이미 존재하므로, MongoDB는 이 삽입을 거부하고 오류를 반환합니다.
```

**결과:**
"Frank"의 문서는 삽입되지 않고, 다음과 유사한 \*\*중복 키 오류(duplicate key error)\*\*가 발생합니다. 이 인덱스는 쿼리 성능 향상뿐만 아니라 **데이터의 무결성을 강제하는 규칙**의 역할을 합니다.

### 비교 요약

| 구분 | 비고유 인덱스 (Non-Unique) | 고유 인덱스 (Unique) |
| :--- | :--- | :--- |
| **주요 목적** | 쿼리 성능 향상 | 데이터 무결성 강제 + 쿼리 성능 향상 |
| **중복 값** | **허용** | **금지** |
| **사용 사례** | 부서, 카테고리, 도시 등 중복 가능한 필드 | 이메일, 사용자 ID, 주민등록번호, 사번 등 고유해야 하는 필드 |


36. 추가 개념: $unwind와 $group을 이용한 배열 집계
문제
orders 컬렉션에 다음과 같은 문서들이 있습니다. 각 제품(product_id)별로 주문된 총 수량(quantity)을 찾는 쿼리는 무엇입니까?

데이터 예시:

JSON

// Document 1
{ "customer_id" : "A123", "items" : [ { "product_id" : "P001", "quantity" : 5 }, { "product_id" : "P002", "quantity" : 2 } ] },
// Document 2
{ "customer_id" : "B456", "items" : [ { "product_id" : "P001", "quantity" : 3 }, { "product_id" : "P003", "quantity" : 1 } ] },
// Document 3
{ "customer_id" : "C789", "items" : [ { "product_id" : "P002", "quantity" : 4 } ] }
출제자 의도
배열 내의 데이터를 집계하기 위해 $unwind를 사용한 후, 특정 키를 기준으로 문서를 그룹화하려면 $group 스테이지에서 _id 필드를 명시해야 한다는 점을 이해하고 있는지 평가합니다.

나의 오답
JavaScript

db.orders.aggregate([
   {
      $unwind: "$items"
   },
   {
      $group: {
         total_orders: { $sum: "$items.quantity" }
      }
   }
])
오답 분석:
이 쿼리는 items 배열을 올바르게 분해($unwind)했지만, $group 단계에서 그룹화의 기준이 되는 _id 필드를 지정하지 않았습니다. _id 필드가 없으면 $group은 모든 문서를 단일 그룹으로 결합하여 모든 문서에 걸친 quantity 필드의 총합을 계산합니다. 이는 각 제품별 주문 수량을 제공하는 대신, 전체 제품의 총 주문 수량을 반환하게 됩니다.

정답
JavaScript

db.orders.aggregate([
   {
      $unwind: "$items"
   },
   {
      $group: {
         _id: "$items.product_id",
         total_orders: { $sum: "$items.quantity" }
      }
   }
])
정답 해설:
이 쿼리는 MongoDB Aggregation Framework를 사용하여 각 제품별 주문 수량을 정확하게 계산합니다.

$unwind: "$items": items 배열을 분해하여 각 배열 요소에 대해 별도의 문서를 생성합니다. 3개의 주문 문서가 5개의 개별 품목 문서로 변환됩니다.

$group: { _id: "$items.product_id", ... }: 분해된 문서를 items.product_id 필드를 기준으로 그룹화합니다. 즉, 동일한 product_id를 가진 문서들이 같은 그룹으로 묶입니다.

total_orders: { $sum: "$items.quantity" }: 각 그룹 내에서 quantity 필드의 합계를 계산하여 total_orders라는 필드에 저장합니다.

단계별 실행 과정
1. $unwind 실행 후:

JSON

{ "customer_id" : "A123", "items" : { "product_id" : "P001", "quantity" : 5 } }
{ "customer_id" : "A123", "items" : { "product_id" : "P002", "quantity" : 2 } }
{ "customer_id" : "B456", "items" : { "product_id" : "P001", "quantity" : 3 } }
{ "customer_id" : "B456", "items" : { "product_id" : "P003", "quantity" : 1 } }
{ "customer_id" : "C789", "items" : { "product_id" : "P002", "quantity" : 4 } }
2. $group 실행 후 (최종 결과):

JSON

{ "_id" : "P001", "total_orders" : 8 }  // 5 + 3
{ "_id" : "P003", "total_orders" : 1 }
{ "_id" : "P002", "total_orders" : 6 }  // 2 + 4
핵심 개념 정리
$unwind: 배열 필드를 "풀어서" 각 배열 요소마다 문서를 복제하는 집계 파이프라인 단계입니다. 배열 내 데이터를 다룰 때 거의 항상 첫 단계로 사용됩니다.

$group의 _id 필드: 그룹화의 기준을 정의하는 핵심 필드입니다. 이 필드를 지정하지 않으면 모든 문서가 하나의 그룹으로 처리됩니다.






## 각 데이터의 관계와 모델링 결정
1. 사용자(Users)와 게시물(Posts) → 참조 방식 사용
관계: 한 명의 사용자는 수많은 게시물을 작성할 수 있습니다 (1:N 관계).

왜 임베딩하지 않는가?: 만약 사용자의 모든 게시물을 사용자 문서 안에 배열로 저장(임베딩)한다면, 게시물을 많이 작성하는 사용자의 경우 문서 크기가 계속해서 커집니다. 이는 MongoDB의 단일 문서 크기 제한(16MB)을 초과할 위험이 있고, 문서를 읽고 쓸 때마다 거대한 데이터를 다뤄야 하므로 성능이 저하됩니다. 이를 'Unbounded Array' 문제라고 하며, 이런 경우엔 참조 방식을 사용해야 합니다.

결과: Users 컬렉션과 Posts 컬렉션을 분리합니다. Posts 문서에는 해당 게시물을 작성한 사용자의 ID(userId)를 저장하여 연결합니다.

사용자 프로필 조회: Users 컬렉션에서 해당 사용자 문서 하나만 읽으면 되므로 매우 빠릅니다.

사용자의 모든 게시물 조회: Posts 컬렉션에서 userId 필드를 인덱싱하여 검색하면 효율적입니다.

2. 게시물(Posts)과 댓글(Comments) → 임베딩 방식 사용
관계: 하나의 게시물에는 여러 개의 댓글이 달릴 수 있습니다 (1:N 관계).

왜 임베딩하는가?: 사용자는 언제나 게시물을 볼 때 그 게시물에 달린 댓글을 함께 봅니다. 댓글만 따로 보는 경우는 거의 없습니다. 이렇게 '같이' 조회되는 데이터는 한 문서에 묶어두는 것이 가장 효율적입니다.

결과: Posts 문서 내에 comments라는 배열을 만들고, 각 댓글을 객체 형태로 저장합니다.

게시물과 댓글 조회: 게시물 문서 하나만 DB에서 읽어오면 모든 댓글 정보까지 한 번에 가져올 수 있습니다. 별도의 쿼리나 '조인($lookup)'이 필요 없어 읽기 속도가 매우 빠릅니다.

3. 게시물(Posts)과 좋아요(Likes) → 임베딩 방식 사용
관계: 하나의 게시물에는 여러 명이 '좋아요'를 누를 수 있습니다 (1:N 관계).

왜 임베딩하는가?: '좋아요' 수 계산은 매우 빈번하게 일어나는 작업입니다. 이 정보를 별도 컬렉션으로 분리하면 '좋아요' 수를 셀 때마다 해당 컬렉션 전체를 검색해야 해서 비효율적입니다.

결과: Posts 문서 내에 likes 필드를 만듭니다. 두 가지 방법이 일반적입니다.

카운터 방식: likeCount 필드를 두고, '좋아요'가 눌릴 때마다 숫자를 1씩 증가($inc)시킵니다. 수를 세는 것이 목적이라면 가장 빠릅니다.

배열 방식: likedByUsers 같은 배열을 두고, '좋아요'를 누른 사용자의 ID를 저장합니다. '좋아요' 수는 배열의 크기($size)로 쉽게 알 수 있고, 누가 '좋아요'를 눌렀는지도 알 수 있습니다.

'좋아요' 수 계산: 어떤 방식을 쓰든 게시물 문서 하나만 읽으면 되므로 즉시 계산이 가능합니다.

---
Covered Query란 ?

데이터베이스가 쿼리 결과를 인덱스만으로 모두 처리할 수 있는 경우를 말합니다. 즉, 실제 데이터가 저장된 도큐먼트(document)를 읽을 필요 없이, 인덱스에 있는 정보만으로 사용자에게 필요한 모든 데이터를 반환할 수 있는 매우 효율적인 쿼리입니다. 🚀


예시 💻
users 컬렉션에 다음과 같은 데이터가 있다고 가정해 봅시다.

{ "_id": 1, "name": "Alice", "age": 30, "city": "Seoul" }
{ "_id": 2, "name": "Bob", "age": 25, "city": "Busan" }
그리고 name과 age 필드로 구성된 복합 인덱스를 생성합니다.

db.users.createIndex({ "name": 1, "age": 1 })
1. 커버드 쿼리 예시
아래 쿼리는 name으로 문서를 찾고, 결과로 name과 age 필드만 요청합니다. name과 age는 모두 인덱스에 포함되어 있으므로 커버드 쿼리가 됩니다.

// 쿼리 필드(name), 프로젝션 필드(name, age) 모두 인덱스에 존재
db.users.find(
  { "name": "Alice" },
  { "name": 1, "age": 1, "_id": 0 }
)
이 쿼리는 도큐먼트를 전혀 보지 않고 인덱스만으로 결과를 반환할 수 있습니다.

2. 커버드 쿼리가 아닌 예시
아래 쿼리는 결과로 city 필드를 추가로 요청합니다. 하지만 city 필드는 인덱스에 없기 때문에, MongoDB는 name과 age를 인덱스에서 찾은 후 city 값을 얻기 위해 결국 도큐먼트를 열어봐야 합니다.

// 프로젝션 필드 'city'가 인덱스에 없음
db.users.find(
  { "name": "Alice" },
  { "name": 1, "age": 1, "city": 1, "_id": 0 }
)

54. 추가 개념: 데이터 모델링 - 참조 패턴의 올바른 적용
문제
전자 상거래 플랫폼을 위한 MongoDB 스키마를 설계하고 있습니다. 시스템에는 Products, Categories, Reviews 세 개의 컬렉션이 있습니다.
Products 컬렉션: 이름, 가격 및 Categories 컬렉션을 참조하는 categoryId를 포함합니다.
Categories 컬렉션: 카테고리 이름과 설명을 포함합니다.
Reviews 컬렉션: Products 컬렉션을 참조하는 productId, userId, rating, reviewText를 포함합니다.
이 시나리오에서 Products, Categories, Reviews 간의 관계를 모델링하는 가장 좋은 접근 방식은 무엇입니까?
출제자 의도
데이터 관계의 특성(1:N vs 1:Squillions)을 파악하고, 데이터 중복 및 무한 배열(unbounded array) 문제를 피하기 위해 참조(referencing)를 일관되게 적용할 수 있는지 평가합니다.
나의 오답
Categories를 Products 컬렉션 내에 직접 임베드한다.
오답 분석:
Categories를 Products에 임베딩하면 데이터 중복이 발생합니다. 만약 카테고리 이름이 변경되면, 해당 카테고리에 속한 모든 제품 문서를 찾아서 업데이트해야 하므로 매우 비효율적입니다.
정답
Products 컬렉션에서 categoryId를 사용하여 Categories를 참조하고, Reviews 컬렉션에서 productId를 사용하여 Products를 참조한다.
정답 해설:
Products에서 categoryId를 사용하여 Categories를 참조하는 것이 최적입니다. 왜냐하면 카테고리는 일반적으로 많은 제품에서 쉽게 참조할 수 있는 작고 관리 가능한 양의 데이터를 포함하기 때문입니다. 마찬가지로, Reviews에서 productId를 사용하여 Products를 참조하면 리뷰가 제품과 독립적으로 증가할 수 있어 확장성을 허용하며, 크고 중첩된 문서를 피할 수 있습니다.
핵심 개념 정리
이 시나리오는 두 가지 다른 종류의 "일대다" 관계를 보여주며, 두 경우 모두 참조(Referencing)가 최적인 이유를 잘 설명합니다.
Products와 Categories (1 대 다수 - One-to-Many)
관계: 하나의 카테고리(Categories)는 여러 제품(Products)을 가질 수 있습니다.
모델링: Products 문서가 categoryId 필드를 통해 Categories를 참조합니다.
이유: 데이터 중복을 방지하고 일관성을 유지하기 위함입니다. 만약 "전자기기" 카테고리의 이름을 "가전제품"으로 바꾸고 싶을 때, Categories 컬렉션의 문서 하나만 수정하면 됩니다. 만약 임베딩했다면, 수천 개의 제품 문서를 모두 수정해야 합니다.
Products와 Reviews (1 대 무한대 - One-to-Squillions)
관계: 하나의 제품(Products)은 잠재적으로 수백만 개의 리뷰(Reviews)를 가질 수 있습니다.
모델링: Reviews 문서가 productId 필드를 통해 Products를 참조합니다. (이를 '자식 참조'라고 합니다.)
이유: 무한 배열(Unbounded Array) 안티패턴을 피하기 위함입니다. 만약 모든 리뷰를 제품 문서 안에 임베딩한다면, 리뷰가 늘어날수록 제품 문서가 계속 커져 16MB 크기 제한에 도달하거나 성능이 심각하게 저하될 수 있습니다.
올바른 스키마 예시:
Categories 컬렉션:
JSON
{ "_id": "CAT_ELEC", "name": "Electronics", "description": "..." }


Products 컬렉션:
JSON
{
  "_id": "PROD_123",
  "name": "Super Laptop",
  "price": 1200,
  "categoryId": "CAT_ELEC" // Categories 참조
}


Reviews 컬렉션:
JSON
{
  "_id": "REV_abc",
  "productId": "PROD_123", // Products 참조
  "rating": 5,
  "reviewText": "Amazing!"
}






55. 추가 개념: 동시성 - 삭제(remove)와 업데이트(update)의 경합
문제
tasks 컬렉션에 다음과 같은 문서가 있습니다.
JSON
{
  "_id": ObjectId("..."),
  "task": "Review PR",
  "status": "pending",
  "assignedTo": "alice"
}


두 개의 작업이 거의 동시에 실행됩니다.
작업 A: findAndModify({ query: { task: "Review PR", status: "pending" }, remove: true })
작업 B: findAndModify({ query: { task: "Review PR", status: "pending" }, update: { $set: { status: "completed" } }, new: true })
작업 B가 작업 A보다 약간 늦게 시작하지만, 작업 A가 완료되기 전에 시작됩니다. 두 작업이 모두 실행된 후 tasks 컬렉션의 최종 상태는 어떻게 될까요?
출제자 의도
단일 문서에 대한 쓰기 작업의 원자성과 잠금(locking) 메커니즘으로 인해, 거의 동시에 발생하는 여러 작업이 실제로는 순차적으로 처리됨을 이해하고 그 결과를 예측할 수 있는지 평가합니다.
나의 오답
status가 "completed"인 새 문서가 삽입될 것이다.
오답 분석:
findAndModify는 기본적으로 일치하는 문서를 찾지 못했을 때 새 문서를 삽입하지 않습니다. (새 문서를 삽입하는 것은 upsert: true 옵션이 있을 때의 동작입니다.) 작업 A에 의해 문서가 먼저 제거되므로, 작업 B는 쿼리 조건에 맞는 문서를 찾지 못하게 되고, 따라서 아무런 삽입이나 업데이트 작업을 수행하지 않습니다.
정답
문서는 컬렉션에서 제거될 것이다.
정답 해설:
MongoDB의 쓰기 작업은 문서 수준에서 원자적(atomic)이므로, 두 작업은 순차적으로 실행됩니다.
작업 A가 먼저 실행: 작업 A가 먼저 문서에 대한 잠금(lock)을 획득하고 query 조건에 맞는 문서를 찾습니다.
문서 삭제: remove: true 옵션에 따라 해당 문서를 컬렉션에서 영구적으로 삭제합니다.
작업 B 실행: 작업 A가 완료된 후, 작업 B가 실행되지만 query 조건({ task: "Review PR", status: "pending" })에 맞는 문서는 이미 삭제되었으므로 아무것도 찾을 수 없습니다.
아무 작업도 하지 않음: 작업 B는 업데이트할 대상을 찾지 못했으므로 아무런 작업도 수행하지 않고 종료됩니다.
결과적으로 컬렉션에는 해당 문서가 존재하지 않게 됩니다.
핵심 개념 정리
원자성과 잠금(Atomicity and Locking): 단일 문서에 대한 MongoDB의 모든 쓰기 작업은 원자적입니다. 이는 한 작업이 문서를 수정하는 동안 다른 작업은 해당 문서에 접근할 수 없도록 잠금이 걸린다는 의미입니다. 따라서 "동시에" 요청이 들어와도 실제로는 순서대로 처리됩니다.
findAndModify의 동작: 이 명령어는 query로 문서를 찾고, 그 다음 update 또는 remove를 수행합니다. 만약 query 단계에서 문서를 찾지 못하면, 후속 작업(update, remove)은 일어나지 않습니다.
remove: true: 이 옵션은 찾은 문서를 영구적으로 삭제하는 강력한 작업입니다.
new: true: 이 옵션은 명령어의 반환 값을 제어합니다.
new: false (기본값): 수정 전의 원본 문서를 반환합니다.
new: true: 수정 후의 새로운 문서를 반환합니다.
문제의 작업 B에서는 new: true가 사용되었으므로, 만약 작업 A가 없어서 B가 성공했다면, status가 'completed'로 변경된 후의 문서를 반환했을 것입니다. 하지만 작업 A 때문에 B가 대상을 찾지 못했으므로, B는 아무것도 반환하지 않습니다.
56. 추가 개념: 배열 내 문서 쿼리 ($elemMatch vs. $in)
문제
sales 컬렉션에 주문 정보가 저장되어 있습니다. items 배열 필드에 name이 'notepad'인 항목을 포함하는 모든 판매 문서를 어떻게 찾을 수 있습니까?
데이터 예시:
JSON
{
  ...
  "items": [
    { "name": "printer paper", "price": 40.01, "quantity": 2 },
    { "name": "pens", "price": 56.12, "quantity": 5 },
    { "name": "notepad", "price": 18.47, "quantity": 2 }
  ],
  ...
}


출제자 의도
배열 내부에 있는 **문서(document)**를 쿼리할 때, 단일 배열 요소가 여러 조건을 만족해야 하는 경우 사용하는 $elemMatch와, 필드 값이 주어진 목록 중 하나와 일치하는지 확인하는 $in의 차이점을 이해하고 있는지 평가합니다.
나의 오답
$in
오답 분석:
$in 연산자는 필드의 값이 지정된 배열에 있는 값 중 하나와 일치하는 문서를 찾을 때 사용됩니다. 예를 들어, storeLocation이 "Denver" 또는 "Austin"인 문서를 찾을 때 db.sales.find({ storeLocation: { $in: ["Denver", "Austin"] } }) 처럼 사용합니다. items는 객체(문서)로 이루어진 배열이므로, $in은 이 구조 내부를 검색하는 데 적합하지 않습니다.
정답
$elemMatch
정답 해설:
$elemMatch 연산자는 배열 필드 내의 요소 중 지정된 모든 기준을 동시에 만족하는 요소가 하나 이상 포함된 문서를 찾을 때 사용됩니다. 이 문제에서는 items 배열의 요소 중 name이 'notepad'인 객체가 하나라도 있는 문서를 찾아야 하므로 $elemMatch가 정확한 해결책입니다.
올바른 쿼리 구문:
JavaScript
db.sales.find({ items: { $elemMatch: { name: 'notepad' } } })


핵심 개념 정리: $elemMatch vs. 단순 점 표기법(Dot Notation)
이 특정 문제처럼 하나의 조건만으로 배열 내 문서를 찾을 때는 더 간단한 방법도 있습니다.
단순 점 표기법 (Dot Notation):
JavaScript
db.sales.find({ "items.name": "notepad" })


이 쿼리는 "items 배열 안의 어떤 요소든 name 필드가 'notepad'인 문서"를 찾아주므로, 이 문제에서는 정답과 동일한 결과를 냅니다.
$elemMatch가 반드시 필요한 경우:
두 개 이상의 조건이 배열의 '같은' 요소 내에서 충족되어야 할 때 $elemMatch는 필수적입니다.
예시: 이름이 'pens'이고 수량이 5개 이상인 항목이 포함된 주문 찾기
잘못된 쿼리 (Dot Notation):
JavaScript
db.sales.find({ "items.name": "pens", "items.quantity": { $gte: 5 } })


이 쿼리는 한 항목의 이름이 'pens'이고 다른 항목의 수량이 5 이상이어도 문서를 잘못 찾아낼 수 있습니다.
올바른 쿼리 ($elemMatch):
JavaScript
db.sales.find({ items: { $elemMatch: { name: "pens", quantity: { $gte: 5 } } } })


이 쿼리는 '동일한' 배열 요소 하나가 name이 'pens'이면서 동시에 quantity가 5 이상인 조건을 만족할 때만 문서를 정확하게 찾아냅니다.
결론: 배열 내 문서에 대해 하나의 조건만 검사할 때는 단순 점 표기법이 편리합니다. 하지만 여러 조건이 동일한 배열 요소 내에서 만족되어야 하는 복합적인 쿼리에는 반드시 $elemMatch를 사용해야 합니다.

57. 추가 개념: 배열에서 단일 값 쿼리 (Direct Match vs. $in)
문제
students 컬렉션의 각 문서는 학생이 등록한 과목 코드를 나열하는 courses라는 배열 필드를 포함합니다. 과목 코드 "CS101"에 등록한 모든 학생을 찾는 올바른 쿼리는 무엇입니까?
데이터 예시:
JSON
{ "name": "Alice", "age": 20, "courses": ["CS101", "MA203"] },
{ "name": "Bob", "age": 22, "courses": ["EE101", "PH101"] },
{ "name": "Charlie", "age": 21, "courses": ["CS101", "CS305"] }


출제자 의도
배열 필드에서 특정 단일 요소를 찾는 가장 간단하고 직접적인 방법을 알고 있는지, 그리고 $in 연산자의 올바른 구문과 용도를 이해하고 있는지 평가합니다.
나의 오답
JavaScript
db.students.find({ "courses": { $in: "CS101" } })


오답 분석:
$in 연산자는 값으로 배열을 기대합니다 (예: { $in: ["CS101"] }). $in 내부에 단일 값(스칼라 값)을 사용하는 것은 구문적으로 올바르지 않으며 오류를 발생시킵니다. 이는 $in 연산자가 여러 값을 비교하기 위한 것임을 잘못 이해했기 때문에 발생하는 실수입니다.
정답
JavaScript
db.students.find({ "courses": "CS101" })


정답 해설:
이 쿼리는 MongoDB가 스칼라 값에 대해 배열 필드를 직접 비교할 수 있기 때문에 올바릅니다. 만약 "CS101"이 문서의 courses 배열에 요소로 존재하면 해당 문서가 반환됩니다. 이는 배열 필드에서 특정 값을 쿼리하는 가장 간단하고 효과적인 방법입니다.
핵심 개념 정리
배열에 대한 직접 일치 (Direct Match on Array):
db.collection.find({ arrayField: "value" }) 구문은 arrayField 배열에 "value"가 하나의 요소로서 포함되어 있는 모든 문서를 찾습니다.
이는 "배열에 이 값이 포함되어 있는가?"를 묻는 가장 기본적인 방법입니다.
$in 연산자의 올바른 사용법:
$in은 필드의 값이 제공된 배열 안의 여러 값 중 하나와 일치하는 문서를 찾을 때 사용됩니다.
구문: db.collection.find({ field: { $in: ["valueA", "valueB", "valueC"] } })
의미: "field의 값이 'valueA' 또는 'valueB' 또는 'valueC' 중 하나와 일치하는가?"
따라서 "CS101" 또는 "MA203" 과목을 듣는 학생을 찾고 싶을 때 다음과 같이 사용합니다.
JavaScript
db.students.find({ "courses": { $in: ["CS101", "MA203"] } })




결론: 배열에서 단 하나의 특정 값을 찾을 때는 간단한 직접 일치 쿼리를 사용하고, 여러 값 중 하나라도 일치하는 것을 찾을 때 $in 연산자를 사용해야 합니다.


55. 추가 개념: 복합 인덱스와 정규식 쿼리 (Compound Index with Regex Query)
문제
artists 컬렉션에 다음과 같은 문서와 인덱스가 있습니다.
문서 예시:
JSON
{
  "_id": 5,
  "last_name": "Maurer",
  "first_name": "Alfred",
  "year_born": 1868,
  "year_died": 1932,
  "nationality": "USA"
}


인덱스:
JavaScript
db.artists.createIndex( { "last_name": 1, "nationality": 1 } )


MongoDB는 아래 쿼리를 어떻게 처리할까요?
db.artists.find( { "last_name": /^B./, "nationality": 'France' } )
출제자 의도
복합 인덱스가 있을 때, 쿼리 조건에 접두사(prefix) 기반의 정규식이 포함된 경우 MongoDB가 인덱스를 효율적으로 사용할 수 있는지(인덱스 스캔)를 이해하는지 평가합니다.
나의 오답
텍스트 인덱스 스캔 (As a text index scan).
오답 분석:
텍스트 인덱스 스캔은 전문(full-text) 검색 작업을 위해 text 타입의 인덱스를 사용할 때를 의미합니다. 주어진 예제에서는 text 인덱스가 생성되었다는 언급이 없으며, 쿼리도 $text 연산자를 사용하지 않았습니다. 정규식을 이용한 패턴 매칭과 텍스트 검색은 다른 개념입니다.
정답
인덱스 스캔 (As an index scan).
정답 해설:
제공된 쿼리 { "last_name": /^B./, "nationality": 'France' }는 인덱싱된 필드인 last_name과 nationality에 대한 검색 조건을 포함합니다. last_name 필드의 정규식 /^B./는 "B"로 시작하는 성(last name)에 대한 패턴 매칭을 나타냅니다. 쿼리는 또한 nationality 필드에 대해 'France'라는 값을 지정합니다.
인덱스가 이 두 필드를 모두 포함하고 있기 때문에, MongoDB는 인덱스를 효율적으로 활용하여 인덱스 스캔을 수행할 수 있습니다. 즉, MongoDB는 전체 컬렉션을 다 훑어보는 대신, 인덱스를 사용하여 "B"로 시작하는 성을 가진 문서들의 위치를 빠르게 찾은 다음, 그 결과 내에서 국적이 'France'인 문서를 효율적으로 필터링합니다. 이는 쿼리 성능을 크게 향상시킵니다.
핵심 개념 정리
인덱스 스캔 (Index Scan): 쿼리를 해결하기 위해 전체 컬렉션이 아닌, 인덱스만 탐색하여 필요한 문서를 찾는 효율적인 방식입니다.
컬렉션 스캔 (Collection Scan): 인덱스를 사용하지 못하고 컬렉션의 모든 문서를 하나씩 확인하는 비효율적인 방식입니다.
인덱스 사용이 가능한 정규식: /^prefix/ 와 같이 문자열의 시작 부분을 고정하는 정규식(접두사 표현식)은 인덱스를 효율적으로 사용할 수 있습니다. MongoDB는 인덱스에서 'prefix'로 시작하는 키 범위를 빠르게 찾을 수 있습니다.
인덱스 사용이 비효율적인 정규식: /substring/ (중간 문자열 검색)이나 /.+suffix$/ (접미사 검색)와 같은 정규식은 인덱스의 모든 키를 스캔해야 할 수 있어 성능상 이점이 거의 없거나 아예 인덱스를 사용하지 못할 수도 있습니다.
결론: 복합 인덱스의 첫 번째 필드에 대해 접두사 기반 정규식을 사용하면, MongoDB는 여전히 해당 인덱스를 효율적으로 활용하여 인덱스 스캔을 수행할 수 있습니다.
MongoDB 주요 데이터 모델링 패턴 가이드
MongoDB의 문서(document) 모델은 매우 유연하여 다양한 방법으로 데이터를 구조화할 수 있습니다. 어떤 패턴을 선택하느냐에 따라 애플리케이션의 성능, 확장성, 유지보수 용이성이 크게 달라집니다. 아래는 가장 중요하고 자주 사용되는 데이터 모델링 패턴들입니다.
1. 애트리뷰트 패턴 (The Attribute Pattern)
핵심 아이디어: 유사한 속성들을 키-값 쌍의 배열로 그룹화하여, 필드 이름에 있던 정보를 필드 값으로 옮깁니다.
언제 사용하는가?
제품 사양처럼 필드가 너무 많아지거나, 필드 이름 자체에 중요한 데이터가 포함될 때.
특정 속성을 기준으로 쿼리하거나 인덱싱해야 할 때.
장점: 쿼리와 인덱싱이 간결해지고, 새로운 속성이 추가되어도 스키마를 변경할 필요가 없습니다.
예시: 수많은 스펙을 가진 제품 정보
- Before (나쁜 모델):
{
  "product_id": "laptop123",
  "ram_8gb": true,
  "storage_ssd": true,
  "storage_512gb": true,
  "screen_15inch": true
}


- After (애트리뷰트 패턴 적용):
{
  "product_id": "laptop123",
  "specs": [
    { "k": "ram", "v": "8gb" },
    { "k": "storage_type", "v": "ssd" },
    { "k": "storage_size", "v": "512gb" },
    { "k": "screen_size", "v": "15inch" }
  ]
}
// 이제 db.products.find({ "specs.k": "ram", "specs.v": "8gb" }) 와 같이
// 유연한 쿼리가 가능하고, "specs.k"와 "specs.v"에 인덱스를 걸 수 있습니다.


2. 계산 패턴 (The Computed Pattern)
핵심 아이디어: 자주 필요한 계산 결과를 별도의 필드에 미리 계산하여 저장합니다.
언제 사용하는가?
읽기 작업 시 반복적으로 복잡한 계산이 필요하여 성능 저하가 발생할 때.
장점: 읽기 성능을 극대화합니다. 매번 계산할 필요 없이 저장된 값을 바로 읽으면 됩니다.
단점/주의사항: 데이터가 변경될 때마다 계산 필드도 함께 업데이트해야 하므로 쓰기 작업이 조금 더 복잡해집니다.
예시: 게시글의 댓글 수와 최신 댓글 날짜 계산
- Before (읽을 때마다 계산): 게시글을 불러올 때마다 해당 게시글의 모든 댓글을 count() 해야 함.
- After (계산 패턴 적용):
// posts 컬렉션
{
  "_id": "post1",
  "title": "My First Post",
  "comment_count": 2, // 댓글이 추가/삭제될 때마다 $inc 연산자로 업데이트
  "latest_comment_date": ISODate("...") // 댓글이 추가될 때마다 업데이트
}


3. 서브셋 패턴 (The Subset Pattern)
핵심 아이디어: 하나의 문서에 있는 방대한 데이터 중, 자주 사용하는 부분만 잘라내어 원본 문서에 남겨두고, 나머지는 별도의 문서나 컬렉션으로 분리합니다.
언제 사용하는가?
문서 크기가 16MB 제한에 가까워지거나, 자주 쓰는 데이터와 거의 쓰지 않는 데이터가 섞여 있어 메모리(Working Set) 낭비가 심할 때.
장점: 애플리케이션이 주로 사용하는 데이터만 메모리에 로드되므로 성능과 효율성이 향상됩니다.
예시: 인기 제품과 수많은 리뷰
- Before (하나의 거대한 문서):
{
  "product_id": "prod456",
  "name": "Super Camera",
  "price": 2000,
  "reviews": [ /* ... 수만 개의 리뷰 객체 ... */ ] 
}


- After (서브셋 패턴 적용):
// products 컬렉션 (자주 쓰는 핵심 정보)
{
  "product_id": "prod456",
  "name": "Super Camera",
  "price": 2000,
  "review_count": 15000,
  "recent_reviews": [ /* ... 최근 5개의 리뷰 객체 ... */ ]
}

// reviews 컬렉션 (필요할 때만 조회하는 전체 정보)
{ "review_id": "rev1", "product_id": "prod456", "text": "..." },
{ "review_id": "rev2", "product_id": "prod456", "text": "..." }
// ...


4. 버킷 패턴 (The Bucket Pattern)
핵심 아이디어: 짧은 시간 동안 대량으로 발생하는 데이터들을 개별 문서로 저장하지 않고, 시간 등의 기준으로 묶어 하나의 "버킷" 문서 안에 배열로 저장합니다.
언제 사용하는가?
IoT 센서 데이터, 실시간 로그, 분석 데이터 등 시계열(Time-series) 데이터 처리에 매우 효과적입니다.
장점: 문서의 총 개수와 인덱스의 크기를 획기적으로 줄여 쓰기 및 읽기 성능을 향상시키고, 데이터 관리를 용이하게 합니다.
예시: 1초마다 수집되는 센서 데이터
- Before (초당 1개 문서): 1시간이면 3,600개의 문서가 생성됨.
- After (버킷 패턴 적용):
// sensor_readings 컬렉션 (1시간 단위 버킷)
{
  "sensor_id": "temp01",
  "start_time": ISODate("2025-10-03T10:00:00Z"),
  "end_time": ISODate("2025-10-03T10:59:59Z"),
  "measurement_count": 3600,
  "readings": [
    { "timestamp": ISODate("...00:00:01"), "value": 25.1 },
    { "timestamp": ISODate("...00:00:02"), "value": 25.2 },
    /* ... 3600개의 측정값 ... */
  ]
}


5. 확장 참조 패턴 (The Extended Reference Pattern)
핵심 아이디어: 참조(Referencing) 관계에서, 조인($lookup) 비용을 줄이기 위해 자주 사용되는 필드를 원본 문서에 중복 저장합니다.
언제 사용하는가?
읽기 작업이 매우 빈번하여 $lookup 오버헤드를 피하고 싶을 때.
장점: 간단한 find 쿼리만으로 필요한 정보를 얻을 수 있어 읽기 성능이 향상됩니다.
단점/주의사항: 데이터가 중복되므로, 원본 데이터(예: 저자 이름)가 변경되면 중복 저장된 모든 곳을 찾아 업데이트해야 하는 부담이 있습니다.
예시: 책 정보와 저자 이름
- Before (순수 참조): 저자 이름을 보려면 항상 authors 컬렉션을 $lookup 해야 함.
- After (확장 참조 패턴 적용):
// books 컬렉션
{
  "title": "MongoDB Patterns",
  "author_id": "author789",
  "author_name": "Jane Doe" // 저자 이름 중복 저장
}

// authors 컬렉션
{ "_id": "author789", "name": "Jane Doe", "country": "USA" }


6. 스키마 버전 관리 패턴 (The Schema Versioning Pattern)
핵심 아이디어: 모든 문서에 스키마 버전을 명시하는 필드를 추가합니다.
언제 사용하는가?
애플리케이션이 발전하면서 데이터 스키마가 변경될 가능성이 있는 모든 경우.
장점: 애플리케이션 코드에서 문서의 버전을 확인하고, 구버전 스키마의 문서를 새로운 스키마로 마이그레이션하거나 호환성을 유지하는 로직을 쉽게 구현할 수 있습니다.
예시: 사용자 주소 필드 변경
- Before (구버전):
{ "name": "John", "address": "123 Main St, Anytown" }


- After (스키마 버전 관리 적용):
// v1 문서
{ "name": "John", "address": "123 Main St, Anytown", "schema_version": 1 }

// v2 문서 (주소를 구조화)
{ 
  "name": "Jane", 
  "address": { "street": "456 Oak Ave", "city": "Newville" },
  "schema_version": 2
}
// 애플리케이션은 schema_version을 보고 데이터를 적절히 처리합니다.


7. 폴리모픽 패턴 (The Polymorphic Pattern)
핵심 아이디어: 하나의 컬렉션에 서로 조금씩 다른 형태의 문서들을 함께 저장합니다. 각 문서에는 자신의 형태를 알려주는 type과 같은 필드를 포함합니다.
언제 사용하는가?
개념적으로는 유사하지만(예: '결제 수단'), 실제로는 필드가 서로 다른 다양한 유형의 데이터를 단일 컬렉션에서 관리하고 싶을 때.
장점: 여러 컬렉션을 만들 필요 없이 관련된 다양한 유형의 데이터를 한 곳에서 관리할 수 있어 애플리케이션 로직이 단순해질 수 있습니다.
예시: 다양한 결제 수단 정보
- Before (나쁜 모델): 결제 수단마다 별도의 컬렉션 생성.
// credit_cards 컬렉션
{ "user_id": "user1", "card_number": "...", "expiry": "..." }

// bank_accounts 컬렉션
{ "user_id": "user2", "account_number": "...", "bank_name": "..." }


- After (폴리모픽 패턴 적용):
// payments 컬렉션
[
  {
    "payment_method_type": "CREDIT_CARD",
    "user_id": "user1",
    "card_number": "...",
    "expiry": "..."
  },
  {
    "payment_method_type": "BANK_ACCOUNT",
    "user_id": "user2",
    "account_number": "...",
    "bank_name": "..."
  }
]
// 이제 db.payments.find({ "user_id": "user1" }) 쿼리 하나로
// 해당 유저의 모든 결제 수단을 가져올 수 있습니다.

네, 알겠습니다. 복합 인덱스를 정렬(sort)에 활용하는 규칙에 대한 문제입니다. 요청하신 대로 문서 업데이트 없이 직접 답변으로 57번 항목을 작성해 드리겠습니다.

57. 추가 개념: 복합 인덱스와 정렬 최적화 (인덱스 접두사 규칙)
문제
routes 컬렉션에 다음과 같은 복합 인덱스가 생성되어 있습니다.
인덱스:
JavaScript
db.routes.createIndex({
   "airplane": 1,
   "src_airport": 1,
   "dst_airport": 1,
   "stops": 1
})


다음 쿼리 중 이 인덱스를 정렬(sorting)에 효율적으로 사용할 수 있는 것은 무엇입니까? (2개 선택)
출제자 의도
복합 인덱스를 사용하여 쿼리의 필터링(find)과 정렬(sort)을 동시에 최적화할 때, 인덱스 필드 순서(접두사)를 반드시 지켜야 한다는 규칙을 이해하고 있는지 평가합니다.
정답 및 오답 분석
정답 쿼리
db.routes.find( { airplane: 'CNC' } ).sort( { src_airport: 1, dst_airport: 1 } )
정답 해설: 이 쿼리는 인덱스를 정렬에 완벽하게 활용합니다. find 조건이 인덱스의 첫 번째 필드(airplane)를 사용하고, sort 조건이 그 바로 다음 필드들(src_airport, dst_airport)을 인덱스 순서 그대로 따르기 때문입니다. MongoDB는 이미 airplane -> src_airport -> dst_airport 순으로 정렬된 인덱스에서 필요한 부분만 읽으면 되므로, 별도의 정렬 과정이 필요 없습니다.
db.routes.find( { airplane: 'CNC', src_airport: { $gt: 'C' } } ).sort( { src_airport: 1 } )
정답 해설: 이 쿼리 역시 인덱스를 정렬에 사용할 수 있습니다. find 조건이 인덱스의 접두사(airplane, src_airport)를 사용하고 있고, sort가 그 필드 중 하나인 src_airport를 기준으로 하기 때문입니다. MongoDB는 인덱스에서 airplane: 'CNC'인 구간을 찾은 뒤, 그 안에서 src_airport가 'C'보다 큰 부분을 스캔하는데, 이 과정 자체가 이미 src_airport 순서대로 진행되므로 효율적입니다.
오답 쿼리
db.routes.find( { airplane: 'CNC' } ).sort( { dst_airport: 1 } )
오답 분석: find 조건은 인덱스 접두사(airplane)를 잘 사용했지만, sort가 중간 필드인 src_airport를 건너뛰고 dst_airport를 기준으로 정렬하려고 합니다. 인덱스는 src_airport를 기준으로 먼저 정렬되어 있기 때문에, dst_airport 기준 정렬에는 사용할 수 없습니다. 이 경우 MongoDB는 인덱스로 문서를 찾은 후, 메모리에서 별도의 정렬 작업을 수행해야 합니다.
db.routes.find( { src_airport: 'JFK' } ).sort( { dst_airport: 1 } )
오답 분석: find 조건이 인덱스의 첫 번째 필드(접두사)인 airplane을 포함하지 않습니다. 인덱스의 선행 필드 없이 중간 필드만으로 쿼리하면 인덱스를 효율적으로 사용할 수 없으므로, 정렬에도 당연히 사용할 수 없습니다.
db.routes.find( { dst_airport: 'SFO' } ).sort( { airplane: 1 } )
오답 분석: find 조건과 sort 조건 모두 인덱스의 접두사 순서를 따르지 않습니다. 이 쿼리는 인덱스의 이점을 거의 활용하지 못하고 컬렉션 스캔에 가까운 비효율적인 작업을 수행하게 됩니다.
핵심 개념 정리
인덱스 접두사 규칙 (Index Prefix Rule): 복합 인덱스가 정렬에 사용되려면, 쿼리 조건은 다음 규칙을 따라야 합니다.
find 조건은 인덱스 필드의 접두사(prefix), 즉 처음부터 순서대로 하나 이상의 필드를 포함해야 합니다.
sort 조건은 find 조건에서 사용된 필드 바로 다음부터 인덱스에 정의된 순서를 그대로 따라야 합니다.
find 조건과 sort 조건 사이의 인덱스 필드를 건너뛸 수 없습니다.
58. 추가 개념: mongodump와 mongoexport의 차이점
문제
MongoDB 클러스터에서 BSON 형식으로 데이터를 내보내는 데 사용할 수 있는 명령어는 다음 중 무엇입니까?
출제자 의도
데이터 백업을 위한 바이너리 형식(BSON)과 데이터 상호 운용성을 위한 텍스트 형식(JSON, CSV)의 차이를 이해하고, 각 목적에 맞는 올바른 유틸리티(mongodump vs. mongoexport)를 선택할 수 있는지 평가합니다.
나의 오답
mongoexport
오답 분석:
mongoexport는 MongoDB 컬렉션의 데이터를 JSON, CSV, 또는 TSV 형식으로 내보내는 데 사용됩니다. MongoDB 클러스터에서 데이터를 내보내는 데 사용할 수는 있지만, 문제에서 요구하는 BSON 형식으로는 내보내지 않습니다.
정답
mongodump
정답 해설:
mongodump 명령어는 MongoDB 데이터베이스의 데이터를 바이너리 덤프(binary dump)로 생성하는 데 사용됩니다. 이 명령어는 MongoDB가 내부적으로 사용하는 JSON과 유사한 문서의 이진 표현인 BSON 형식으로 데이터를 내보낼 수 있습니다. 이 명령어는 MongoDB 클러스터에서 데이터를 백업하거나 이전하는 데 적합합니다.
핵심 개념 정리
mongodump와 mongoexport는 둘 다 데이터를 내보내는 도구이지만, 그 목적과 출력 형식이 완전히 다릅니다.
구분
mongodump
mongoexport
주요 목적
백업 및 복원 (Backup & Restore)
데이터 상호 운용 (Data Interchange)
출력 형식
BSON (Binary JSON)
JSON, CSV, TSV (Human-readable text)
데이터 충실도
높음. 모든 MongoDB 데이터 타입(ObjectId, Date 등)이 완벽하게 보존됨.
낮을 수 있음. 확장 JSON 형식으로 표현되지만, 다른 시스템으로 가져갈 때 타입 정보가 유실될 수 있음.
복원 도구
mongorestore
mongoimport
사용 시나리오
- 데이터베이스 전체/컬렉션 백업 - 다른 MongoDB 서버로 데이터 마이그레이션 - 재해 복구
- 다른 프로그램(Excel, R, Python)에서 분석 - JSON API로 데이터 전송 - 사람이 읽을 수 있는 데이터 생성

결론: MongoDB 시스템 간의 완전한 백업이나 데이터 이전을 원할 때는 BSON 형식을 사용하는 **mongodump**를, 다른 시스템과의 연동이나 사람이 읽을 수 있는 데이터가 필요할 때는 JSON/CSV 형식을 사용하는 **mongoexport**를 사용해야 합니다.
59. 추가 개념: 임베디드 문서 쿼리 (Dot Notation vs. 전체 문서 매칭)
문제
orders 컬렉션에서 각 문서는 name과 email 필드를 가진 customer라는 임베디드 문서를 포함합니다. 다음 조건을 만족하는 주문을 삭제해야 합니다.
orderId는 67890
customer.name은 John Doe
customer.email은 john.doe@example.com
이 문서를 올바르게 삭제하는 deleteOne 표현식은 무엇입니까?
출제자 의도
임베디드 문서 내부의 특정 필드를 쿼리할 때, 유연하고 정확한 '점 표기법(dot notation)'과, 전체 구조가 일치해야만 하는 '전체 문서 매칭'의 차이점을 이해하고 올바른 방법을 선택할 수 있는지 평가합니다.
나의 오답
JavaScript
db.orders.deleteOne({ 
  "orderId": 67890, 
  "customer": { "name": "John Doe", "email": "john.doe@example.com" } 
})


오답 분석:
이 표현식은 customer 임베디드 문서 전체를 하나의 단위로 매칭하려고 시도합니다. MongoDB에서 임베디드 문서를 이런 식으로 매칭하는 것은 매우 엄격합니다. 즉, 데이터베이스에 저장된 customer 문서가 쿼리에 명시된 { "name": ..., "email": ... } 구조와 정확히 일치해야만 합니다. 만약 실제 문서에 phone과 같은 추가 필드가 있거나, 필드의 순서가 다르면 이 쿼리는 문서를 찾지 못해 삭제에 실패할 수 있습니다.
정답
JavaScript
db.orders.deleteOne({ 
  orderId: 67890, 
  "customer.name": "John Doe", 
  "customer.email": "john.doe@example.com" 
})


정답 해설:
이 표현식은 **점 표기법(dot notation)**을 사용하여 customer 임베디드 문서 내의 개별 필드(name, email)에 직접 접근하고 값을 비교합니다. 이 방법은 customer 문서에 다른 추가 필드가 있거나 필드 순서가 달라도 상관없이, orderId, customer.name, customer.email 값이 모두 일치하기만 하면 문서를 정확하게 찾아냅니다. 이것이 원하는 문서를 삭제하는 데 가장 정확하고 안전한 방법입니다.
핵심 개념 정리: 쿼리 방식 비교
구분
전체 문서 매칭 (Whole Document Match)
점 표기법 (Dot Notation)
방식
{ "customer": { "name": "John", ... } }
{ "customer.name": "John", ... }
동작
customer 문서의 구조와 내용 전체가 정확히 일치해야 함.
customer 문서 내부의 특정 필드 값만 개별적으로 비교함.
특징
엄격함. 추가 필드나 다른 필드 순서에 민감함.
유연함. 다른 필드의 존재나 순서에 영향을 받지 않음.
추천
거의 사용되지 않음. 정확히 일치하는 구조를 찾아야 하는 매우 특수한 경우에만 사용.
표준 방식. 임베디드 문서 내부의 특정 필드를 조회할 때 항상 권장됨.

결론: 임베디드 문서 내부의 특정 필드 값을 조회할 때는 점 표기법(dot notation)을 사용하는 것이 표준이며 가장 안전하고 예측 가능한 방법입니다.
59. 추가 개념: 인과적 일관성과 읽기 관심 수준 (Causal Consistency & Read Concern)
문제
MongoDB를 사용하는 애플리케이션에서 사용자 세션을 유지 관리하고 있습니다. 네트워크 파티션이나 레플리카 셋 재선거가 발생하는 경우에도 세션 데이터를 읽을 때 세션의 일관성을 보장해야 합니다. 이 요구사항을 충족하기 위해 MongoDB의 인과적 일관성(Causal Consistency)을 사용하기로 결정했습니다. 세션 일관성을 보장하기 위해 인과적 일관성과 함께 사용해야 하는 읽기 관심 수준(read concern level)은 다음 중 무엇입니까?
출제자 의도
"내가 쓴 내용은 내가 반드시 읽을 수 있어야 한다"는 인과적 일관성의 개념을 이해하고, 이를 보장하기 위한 읽기 관심 수준의 역할을, 특히 데이터 롤백 방지("majority")와 특정 시점 보장("snapshot")의 차이점을 구분할 수 있는지 평가합니다.
나의 오답
"majority"
오답 분석: "majority" 읽기 관심 수준은 반환된 데이터가 레플리카 셋 멤버의 과반수에 의해 확인되었음을 보장합니다. 이는 일반적인 상황에서 데이터가 롤백되지 않을 것을 보장하지만, 세션 일관성 자체를 제공하지는 않습니다. 예를 들어, 클라이언트가 쓰기 작업을 한 직후, 아직 해당 쓰기 내용이 복제되지 않은 다른 보조(Secondary) 노드에서 데이터를 읽게 되면, 클라이언트는 방금 자신이 쓴 내용을 보지 못하는 현상이 발생할 수 있습니다. "majority"는 이 현상을 막아주지 못합니다.
정답
"snapshot"
정답 해설: "snapshot" 읽기 관심 수준은 인과적 일관성과 함께 사용될 때 데이터에 대한 일관된 뷰를 제공하여, 항상 동일한 데이터 스냅샷에서 읽기가 수행되도록 보장합니다. 이는 세션 일관성이 필요한 애플리케이션에 이상적입니다.
핵심 개념 정리
인과적 일관성 (Causal Consistency): 클라이언트 세션 내에서 작업의 순서를 논리적으로 보장하는 기능입니다. 간단히 말해, **"내가 A를 쓰고 B를 썼다면, B를 읽는 다른 작업은 반드시 A도 읽을 수 있어야 한다"**는 원칙을 지켜줍니다. 이는 클라이언트 세션이 시간을 거슬러 올라가는 것처럼 느껴지는 현상을 방지합니다.
읽기 관심 수준 "majority": 데이터의 **내구성(durability)**에 초점을 맞춥니다. 과반수 노드에 커밋된 데이터만 읽어옴으로써, 주(Primary) 노드가 다운되어도 롤백되지 않을 데이터임을 보장받고 싶을 때 사용합니다.
읽기 관심 수준 "snapshot": 데이터의 **격리성(isolation)**에 초점을 맞춥니다. 다중 문서 트랜잭션 내에서 사용될 때, 트랜잭션 내의 모든 읽기 작업이 트랜잭션 시작 시점의 특정 시점 스냅샷을 기준으로 데이터를 보도록 보장합니다. 즉, 트랜잭션이 진행되는 동안 다른 클라이언트가 데이터를 변경하더라도, 현재 트랜잭션은 그 변화를 보지 않고 일관된 "데이터 우주"에서 작업을 수행하게 됩니다.
왜 "snapshot"이 정답인가? 인과적 일관성은 작업의 순서를 보장하고, "snapshot"은 특정 시점의 데이터를 고정시킵니다. 이 둘이 결합될 때 가장 강력한 형태의 세션 일관성이 보장됩니다. 클라이언트는 자신이 쓴 내용을 순서대로 볼 수 있을 뿐만 아니라, 트랜잭션이 진행되는 동안 외부의 변화에 전혀 영향을 받지 않는 완벽하게 격리된 데이터 뷰를 얻게 됩니다. 이는 복잡한 비즈니스 로직에서 데이터가 여러 번 읽히더라도 항상 동일한 상태를 유지해야 하는 경우에 필수적입니다.
60. 추가 개념: 데이터 모델링 - 관계의 종류에 따른 전략 선택
문제
블로그 플랫폼을 위한 MongoDB 데이터베이스를 설계하고 있습니다. 시스템은 Users, Posts, Comments 컬렉션을 관리합니다. 주어진 시나리오에서, 제안된 데이터 모델의 안티패턴(anti-pattern)을 가장 잘 나타내는 설명은 무엇입니까?
컬렉션 구조:
Users: 사용자 정보
Posts: 게시물 정보, 작성자 참조(user_id) 포함
Comments: 댓글 정보, 게시물 참조(post_id)와 사용자 참조(user_id) 포함
출제자 의도
서로 다른 종류의 '일대다' 관계(1:N)를 구별하고, 데이터 중복 문제와 무한 배열(Unbounded Array) 문제를 피하기 위해 각각에 맞는 올바른 모델링 전략(참조 또는 임베딩)을 선택할 수 있는지 평가합니다.
나의 오답
Posts 컬렉션은 각 게시물에 작성자 정보를 표시할 때 추가적인 조회를 피하기 위해 Users 컬렉션을 임베드해야 한다.
오답 분석: Users 컬렉션(작성자 정보)을 Posts 컬렉션 내에 임베딩하면, 한 명의 사용자가 여러 개의 게시물을 작성할 경우 심각한 데이터 중복이 발생합니다. 예를 들어, 사용자가 자신의 프로필 소개(bio)를 변경하면, 그가 작성한 모든 게시물 문서를 일일이 찾아서 임베딩된 bio를 수정해야 합니다. 이는 매우 비효율적이고 데이터 불일치를 유발할 수 있으므로, Posts 문서에 사용자의 _id를 참조로 저장하는 것이 훨씬 더 나은 방법입니다.
정답
Posts 컬렉션은 시간이 지남에 따라 댓글이 임베딩될 경우 거대한 게시물 문서를 유발할 수 있으므로, 참조를 사용하여 Comments 컬렉션에 연결해야 한다.
정답 해설: Posts를 Comments에 참조로 연결하는 것이 올바른 접근 방식입니다. 왜냐하면 댓글은 시간이 지남에 따라 계속 누적될 수 있으며, 만약 댓글을 게시물 문서에 모두 임베딩한다면 게시물 문서가 지나치게 커질 수 있기 때문입니다. 참조를 사용함으로써 데이터는 정규화된 상태를 유지하고, 더 많은 댓글이 추가되어도 게시물 문서가 과도하게 커지는 것을 방지할 수 있습니다.
핵심 개념 정리: 두 가지 '참조'의 다른 이유
이 문제에서는 Posts -> Users 관계와 Posts -> Comments 관계 모두 **참조(Linking/Referencing)**를 사용하는 것이 최선이지만, 그 이유는 다릅니다.
Posts가 Users를 참조하는 이유: 데이터 중복 및 일관성 문제 방지
관계: 한 명의 사용자(One)가 여러 개의 게시물(Many)을 작성합니다.
모델링: 자식(Posts)이 부모(Users)를 참조합니다 ({ "user_id": ... }).
주된 이유: 만약 부모(Users) 정보를 자식(Posts)에 임베딩하면, 사용자 정보가 그가 쓴 모든 게시물에 중복되어 저장됩니다. 사용자 이름이나 프로필이 변경될 때 모든 게시물을 수정해야 하는 큰 문제가 발생합니다. 따라서 데이터의 일관성과 정규화를 위해 참조를 사용합니다.
Posts가 Comments를 참조하는 이유: 무한 배열(Unbounded Array) 문제 방지
관계: 하나의 게시물(One)에 여러 개의 댓글(Many, 잠재적으로 수만 개)이 달릴 수 있습니다. (One-to-Squillions)
모델링: 자식(Comments)이 부모(Posts)를 참조합니다 ({ "post_id": ... }).
주된 이유: 만약 자식(Comments)을 부모(Posts)에 임베딩하면, 댓글이 달릴 때마다 게시물 문서 내의 댓글 배열이 계속 커집니다. 이는 문서 크기를 비대하게 만들어 성능을 저하시키고, 결국 16MB 문서 크기 제한에 도달하게 만드는 '무한 배열 안티패턴'을 유발합니다. 확장성을 위해 참조를 사용합니다.
올바른 스키마 요약:
Users 컬렉션: 사용자 정보의 원본.
Posts 컬렉션: user_id를 통해 Users를 참조.
Comments 컬렉션: post_id를 통해 Posts를, user_id를 통해 Users를 각각 참조.
결론: 데이터 모델링 시 단순히 "일대다" 관계로 판단하는 것을 넘어, "다(Many)"에 해당하는 쪽이 얼마나 커질 수 있는지, 그리고 데이터가 얼마나 자주 변경되는지를 고려하여 임베딩할지 참조할지를 결정해야 합니다.
60. 추가 개념: 배열 내 객체 쿼리 - 여러 조건의 결합 ($elemMatch)
문제
orders 컬렉션에는 items라는 객체 배열 필드가 있습니다. items 배열 내의 항목 중 price가 $1000를 초과하고 동시에 quantity가 1인 항목이 하나 이상 포함된 모든 주문을 찾는 올바른 쿼리는 무엇입니까?
데이터 예시:
JSON
{
  "customerName": "Jane Doe",
  "items": [
    { "product": "Laptop", "price": 1200, "quantity": 1 },
    { "product": "Mouse", "price": 25, "quantity": 2 }
  ]
}

출제자 의도
배열 내 단일 객체가 여러 조건을 동시에 만족해야 하는 경우, 점 표기법의 한계를 이해하고 $elemMatch를 올바르게 사용할 수 있는지 평가합니다.
나의 오답
JavaScript
db.orders.find({ "items.price": { $gt: 1000 }, "items.quantity": 1 })

오답 분석: 이 쿼리는 $elemMatch를 사용하지 않았습니다. 이 경우 MongoDB는 items.price 조건과 items.quantity 조건을 독립적으로 취급합니다. 즉, 쿼리는 "이 주문의 items 배열 안에 가격이 $1000를 넘는 상품이 하나라도 있고, 그리고 (별개로) 수량이 1인 상품이 하나라도 있는가?" 라고 묻는 것과 같습니다. 두 조건이 같은 상품에 적용되어야 한다는 요구사항을 충족시키지 못합니다.
예를 들어, 아래와 같은 문서는 잘못 검색됩니다.
JSON
// 이 문서는 '나의 오답' 쿼리에 의해 잘못 선택됩니다.
{
  "customerName": "Wrong Match",
  "items": [
    { "product": "Super Monitor", "price": 1500, "quantity": 2 }, // 가격 조건은 여기서 충족
    { "product": "Keyboard", "price": 100, "quantity": 1 }      // 수량 조건은 여기서 충족
  ]
}

위 문서에는 가격이 1000을 넘으면서 동시에 수량이 1인 상품은 없지만, '나의 오답' 쿼리는 이 문서를 결과에 포함시킵니다.
정답
JavaScript
db.orders.find({ "items": { $elemMatch: { "price": { $gt: 1000 }, "quantity": 1 } } })

정답 해설: 이 쿼리는 $elemMatch를 올바르게 사용하여, items 배열의 요소 중 price가 $1000보다 크고 동시에 quantity가 1인 항목이 하나 이상 있는 문서를 찾습니다. $elemMatch\ 연산자는 배열 내의 동일한 하위 문서(sub-document) 안에서 두 조건이 모두 충족되어야 함을 보장하며, 이것이 바로 이 시나리오에서 요구하는 정확한 동작입니다.
핵심 개념 정리
점 표기법 (Dot Notation)의 한계: 여러 조건을 점 표기법으로 나열하면, 각 조건이 배열 내의 서로 다른 요소에서 충족되어도 전체 문서는 참으로 간주될 수 있습니다.
$elemMatch의 역할: $elemMatch는 제공된 모든 쿼리 조건이 배열 내의 단일 요소(객체) 하나에서 모두 만족될 때만 해당 문서를 반환하도록 보장합니다.
결론: 배열 내 객체를 쿼리할 때, 여러 조건이 반드시 동일한 객체 내에서 충족되어야 한다면, 그때는 반드시 $elemMatch를 사용해야 합니다. 조건이 하나일 경우에는 간단한 점 표기법을 사용해도 됩니다.


네, 이 문제는 배열 필드에 unique 인덱스를 적용할 때의 동작 방식을 정확히 이해하는 것이 핵심입니다. 단순히 unique: true 옵션을 추가하는 것 이상의 의미가 있습니다. 61번 항목으로 정리해 드리겠습니다.

61. 추가 개념: 배열에 대한 고유 인덱스 (Unique Index on Arrays)
문제
students 컬렉션이 있습니다. 각 학생이 정확히 동일한 과목 조합을 갖는 것을 방지하기 위해 subjects 배열 필드에 고유 인덱스를 생성하려고 합니다. 어떤 MongoDB 작업을 사용해야 할까요?
데이터 예시:
JSON
{ "_id": 1, "name": "Alice", "subjects": ["Math", "Physics"] },
{ "_id": 2, "name": "Bob", "subjects": ["Math", "Computer Science"] }


출제자 의도
배열 필드에 unique: true 옵션을 사용하여 인덱스를 생성하는 방법을 알고 있는지, 그리고 이 인덱스가 어떻게 동작하는지(멀티키 인덱스) 이해하고 있는지 평가합니다.
나의 오답
db.students.createIndex({subjects: 1})
오답 분석:
이 작업은 subjects 배열 필드에 인덱스를 생성하지만, 여기에는 고유성(uniqueness)을 강제하는 옵션이 빠져 있습니다. 문제의 요구사항은 '중복된 조합'을 막는 것이므로, 이 인덱스로는 목적을 달성할 수 없습니다.
정답
db.students.createIndex({subjects: 1}, {unique: true})
정답 해설:
createIndex 작업은 MongoDB에서 인덱스를 생성하는 데 사용되며, {unique: true} 옵션은 subjects 배열 필드에 대한 고유성을 강제합니다.
심층 분석: 배열에 대한 unique 인덱스는 어떻게 동작하는가?
이 부분이 매우 중요합니다. 배열에 unique 인덱스를 생성하면, MongoDB는 **멀티키 인덱스(Multikey Index)**를 만듭니다. 이는 배열의 **각 요소(element)**에 대해 개별적인 인덱스 키를 생성한다는 의미입니다.
그리고 unique: true 제약 조건은 이 개별적인 인덱스 키 각각에 대해 적용됩니다.
즉, 이 인덱스는 "두 명의 학생이 정확히 동일한 과목 조합을 가질 수 없다"를 보장하는 것이 아니라, "두 명의 학생이 단 하나의 과목이라도 겹치는 것을 허용하지 않는다"는 훨씬 더 강력한 규칙을 강제합니다.
예시로 보는 동작 방식
1. 인덱스 생성:
JavaScript
db.students.createIndex({ subjects: 1 }, { unique: true })


2. 데이터 삽입 시도:
JavaScript
// Alice 삽입 (성공)
db.students.insertOne({ name: "Alice", subjects: ["Math", "Physics"] })
// MongoDB는 "Math"와 "Physics"에 대한 인덱스 키를 생성합니다.

// Bob 삽입 (실패!)
db.students.insertOne({ name: "Bob", subjects: ["Math", "Computer Science"] })


3. 결과:
Bob의 문서는 삽입되지 않고 **중복 키 오류(duplicate key error)**가 발생합니다. 왜냐하면 Bob의 subjects 배열에 있는 "Math"가 Alice의 subjects 배열에 이미 존재하여, "Math"라는 인덱스 키가 중복되기 때문입니다.
그렇다면 "정확히 동일한 조합"을 막으려면 어떻게 해야 할까?
이 문제의 원래 의도("정확히 동일한 조합 방지")를 달성하려면, MongoDB만으로는 부족하고 애플리케이션 로직이 함께 사용되어야 합니다.
해결책: 배열을 항상 정렬하여 저장하기
애플리케이션 코드: 학생 문서를 데이터베이스에 저장하기 전에, subjects 배열을 항상 알파벳순으로 정렬합니다.
["Physics", "Math"] -> ["Math", "Physics"]
["Math", "Physics"] -> ["Math", "Physics"]
MongoDB 인덱스: 그리고 나서 db.students.createIndex({ subjects: 1 }, { unique: true }) 인덱스를 사용합니다.
이제 unique 인덱스는 배열 전체를 하나의 값으로 보고 고유성을 비교하게 됩니다.
수정된 로직으로 데이터 삽입 시도:
JavaScript
// Alice 저장 (정렬 후) -> ["Math", "Physics"] (성공)
db.students.insertOne({ name: "Alice", subjects: ["Math", "Physics"] })

// David 저장 (정렬 후) -> ["Chemistry", "Physics"] (성공)
db.students.insertOne({ name: "David", subjects: ["Chemistry", "Physics"] })

// Eve 저장 (정렬 후) -> ["Math", "Physics"] (실패!)
db.students.insertOne({ name: "Eve", subjects: ["Math", "Physics"] }) 


Eve의 subjects 배열 ["Math", "Physics"]는 Alice의 배열과 완전히 동일하므로, 이제 고유 인덱스 제약 조건에 의해 삽입이 올바르게 거부됩니다.
핵심 개념 정리
인덱스 유형
db.students.createIndex({ subjects: 1 }, { unique: true })
동작 방식
멀티키 인덱스(Multikey Index)
고유성 강제 대상
배열의 각 개별 요소(element)
결과
하나의 과목이라도 중복되면 삽입 실패
"조합"의 고유성 보장
불가능 (애플리케이션에서 배열 정렬 로직 추가 필요)


네, 이 문제는 $lookup집계 단계의 가장 중요하고 기본적인 동작 원칙에 대한 것입니다. 많은 개발자들이 처음$lookup을 사용할 때 하는 흔한 실수이기도 합니다.
결과가 왜 항상 배열이어야 하는지, 그 이유와 함께 62번 항목으로 정리해 드리겠습니다.

62. 추가 개념: $lookup의 결과는 항상 배열(Array)이다
문제
orders 컬렉션과 customers 컬렉션이 있습니다. orders 컬렉션에서 집계 쿼리를 시작하여, customer_id를 기준으로 customers 컬렉션의 정보를 customer_details라는 필드로 가져오려고 합니다.
$lookup 쿼리:
JavaScript
db.orders.aggregate([
    {
        $lookup: {
            from: "customers",
            localField: "customer_id",
            foreignField: "customer_id",
            as: "customer_details"
        }
    }
])


이 집계 쿼리가 반환하는 문서의 구조는 무엇일까요?
출제자 의도
$lookup 집계 단계의 출력 형식이, 일치하는 문서가 단 하나일 때라도 항상 배열이라는 점을 이해하고 있는지 평가합니다.
나의 오답
customer_details 필드가 단일 객체(embedded document)일 것이라고 예상했습니다.
JSON
{
    ...,
    "customer_details": { // <-- 배열이 아닌 객체
        "_id": ObjectId("..."),
        "customer_id": 1,
        "name": "John Doe",
        ...
    }
}


오답 분석:
customer_details가 임베디드 문서가 아닌 배열로 표시됩니다. $lookup 단계는 일치하는 문서가 하나만 있더라도 항상 배열을 반환합니다.
정답
customer_details 필드는 일치하는 고객 문서가 하나만 담긴 배열이 됩니다.
JSON
{
    ...,
    "customer_details": [ // <-- 항상 배열
        {
            "_id": ObjectId("..."),
            "customer_id": 1,
            "name": "John Doe",
            ...
        }
    ]
}


정답 해설:
$lookup 단계는 SQL의 LEFT OUTER JOIN과 유사하게 동작하며, as 필드에 지정된 이름으로 customers 컬렉션에서 일치하는 문서들의 배열을 반환합니다. customer_id가 일치하므로, 출력은 일치하는 고객 문서 하나를 포함하는 배열이 됩니다.
핵심 개념 정리: 왜 항상 배열일까?
$lookup의 결과 필드(as로 지정된 필드)는 일치하는 문서의 수에 관계없이 **항상 배열(array)**입니다. 그 이유는 일관성과 유연성 때문입니다.
from 컬렉션에서 localField와 foreignField가 일치하는 문서는 다음과 같은 세 가지 경우가 있을 수 있습니다.
일치하는 문서가 1개인 경우 (이 문제의 경우):
결과: [ { ... } ] (요소가 하나인 배열)
일치하는 문서가 여러 개인 경우:
결과: [ { ... }, { ... }, ... ] (요소가 여러 개인 배열)
일치하는 문서가 없는 경우:
결과: [] (빈 배열)
MongoDB는 이 모든 경우를 일관되게 처리하기 위해 결과 타입을 항상 '배열'로 고정합니다. 이렇게 하면 애플리케이션 개발자는 $lookup 결과가 항상 배열이라고 가정하고 코드를 작성할 수 있어 훨씬 편리합니다.
팁: 배열에서 객체만 꺼내고 싶다면?
만약 조인 결과가 항상 1개이거나, 1개만 필요해서 배열이 아닌 객체로 만들고 싶다면, $lookup 바로 다음에 $unwind 또는 $arrayElemAt 단계를 추가할 수 있습니다.
1. $unwind 사용:
JavaScript
// ... $lookup 단계 이후 ...
{ $unwind: "$customer_details" } 
// customer_details 배열을 "풀어서" 하위 문서로 만듭니다.
// 단점: 일치하는 문서가 없으면(빈 배열이면) 해당 주문 문서 전체가 결과에서 사라집니다.


2. $arrayElemAt 사용 (더 안전한 방법):
JavaScript
// ... $lookup 단계 이후 ...
{
  $addFields: {
    customer_details: { $arrayElemAt: [ "$customer_details", 0 ] }
  }
}
// customer_details 배열의 0번째 요소(첫 번째 객체)를 꺼내서 덮어씁니다.
// 장점: 일치하는 문서가 없어도 주문 문서는 사라지지 않고, customer_details 필드가 null이 됩니다.




63. 추가 개념: 집계 결과 저장 ($out vs. $merge)
문제
orders 컬렉션의 데이터를 집계하여 고객별 총매출을 계산한 후, 그 결과를 이미 존재하는 customer_sales 컬렉션에 저장하려고 합니다. $out 단계를 사용한 집계 파이프라인을 실행하면 customer_sales 컬렉션의 최종 상태는 어떻게 될까요?
집계 파이프라인:
JavaScript
db.orders.aggregate([
    {
        $group: {
            _id: "$customer_id",
            total_spent: { $sum: "$order_total" }
        }
    },
    {
        $out: "customer_sales"
    }
])

출제자 의도
집계 결과를 컬렉션에 쓸 때, 파괴적인(destructive) 덮어쓰기 작업을 수행하는 $out의 동작을 정확히 이해하고 있는지, 그리고 이를 데이터를 보존하는 다른 방식과 구분할 수 있는지 평가합니다.
나의 오답
customer_sales 컬렉션에는 각 고객에 대한 집계 데이터가 포함될 것이며, 기존 데이터는 보존될 것이다.
오답 분석: $out은 기존 데이터를 보존하지 않습니다. 이 단계는 집계 결과로 대상 컬렉션 전체를 **교체(replace)**합니다.
정답
customer_sales 컬렉션은 새로운 집계 결과로 덮어쓰여지고, 모든 기존 데이터는 삭제될 것이다.
정답 해설: $out 단계가 사용되면, 대상 컬렉션(이 경우 customer_sales)을 완전히 덮어씁니다. customer_sales에 있던 기존 문서들은 모두 삭제되고, 컬렉션은 새로운 집계 결과로 대체됩니다.
핵심 개념 정리: $out vs. $merge
$out의 파괴적인 동작 때문에, 최신 MongoDB 버전에서는 더 유연하고 안전한 $merge 단계가 도입되었습니다. 두 단계의 차이점을 이해하는 것이 매우 중요합니다.
구분
$out
$merge
동작 방식
덮어쓰기 (Overwrite/Replace)
병합 및 업데이트 (Merge/Update)
기존 데이터
모두 삭제됨
보존, 업데이트 또는 병합 가능
인덱스
기존 인덱스는 유지됨
기존 인덱스는 유지됨
주요 사용 사례
- 임시 집계 결과 저장 - 스냅샷 생성 - 기존 데이터를 완전히 버려도 될 때
- 기존 데이터에 새로운 집계 결과 추가/업데이트 - 데이터 증분 업데이트 - 변경 데이터 캡처(CDC)

Sheets로 내보내기

Shutterstock
$out: "철거 후 재건축"
$out은 대상 컬렉션이라는 **"기존 건물을 완전히 허물고, 집계 결과라는 새 건물"**을 짓는 것과 같습니다. 이전 건물의 흔적은 남지 않습니다.
$out 사용 시 customer_sales의 변화:
실행 전: { "_id": "old_customer", "total_spent": 50 }
실행 후: { "_id": 1, "total_spent": 250 }, { "_id": ..., ... } (old_customer 데이터는 사라짐)
$merge: "리모델링 또는 증축"
$merge는 대상 컬렉션이라는 **"기존 건물을 유지하면서, 집계 결과를 가지고 리모델링하거나 새로운 부분을 증축"**하는 것과 같습니다. 기존 구조를 활용하고 변경이 필요한 부분만 수정합니다.
$merge를 사용한 쿼리 예시:
JavaScript
db.orders.aggregate([
    {
        $group: {
            _id: "$customer_id",
            total_spent: { $sum: "$order_total" }
        }
    },
    {
        $merge: {
            into: "customer_sales", // 대상 컬렉션
            on: "_id",              // 문서를 식별할 기준 필드
            whenMatched: "replace", // 일치하는 문서가 있으면 덮어쓰기
            whenNotMatched: "insert"// 일치하는 문서가 없으면 새로 삽입
        }
    }
])

$merge 사용 시 customer_sales의 변화:
실행 전: { "_id": "old_customer", "total_spent": 50 }
실행 후: { "_id": "old_customer", "total_spent": 50 }, { "_id": 1, "total_spent": 250 }, ... (old_customer 데이터 보존됨)
결론: 집계 결과를 저장할 때, 기존 데이터를 완전히 무시하고 새로 만들고 싶다면 $out을 사용합니다. 하지만 기존 데이터와 새로운 집계 결과를 병합하거나 업데이트해야 한다면, 훨씬 더 유연하고 안전한 **$merge**를 사용해야 합니다.


네, 이 문제는 MongoDB에서 데이터의 무결성을 보장하는 두 가지 중요한 기능, 즉 **스키마 유효성 검사(Schema Validation)**와 **고유 인덱스(Unique Index)**의 역할을 정확히 구분할 수 있는지를 묻는 좋은 질문입니다. 두 기능은 종종 함께 사용되지만, 목적이 완전히 다릅니다.
64번 항목으로 정리해 드리겠습니다.

64. 추가 개념: 스키마 유효성 검사 vs. 고유 인덱스 (Schema Validation vs. Unique Index)
문제
MongoDB에서 스키마 유효성 검사와 관련된 MongoDB 개발자의 일반적인 작업을 정확하게 설명하는 문장은 무엇입니까?
출제자 의도
단일 문서의 구조와 형식을 검사하는 '스키마 유효성 검사'와, 컬렉션 전체에 걸쳐 필드 값의 중복을 막는 '고유 인덱스'의 역할을 명확히 구분할 수 있는지 평가합니다.
나의 오답
스키마 유효성 검사는 컬렉션의 모든 문서에 걸쳐 특정 필드의 고유성을 보장한다.
오답 분석: 컬렉션 전체에 걸친 필드의 고유성(uniqueness)을 보장하는 것은 **고유 인덱스(unique index)**의 역할입니다. 스키마 유효성 검사는 개별 문서의 구조가 규칙에 맞는지를 검사할 뿐, 다른 문서와 값을 비교하지는 않습니다.
정답
스키마 유효성 검사는 문서 내에 필수 필드의 존재 여부와 해당 필드의 데이터 타입을 보장한다.
정답 해설: MongoDB의 스키마 유효성 검사는 개발자가 규칙을 정의하여, 문서가 저장되거나 업데이트될 때 필수 필드가 존재하는지, 그리고 각 필드의 값이 지정된 데이터 타입(예: 문자열, 숫자, 배열)을 따르는지 등을 강제할 수 있도록 합니다.
핵심 개념 정리: "설계도 검사" vs. "주민등록번호 중복 확인"
두 기능의 역할을 건물과 입주자에 비유하면 쉽게 이해할 수 있습니다.
구분
스키마 유효성 검사 (Schema Validation)
고유 인덱스 (Unique Index)
비유
건축 설계도(Blueprint) 검사
전체 입주자 명부에서 주민등록번호 중복 확인
주요 목적
문서 구조의 일관성 유지
필드 값의 고유성 보장
적용 범위
단일 문서 (Single Document)
컬렉션 전체 (Entire Collection)
검사 내용
- 이 필드가 꼭 있어야 하는가? (required) - 이 필드는 숫자 타입이 맞는가? (bsonType) - 이 값은 0보다 큰가? (minimum)
- 이 email 값을 가진 다른 사람이 이미 있는가?
설정 방법
db.runCommand({ collMod: ..., validator: { $jsonSchema: ... } })
db.collection.createIndex({ field: 1 }, { unique: true })

Sheets로 내보내기
예시로 보는 동작 방식
users 컬렉션에 다음과 같은 규칙을 적용한다고 가정해 봅시다.
스키마 유효성 규칙: 모든 문서는 반드시 문자열 타입의 username과 email 필드를 가져야 한다.
고유 인덱스 규칙: email 필드의 값은 컬렉션 전체에서 유일해야 한다.
설정:
JavaScript
// 스키마 유효성 검사 설정
db.runCommand({
  collMod: "users",
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: [ "username", "email" ],
      properties: {
        username: { bsonType: "string" },
        email: { bsonType: "string" }
      }
    }
  }
})

// 고유 인덱스 생성
db.users.createIndex({ email: 1 }, { unique: true })

데이터 삽입 시도:
정상적인 문서: db.users.insertOne({ username: "Alice", email: "alice@example.com" }) -> 성공: 스키마 규칙을 만족하고, 이메일이 중복되지 않았습니다.
스키마 유효성 검사 실패: db.users.insertOne({ username: "Bob" }) // email 필드가 없음 -> 실패: "Document failed validation" 오류가 발생합니다. 스키마 규칙(설계도)을 위반했기 때문입니다.
고유 인덱스 실패: db.users.insertOne({ username: "Charlie", email: "alice@example.com" }) // email 중복 -> 실패: "E11000 duplicate key error" 오류가 발생합니다. 다른 문서와 email 값이 중복되었기 때문입니다.
결론: 스키마 유효성 검사는 **"문서가 올바른 양식인가?"**를 검사하고, 고유 인덱스는 **"이 값이 이미 사용되었는가?"**를 검사하는, 서로 다른 차원의 데이터 무결성 도구입니다.


네, 이 문제는 배열 안에 포함된 여러 객체(임베디드 문서) 중 특정한 하나를 골라서 업데이트할 때 사용하는 **위치 연산자($)**의 역할을 이해하는 데 매우 중요한 예시입니다. 많은 개발자들이 이 개념에서 어려움을 겪곤 합니다.

65. 추가 개념: 배열 내 특정 요소 업데이트 (위치 연산자 $)
문제
employees 컬렉션의 문서에는 projects라는 객체 배열 필드가 있습니다. "John Doe"라는 직원의 프로젝트 중 project_id가 "P124"인 프로젝트의 role을 "Senior Lead Developer"로 업데이트하는 올바른 명령어는 무엇입니까?
데이터 예시:
JSON
{
  "name": "John Doe",
  "projects": [
    { "project_id": "P123", "role": "Developer", ... },
    { "project_id": "P124", "role": "Lead Developer", ... }
  ]
}


출제자 의도
배열 내 여러 객체 중 쿼리 조건과 일치하는 바로 그 객체를 특정하여 업데이트하기 위해 위치 연산자($)를 올바르게 사용해야 함을 이해하고 있는지 평가합니다.
나의 오답
JavaScript
db.employees.updateOne(
  { "name": "John Doe", "projects.project_id": "P124" },
  { $set: { "projects.role": "Senior Lead Developer" } }
)


오답 분석:
이 명령어는 projects.role을 업데이트하려고 하지만, 위치 연산자($)를 사용하지 않았습니다. projects 배열에는 여러 객체가 들어있는데, MongoDB는 이 중에서 몇 번째 객체의 role을 바꿔야 할지 특정할 수 없습니다. 따라서 이 업데이트는 의도와 다르게 동작하거나 실패하게 됩니다.
정답
JavaScript
db.employees.updateOne(
  { "name": "John Doe", "projects.project_id": "P124" },
  { $set: { "projects.$.role": "Senior Lead Developer" } }
)


정답 해설:
이 명령어는 위치 연산자 $를 올바르게 사용했습니다.
query 부분: { "name": "John Doe", "projects.project_id": "P124" }
먼저 name이 "John Doe"인 문서를 찾습니다.
그 다음, 그 문서의 projects 배열 안에서 project_id가 "P124"인 요소(객체)를 찾습니다. (이 예시에서는 두 번째 요소가 일치합니다.)
update 부분: { $set: { "projects.$.role": "Senior Lead Developer" } }
여기서 $는 **"앞의 query 부분에서 일치했던 바로 그 배열 요소의 위치"**를 가리키는 자리 표시자(placeholder) 역할을 합니다.
따라서 "projects.$.role"은 "projects 배열 안에서, 아까 찾았던 project_id가 'P124'였던 바로 그 객체의 role 필드"라는 매우 구체적인 지시가 됩니다.
결과적으로, MongoDB는 "John Doe"의 projects 배열에서 "P124" 프로젝트를 정확히 찾아내어 해당 프로젝트의 role만 "Senior Lead Developer"로 변경합니다.
핵심 개념 정리
위치 연산자 ($): 배열 필드를 업데이트할 때, query 조건과 일치한 첫 번째 배열 요소의 위치를 가리키는 특별한 플레이스홀더입니다.
사용 조건: update 부분에서 $ 연산자를 사용하려면, query 부분에서 업데이트하려는 바로 그 배열 필드에 대한 조건이 명시되어야 합니다. MongoDB는 이 쿼리 조건을 통해 $가 가리킬 '위치'를 찾기 때문입니다.
한계: $ 연산자는 query와 일치하는 첫 번째 요소에만 적용됩니다. 만약 여러 배열 요소가 쿼리 조건과 일치하더라도 첫 번째 요소만 업데이트됩니다. (모든 일치 요소를 업데이트하려면 집계 파이프라인을 사용해야 합니다.)



커버드 쿼리(Covered Query)는 **데이터베이스가 쿼리 결과를 인덱스만으로 모두 처리할 수 있는 경우**를 말합니다. 즉, 실제 데이터가 저장된 도큐먼트(document)를 읽을 필요 없이, 인덱스에 있는 정보만으로 사용자에게 필요한 모든 데이터를 반환할 수 있는 매우 효율적인 쿼리입니다. 🚀

책의 맨 뒤에 있는 '찾아보기(인덱스)'를 생각하면 쉽습니다. 만약 여러분이 "용"이라는 단어가 나오는 모든 페이지 번호와 그 페이지의 첫 문장을 알고 싶다고 가정해 봅시다.

  * **일반 쿼리:** 찾아보기에서 "용"이 나오는 페이지 번호(25, 68, 102)를 찾은 후, 다시 책의 해당 페이지(25, 68, 102)를 일일이 펼쳐서 첫 문장을 확인해야 합니다.
  * **커버드 쿼리:** 찾아보기에 "용"이라는 단어와 함께 해당 페이지 번호 및 **첫 문장까지 요약되어 있다면**, 굳이 본문 페이지를 펼쳐볼 필요 없이 찾아보기만 보고 원하는 정보를 모두 얻을 수 있습니다. 이것이 바로 커버드 쿼리의 원리입니다.

-----

### 커버드 쿼리의 조건 📝

커버드 쿼리가 성립하려면 다음 두 가지 조건을 모두 만족해야 합니다.

1.  **쿼리의 모든 필드가 인덱스에 포함되어야 합니다.**

      * `find()`나 `sort()` 등 쿼리 조건에 사용되는 모든 필드가 인덱스의 일부여야 합니다.

2.  **프로젝션(결과)의 모든 필드가 인덱스에 포함되어야 합니다.**

      * 쿼리 결과로 요청하는 모든 필드 또한 같은 인덱스에 있어야 합니다.
      * `_id` 필드는 예외적으로, 프로젝션에서 명시적으로 제외(`_id: 0`)해야 커버드 쿼리로 동작하는 경우가 많습니다. (인덱스에 `_id`가 포함되지 않은 경우)

만약 쿼리나 프로젝션에 인덱스에 없는 필드가 단 하나라도 포함되면, MongoDB는 해당 필드 값을 얻기 위해 결국 실제 도큐먼트를 찾아봐야 하므로 커버드 쿼리가 될 수 없습니다.

-----

### 장점 👍

  * **엄청난 성능 향상**: 디스크나 메모리에서 무거운 도큐먼트 전체를 가져오는 과정을 생략하고, 상대적으로 가벼운 인덱스만 읽기 때문에 쿼리 속도가 매우 빨라집니다. 이는 I/O 작업을 획기적으로 줄여줍니다.

-----

### 예시 💻

`users` 컬렉션에 다음과 같은 데이터가 있다고 가정해 봅시다.

```json
{ "_id": 1, "name": "Alice", "age": 30, "city": "Seoul" }
{ "_id": 2, "name": "Bob", "age": 25, "city": "Busan" }
```

그리고 `name`과 `age` 필드로 구성된 복합 인덱스를 생성합니다.

```javascript
db.users.createIndex({ "name": 1, "age": 1 })
```

#### **1. 커버드 쿼리 예시**

아래 쿼리는 `name`으로 문서를 찾고, 결과로 `name`과 `age` 필드만 요청합니다. `name`과 `age`는 모두 인덱스에 포함되어 있으므로 커버드 쿼리가 됩니다.

```javascript
// 쿼리 필드(name), 프로젝션 필드(name, age) 모두 인덱스에 존재
db.users.find(
  { "name": "Alice" },
  { "name": 1, "age": 1, "_id": 0 }
)
```

이 쿼리는 도큐먼트를 전혀 보지 않고 인덱스만으로 결과를 반환할 수 있습니다.

#### **2. 커버드 쿼리가 아닌 예시**

아래 쿼리는 결과로 `city` 필드를 추가로 요청합니다. 하지만 `city` 필드는 인덱스에 없기 때문에, MongoDB는 `name`과 `age`를 인덱스에서 찾은 후 `city` 값을 얻기 위해 결국 도큐먼트를 열어봐야 합니다.

```javascript
// 프로젝션 필드 'city'가 인덱스에 없음
db.users.find(
  { "name": "Alice" },
  { "name": 1, "age": 1, "city": 1, "_id": 0 }
)
```

따라서 이 쿼리는 커버드 쿼리가 아닙니다.


-----

### **1. 오타/맞춤법 오류가 포함된 텍스트 검색 (Fuzzy Search)**

MongoDB의 기본 `$text` 검색은 오타나 유사한 단어를 직접 찾아주지 않습니다. 이 기능을 사용하려면 **Atlas Search**를 사용해야 합니다.

  * **잘못된 생각**: `db.collection.find({ $text: { $search: "mongo" } })`가 "mango"도 찾아줄 것이다.
  * **정확한 개념**:
      * **Standard MongoDB**: 기본 `$text` 검색은 정확한 단어 매칭(stemming, 즉 어간 추출은 지원)에 중점을 둡니다.
      * **Atlas Search**: MongoDB의 클라우드 서비스인 Atlas에서 제공하는 고급 검색 기능입니다. 내부적으로 Apache Lucene을 사용하여 \*\*fuzzy search(퍼지 검색)\*\*를 지원합니다. 이를 통해 오타, 맞춤법 오류, 동의어 등을 처리할 수 있습니다.

> **💡 핵심**: 오타나 맞춤법 오류를 포함한 검색은 **Atlas Search**의 **fuzzy** 옵션을 사용해야 합니다.

-----

### **2. 대소문자 미구분 검색 (Case-Insensitive Search)**

필드 값의 대소문자를 구분하지 않고 검색하는 방법은 크게 두 가지입니다.

1.  **`$regex` 연산자 사용**: 정규 표현식(Regular Expression)과 `i` 옵션을 사용하는 가장 일반적인 방법입니다.
    ```javascript
    // 'name' 필드에서 'John'을 대소문자 구분 없이 검색
    db.users.find({ name: { $regex: 'john', $options: 'i' } });
    ```
2.  **Collation 사용**: 인덱스를 생성할 때나 쿼리 시에 언어별 정렬 규칙(Collation)을 지정할 수 있습니다. 이 방법은 인덱스를 활용할 수 있어 `$regex`보다 성능상 이점이 있습니다.
      * **Collation의 `strength` 옵션**:
          * `strength: 1`: 기본 문자만 비교 (대소문자, 악센트 무시)
          * `strength: 2`: 대소문자는 무시, 악센트는 구분
    <!-- end list -->
    ```javascript
    // strength: 2를 주어 대소문자를 무시하는 Collation으로 검색
    db.users.find({ name: 'john' }).collation({ locale: 'en', strength: 2 });
    ```

> **💡 핵심**: 간단한 쿼리는 \*\*`$regex`\*\*와 \*\*`$options: 'i'`\*\*를, 성능이 중요한 경우나 인덱스를 활용해야 할 때는 **Collation**을 사용합니다.

-----

### **3. 쿼리와 일치하는 첫 번째 문서 찾기**

쿼리 조건에 맞는 **단 하나의 문서**만 가져오고 싶을 때는 `findOne()` 메소드를 사용합니다.

  * **`find()`**: 쿼리와 일치하는 모든 문서를 가리키는 \*\*커서(cursor)\*\*를 반환합니다.
  * **`findOne()`**: 쿼리와 일치하는 **첫 번째 문서**를 직접 반환합니다. 문서가 없으면 `null`을 반환합니다.

<!-- end list -->

```javascript
// age가 30 이상인 사용자 중 첫 번째 한 명의 문서만 가져옴
db.users.findOne({ age: { $gte: 30 } });
```

> **💡 핵심**: 여러 개가 아닌 **단 한 개의 문서**를 원할 때는 `findOne()`이 가장 간단하고 효율적입니다.

-----

### **4. `.limit()` 메소드의 목적**

`.limit()` 메소드는 쿼리 결과로 반환될 문서의 **최대 개수를 제한**하는 역할을 합니다.

  * 주로 \*\*페이지네이션(Pagination)\*\*을 구현할 때 사용됩니다. (예: 한 페이지에 10개씩 보여주기)
  * 불필요하게 많은 데이터를 네트워크를 통해 전송하는 것을 방지하여 성능을 향상시킬 수 있습니다.

<!-- end list -->

```javascript
// 등록일(createdAt) 순으로 정렬 후, 가장 최근 사용자 5명만 가져오기
db.users.find().sort({ createdAt: -1 }).limit(5);
```

> **💡 핵심**: `.limit(N)`은 결과물 중 **최대 N개**의 문서만 가져오도록 개수를 제한합니다.

-----

### **5. 숫자 필드가 특정 값과 일치하는 문서 찾기**

숫자 필드 값이 특정 값과 정확히 일치하는 문서를 찾을 때는 `{ <필드>: <값> }` 구문을 사용합니다.

  * MongoDB는 이 구문을 내부적으로 `$eq` (equals) 연산자로 해석합니다.

<!-- end list -->

```javascript
// 'quantity' 필드의 값이 정확히 20인 문서 검색
// 아래 두 쿼리는 동일하게 동작합니다.

// 1. 암시적(Implicit) 구문 (일반적으로 사용)
db.inventory.find({ quantity: 20 });

// 2. 명시적(Explicit) 구문 ($eq 사용)
db.inventory.find({ quantity: { $eq: 20 } });
```

> **💡 핵심**: `{ field: value }`는 `field`의 값이 `value`와 **정확히 같은** 문서를 찾는 가장 기본적인 쿼리입니다.

-----

### **6. `.sort()` 메소드의 역할**

`.sort()` 메소드는 조회된 문서들의 **정렬 순서**를 지정합니다.

  * 인자로 정렬할 필드와 순서를 담은 문서를 전달합니다.
  * **1**: 오름차순 (Ascending)
  * **-1**: 내림차순 (Descending)

<!-- end list -->

```javascript
// 사용자들을 나이(age)는 오름차순으로,
// 나이가 같다면 가입일(signupDate)은 내림차순(최신순)으로 정렬
db.users.find().sort({ age: 1, signupDate: -1 });
```

> **💡 핵심**: `.sort()`는 결과를 어떤 기준으로 **정렬**할지 결정합니다. `1`은 오름차순, `-1`은 내림차순입니다.

-----

### **7. 텍스트 검색(Text Search)의 올바른 구문**

텍스트 검색을 수행하려면 먼저 **text index**가 생성되어 있어야 합니다.

1.  **텍스트 인덱스 생성**:

    ```javascript
    // 'content' 필드에 텍스트 인덱스 생성
    db.articles.createIndex({ content: "text" });
    ```

2.  **`$text`와 `$search`를 이용한 검색**:
    `$text` 연산자를 사용하여 검색을 수행하며, 찾고 싶은 문자열은 `$search` 연산자 값으로 전달합니다.

    ```javascript
    // 'content' 필드에서 "mongodb"와 "search"라는 단어를 포함하는 기사 검색
    db.articles.find({ $text: { $search: "mongodb search" } });
    ```

> **💡 핵심**: 텍스트 검색은 **`$text`** 연산자와 **`$search`** 연산자를 함께 사용하며, `{ $text: { $search: "검색어" } }` 형태를 가집니다.

-----

### **8. 주어진 문서 데이터 분석 및 쿼리**

**데이터셋 예시**:

1.  `{"a": "abc", "b": [7, 8, 9]}`
2.  `{"a": "def", "b": 5}`
3.  `{"a": "ghi", "b": [2, 10, 4, 8]}`

이 데이터에서 필드 `b`는 숫자일 수도 있고, 숫자 배열일 수도 있습니다. 이런 구조에서 쿼리할 때 MongoDB의 유연한 특징이 나타납니다.

  * **질문**: "필드 `b`가 8이라는 값을 포함하는 문서를 찾으시오."

    ```javascript
    db.collection.find({ b: 8 });
    ```

  * **결과**: **1번과 3번 문서**가 반환됩니다.

  * **이유**:

      * MongoDB에서 배열 필드에 대한 동등성(`{ field: value }`) 쿼리는 "해당 `value`를 **요소로 포함**하는가"를 확인합니다.
      * 따라서 `{ b: 8 }` 쿼리는 `b`의 값이 `8`인 문서뿐만 아니라, `b`가 배열이고 그 안에 `8`이라는 요소가 포함된 문서도 모두 찾아냅니다.

  * **질문**: "필드 `b`에 8보다 큰 값이 포함된 문서를 찾으시오."

    ```javascript
    db.collection.find({ b: { $gt: 8 } });
    ```

      * `$gt` (greater than) 연산자는 배열의 **요소 중 하나라도** 조건을 만족하면 해당 문서를 반환합니다.
      * **결과**: 1번 문서(`9`가 조건 만족), 3번 문서(`10`이 조건 만족)가 반환됩니다. 2번 문서는 `5`이므로 조건에 맞지 않아 제외됩니다.

> **💡 핵심**: 배열 필드에 `find({ field: value })`를 사용하면, 배열에 해당 `value`가 **포함되어 있는지** 검사합니다. 비교 연산자(`$gt`, `$lt` 등)는 배열 요소 중 **하나라도 만족하면** 참으로 간주합니다.


### ## 💾 MongoDB 명령어 치트 시트

MongoDB 명령어 도구는 크게 **데이터 가져오기/내보내기**, **백업/복원**, **모니터링** 등으로 나눌 수 있습니다.

### ### 1. 데이터 가져오기 / 내보내기 (텍스트 기반)

다른 시스템과 데이터를 주고받거나 사람이 읽을 수 있는 형태로 데이터를 다룰 때 사용합니다.

* **`mongoimport`** 📥
    * **설명**: **JSON, CSV, TSV** 형식의 파일을 MongoDB 컬렉션으로 가져옵니다.
    * **핵심 용도**: 외부에서 생성된 데이터를 MongoDB에 삽입할 때 사용합니다.
    * **예시**: `mongoimport --db myDB --collection products --file products.json`

* **`mongoexport`** 📤
    * **설명**: 컬렉션의 데이터를 **JSON**이나 **CSV** 파일로 내보냅니다.
    * **핵심 용도**: 데이터를 다른 프로그램에서 사용하거나 분석용으로 추출할 때 유용합니다.
    * **예시**: `mongoexport --db myDB --collection users --out users.csv --type csv --fields name,email`

---

### ### 2. 백업 및 복원 (바이너리 기반)

데이터베이스 전체를 백업하거나 다른 서버로 이전할 때 사용하며, BSON 형식을 사용해 데이터를 완벽하게 보존합니다.

* **`mongodump`**
    * **설명**: 데이터베이스 전체 또는 특정 컬렉션을 **BSON(바이너리)** 형식으로 백업(덤프)합니다.
    * **핵심 용도**: 데이터베이스의 전체적인 스냅샷을 만들어 안정적으로 백업할 때 사용합니다.
    * **예시**: `mongodump --db myDB --out /backup/path`

* **`mongorestore`**
    * **설명**: `mongodump`로 생성된 BSON 백업 파일을 사용해 데이터베이스를 복원합니다.
    * **핵심 용도**: 백업된 데이터를 원래 상태로 되돌리거나 다른 서버에 복제할 때 사용합니다.
    * **예시**: `mongorestore --db myDB /backup/path/myDB`

> #### **💡 `import` vs `dump` 핵심 차이점**
> * **`mongoimport` / `mongoexport`**: **텍스트 기반**(JSON, CSV)이라 사람이 읽기 쉽지만, `ObjectId` 같은 MongoDB 고유 타입 정보가 일부 손실될 수 있습니다. **데이터 교환**에 적합합니다.
> * **`mongodump` / `mongorestore`**: **바이너리 기반**(BSON)이라 데이터 타입이 완벽하게 보존됩니다. **안정적인 백업 및 복원**에 적합합니다.

---

### ### 3. 모니터링 및 진단 📊

MongoDB 서버의 상태를 실시간으로 확인할 때 사용합니다.

* **`mongostat`**
    * **설명**: MongoDB 서버의 현재 상태(초당 insert/query/update 수, 네트워크 트래픽 등)를 일정 간격으로 보여줍니다. 리눅스의 `top` 명령어와 비슷합니다.
    * **핵심 용도**: 서버의 전반적인 부하와 동작 상태를 빠르게 파악할 때 사용합니다.

* **`mongotop`**
    * **설명**: 각 컬렉션이 얼마나 많은 시간을 읽기(read)와 쓰기(write) 작업에 사용하고 있는지 보여줍니다.
    * **핵심 용도**: 어떤 컬렉션이 가장 많은 부하를 받고 있는지(핫 컬렉션) 확인할 때 유용합니다.

---

### ### 4. 서버 프로세스 및 연결 🖥️

* **`mongod`** ⚙️
    * **설명**: MongoDB의 핵심 **데이터베이스 서버 프로세스**(데몬)입니다. 이 프로세스가 실행되어야 데이터베이스가 동작합니다.

* **`mongosh`** (또는 구 버전 `mongo`)
    * **설명**: MongoDB 서버에 연결해서 데이터를 조작하고 관리하는 **대화형 셸(Shell)** 클라이언트입니다. 쿼리를 직접 실행하는 곳입니다.






-----

## 상세 데이터 예시: 상품 재고 관리 📦

`products` 컬렉션에 각 상품의 창고별 재고 수량이 배열로 저장되어 있다고 가정해 보겠습니다.

**데이터 삽입:**

```javascript
db.products.insertMany([
    {
        "productName": "A-자켓",
        "stockByWarehouse": [2, 5, 8] // 3보다 큰 재고(5, 8)가 있음
    },
    {
        "productName": "B-셔츠",
        "stockByWarehouse": [1, 2, 3] // 3보다 큰 재고가 없음
    },
    {
        "productName": "C-바지",
        "stockByWarehouse": [10, 20, 30] // 모든 재고가 3보다 큼
    }
])
```

**쿼리 실행:**
"어느 창고든 재고가 3개 초과인 상품을 모두 찾아주세요."

```javascript
db.products.find({ stockByWarehouse: { $gt: 3 } })
```

-----

## 쿼리 결과 및 분석

MongoDB는 각 문서를 다음과 같이 평가합니다.

1.  **A-자켓 문서 (`[2, 5, 8]`)**

      * `stockByWarehouse` 배열에 3보다 큰 요소가 하나라도 있는가?
      * 네, `5`와 `8`이 3보다 큽니다.
      * **결과: 반환됨 ✅**

2.  **B-셔츠 문서 (`[1, 2, 3]`)**

      * `stockByWarehouse` 배열에 3보다 큰 요소가 하나라도 있는가?
      * 아니요, 가장 큰 값이 3이지만, 3은 3보다 크지 않습니다.
      * **결과: 반환되지 않음 ❌**

3.  **C-바지 문서 (`[10, 20, 30]`)**

      * `stockByWarehouse` 배열에 3보다 큰 요소가 하나라도 있는가?
      * 네, `10`, `20`, `30` 모두 3보다 큽니다.
      * **결과: 반환됨 ✅**

최종적으로, **A-자켓**과 **C-바지** 문서가 반환됩니다.

-----

### 💡 만약 '모든' 창고의 재고가 3개 초과인 상품을 찾고 싶다면?

"모든 창고의 재고가 3개 초과"라는 것은, 반대로 말하면 "3개 이하인 재고가 **하나도 없는**" 상품을 찾는 것과 같습니다. 이 논리를 이용해 `$not`과 `$lte` 연산자를 함께 사용합니다.

```javascript
db.products.find({ stockByWarehouse: { $not: { $lte: 3 } } })
```

이 쿼리를 실행하면 **C-바지** 문서만 반환됩니다. `A-자켓`은 `2`라는 요소가 `$lte: 3` 조건에 걸리기 때문에 제외됩니다.


❌ 잘못된 방법 ($elemMatch 없음)
JavaScript

db.products.find({ 
    stockByWarehouse: { $gt: 3, $lt: 10 } 
})
의미: "이 상품의 재고 목록에 3보다 큰 숫자가 하나라도 있고, 그리고 10보다 작은 숫자가 하나라도 있나요?"

결과 분석:

A-자켓 ([2, 8, 12]): 8이 두 조건을 모두 만족하므로 찾아짐 ✅

B-셔츠 ([1, 2, 3]): 조건을 만족하는 요소가 없으므로 찾아지지 않음 ❌

C-바지 ([1, 15]): 15가 $gt: 3 조건을 만족하고, 1이 $lt: 10 조건을 만족합니다. 두 조건이 서로 다른 요소에 의해 충족되었지만, 쿼리는 참으로 판단하여 C-바지도 찾아집니다. (의도와 다른 결과!)

✅ 올바른 방법 ($elemMatch 사용)
JavaScript

db.products.find({ 
    stockByWarehouse: { 
        $elemMatch: { $gt: 3, $lt: 10 } 
    } 
})
의미: "이 상품의 재고 목록에 하나의 숫자가 3보다 크면서 동시에 10보다 작은 경우가 있나요?"

결과 분석:

A-자켓 ([2, 8, 12]): 8이라는 요소 하나가 두 조건을 모두 만족하므로 찾아짐 ✅

B-셔츠 ([1, 2, 3]): 조건을 만족하는 요소가 없으므로 찾아지지 않음 ❌

C-바지 ([1, 15]): 두 조건을 동시에 만족하는 요소가 없으므로 찾아지지 않음 ✅ (의도한 대로 동작!)



