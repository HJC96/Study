# 오답노트
You are managing a retail inventory system where products are stored in a MongoDB collection called inventory. Each product document has fields _id, item, quantity, and price. You need to increase the quantity of a product if it exists or insert a new product with a specific quantity and price if it does not exist. The product is identified by the item field. Which of the following updateOne commands should you use to accomplish this?
---
db.inventory.updateOne(
  { item: "notebook" },
  { $inc: { quantity: 10 }, $setOnInsert: { price: 5.99 } },
  { upsert: true }
)

setOnInsert -> set the price only when a new document is inserted.
upsert


MongoDB insertMany 명령어 오답노트
1. 문제
다음 중 비어있는 companies 컬렉션에 정확히 두 개의 새 문서를 성공적으로 삽입하는 MongoDB 명령어는 무엇입니까?

명령어 예시:

db.companies.insertMany([
    {"_id": 1, "name": "Facebook"},
    {"_id": 2, "name": "Twitter"},
    {"_id": 2, "name": "Tesla"}
])

출제자 의도
insertMany 명령어의 기본 동작(ordered: true)과 오류 발생 시 이전 작업은 롤백되지 않는다는 점을 이해하고 있는지 평가합니다.

2. 나의 오답 예상 (잘못된 생각)
"_id 필드는 고유(unique)해야 하는 기본 키(Primary Key)이므로, 배열 안에 _id 값이 2로 중복되는 문서가 포함되어 있으면 오류가 발생할 것이다. 따라서 insertMany 명령어 전체가 실패하고 아무 문서도 삽입되지 않을 것이다."

이 생각은 _id의 고유성 제약 조건은 정확히 이해했지만, insertMany 명령어의 동작 방식에 대한 이해가 부족해서 발생한 오해입니다.

3. 정답 및 상세 해설
정답: 위 명령어는 정확히 두 개의 문서를 삽입합니다.

해설:
db.collection.insertMany() 명령어는 기본적으로 순서가 있는(ordered) 방식으로 동작합니다. 이는 명령어에 전달된 배열의 문서들을 순서대로 하나씩 삽입을 시도한다는 의미입니다.

동작 과정은 다음과 같습니다.

첫 번째 문서 삽입 시도: {"_id": 1, "name": "Facebook"}

_id가 1인 문서가 없으므로 성공적으로 삽입됩니다.

두 번째 문서 삽입 시도: {"_id": 2, "name": "Twitter"}

_id가 2인 문서가 없으므로 성공적으로 삽입됩니다.

세 번째 문서 삽입 시도: {"_id": 2, "name": "Tesla"}

_id가 2인 문서가 이미 존재하므로 '중복 키 오류(duplicate key error)'가 발생합니다.

insertMany는 기본적으로 ordered: true 옵션을 사용하기 때문에, 오류가 발생하는 즉시 전체 작업을 중단합니다. 하지만 중요한 점은 오류 발생 이전에 성공적으로 삽입된 문서들은 롤백(취소)되지 않고 그대로 컬렉션에 남는다는 것입니다.

따라서 이 명령어의 최종 결과로 companies 컬렉션에는 첫 번째와 두 번째 문서, 즉 총 2개의 문서만 남게 됩니다.

4. 핵심 개념 정리
insertMany 명령어의 ordered 옵션
insertMany 명령어는 동작 방식을 제어하는 ordered 옵션을 가지고 있습니다.

ordered: true (기본값)

배열의 순서대로 문서를 삽입합니다.

중간에 오류가 발생하면, 그 즉시 작업을 중단합니다.

오류 발생 전까지 삽입된 문서는 그대로 유지됩니다.

ordered: false

배열의 순서와 상관없이 MongoDB가 최적화된 방식으로 모든 문서의 삽입을 시도합니다.

중간에 오류가 발생하더라도 작업을 중단하지 않고, 오류가 없는 다른 모든 문서의 삽입을 계속 시도합니다.

(만약 위 예제를 ordered: false로 실행했더라도, 결과는 동일하게 2개의 문서가 삽입됩니다. 오류가 난 세 번째 문서를 제외한 나머지 문서들의 삽입을 시도하기 때문입니다.)

5. 결론 및 교훈
insertMany 명령어는 기본적으로 순차적으로 실행되며, 오류가 발생하면 그 지점에서 멈춘다. 데이터베이스 트랜잭션처럼 전체 작업이 취소되는 것이 아니라, 오류 발생 직전까지의 성공한 작업은 그대로 유지된다는 점을 반드시 기억해야 합니다.

이 개념을 이해하면 여러 문서를 한 번에 삽입할 때 발생할 수 있는 문제를 정확히 예측하고 해결할 수 있습니다.

6. 추가 개념: Capped Collection 생성하기
문제
latest_news라는 이름의 Capped Collection을 생성하려고 합니다. 이 컬렉션은 최대 3개의 문서와 10,000바이트의 크기 제한을 가져야 합니다. 올바른 명령어는 무엇입니까?

출제자 의도
Capped Collection을 생성하는 db.createCollection 명령어의 기본 문법과 주요 옵션(capped, size, max)을 알고 있는지 평가합니다.

정답 명령어
db.createCollection('latest_news', {'capped': true, 'size': 10000, 'max': 3})

해설
이 명령어는 latest_news라는 이름의 Capped Collection을 생성하는 올바른 방법입니다.

'capped': true: 해당 컬렉션이 고정된 크기를 가지며, 오래된 데이터가 자동으로 삭제되는 FIFO(First-In-First-Out) 방식으로 동작하도록 설정합니다.

'size': 10000: 컬렉션의 최대 크기를 바이트 단위로 지정합니다.

'max': 3: 컬렉션에 저장될 수 있는 최대 문서 수를 지정합니다.

Capped Collection은 이 두 가지 제한 (size와 max) 중 하나라도 먼저 도달하면 가장 오래된 문서를 삭제하고 새 문서를 위한 공간을 확보합니다. 주로 실시간 로그 데이터 저장과 같이 최신 데이터를 유지하는 것이 중요한 경우에 유용하게 사용됩니다.

7. 추가 개념: Aggregation - 전체 평균 vs 그룹별 평균
문제
sales 컬렉션에 아래와 같은 구조의 문서들이 저장되어 있습니다. 이 컬렉션에 있는 모든 상품의 amount 필드의 전체 평균을 계산하는 올바른 Aggregation 쿼리는 무엇입니까?

출제자 의도
$group 스테이지에서 특정 필드로 그룹화(_id: "$field")하는 것과 전체 문서 대상(_id: null)으로 집계하는 것의 차이점을 이해하는지 평가합니다.

예시 데이터:

[
  { "product": "Laptop", "amount": 1200 },
  { "product": "Mouse", "amount": 25 },
  { "product": "Laptop", "amount": 1000 },
  { "product": "Keyboard", "amount": 75 },
  { "product": "Mouse", "amount": 30 }
]

나의 오답
db.sales.aggregate([
  { $group: { _id: "$product", avgAmount: { $avg: "$amount" } } }
])

오답 분석:
이 쿼리는 product 필드를 기준으로 문서를 그룹화합니다. 따라서 "Laptop", "Mouse" 등 각 상품별 amount의 평균을 계산하게 됩니다. 문제에서 요구하는 것은 '모든 상품을 합친 전체 평균'이므로, 이 쿼리는 요구사항과 맞지 않습니다.

쿼리 실행 결과 (오답):

[
  { "_id": "Laptop", "avgAmount": 1100 },
  { "_id": "Mouse", "avgAmount": 27.5 },
  { "_id": "Keyboard", "avgAmount": 75 }
]

정답
db.sales.aggregate([
  { $group: { _id: null, avgAmount: { $avg: "$amount" } } }
])

정답 해설:
이 쿼리가 컬렉션 전체의 평균을 정확하게 계산합니다.

$group: 문서를 특정 기준에 따라 그룹화하는 스테이지입니다.

_id: null: 이 부분이 핵심입니다. $group 스테이지에서 _id 값을 null로 지정하면, 특정 필드를 기준으로 그룹을 나누지 않고 컬렉션의 모든 문서를 하나의 그룹으로 묶어서 집계하라는 의미입니다.

avgAmount: { $avg: "$amount" }: 이렇게 하나의 그룹으로 묶인 모든 문서들의 $amount 필드 값을 가져와 평균($avg)을 계산하고, 그 결과를 avgAmount라는 새로운 필드에 저장합니다.

쿼리 실행 결과 (정답):
(1200 + 25 + 1000 + 75 + 30) / 5 = 466

[
  { "_id": null, "avgAmount": 466 }
]

핵심 개념 정리: $group 스테이지의 _id 필드
$group 스테이지에서 _id 필드는 그룹화의 기준을 정의합니다.

_id: "$field_name": field_name의 고유한 값마다 별도의 그룹을 생성합니다. (예: 상품별, 카테고리별 집계)

_id: null: 모든 문서를 단일 그룹으로 취급하여 전체에 대한 집계를 수행합니다. (예: 전체 합계, 전체 평균)

8. 추가 개념: 쓰기(Write) 성능 최적화
문제
애플리케이션 개발에서 쓰기(write) 성능이 매우 중요합니다. 주로 삽입(insert) 작업이 발생하고 업데이트나 삭제는 거의 없는 시나리오에서, 대용량의 쓰기 작업을 최적화하는 데 가장 적합한 MongoDB 기능은 무엇입니까?

출제자 의도
대규모 데이터 처리 시 수직 확장과 수평 확장(샤딩)의 차이를 이해하고, 쓰기 중심 워크로드에 샤딩이 적합하다는 것을 아는지 평가합니다.

나의 오답
Aggregation Pipeline

오답 분석:
Aggregation Pipeline은 데이터 처리 파이프라인 개념을 모델로 한 데이터 집계 프레임워크입니다. 여러 단계(stage)를 거쳐 데이터를 변환하고 요약하는 등 데이터를 조회하고 분석하는 데 주로 사용됩니다. 쓰기 성능에 직접적인 영향을 주는 기능이 아니므로, 이 문제의 답으로는 적절하지 않습니다.

정답
Sharding (샤딩)

정답 해설:
샤딩은 데이터를 여러 머신(서버)에 분산하여 저장하는 방법입니다. MongoDB는 샤딩을 통해 매우 큰 데이터 세트와 높은 처리량의 작업을 지원합니다.

애플리케이션의 쓰기 요청이 폭주할 경우, 단일 서버는 결국 CPU, RAM, 디스크 I/O 등 하드웨어의 한계에 도달하게 됩니다. 샤딩은 이 문제를 해결하기 위해 데이터를 여러 **샤드(Shard)**라고 불리는 서버 그룹에 분산시킵니다.

이렇게 하면 쓰기 작업 또한 여러 서버로 분산되어 처리됩니다. 즉, 한 서버에 집중되던 쓰기 부하가 여러 서버로 나뉘면서 전체적인 쓰기 처리량이 크게 향상됩니다. 따라서 대용량의 쓰기 작업이 많은(write-heavy) 워크로드에 가장 효과적인 확장 솔루션입니다.

핵심 개념 정리: 수직 확장 vs 수평 확장(샤딩)
수직 확장 (Scaling Up): 단일 서버의 하드웨어 사양(CPU, RAM 등)을 업그레이드하는 방식입니다. 비용이 많이 들고, 결국 물리적인 한계에 부딪힙니다.

수평 확장 (Scaling Out / Sharding): 더 많은 서버를 추가하여 전체 시스템의 용량과 성능을 높이는 방식입니다. 샤딩이 바로 여기에 해당하며, 대규모 시스템을 구축하는 데 훨씬 유연하고 비용 효율적입니다.

9. 추가 개념: 정규식(Regex)을 이용한 텍스트 검색
문제
books 컬렉션에 title 필드가 있습니다. title이 'ian'으로 끝나는 모든 책을 반환하는 쿼리는 무엇입니까?

출제자 의도
정규식(Regex)을 사용하여 텍스트를 검색할 때, 문자열의 끝을 의미하는 앵커($)의 역할을 정확히 이해하고 있는지 평가합니다.

나의 오답
db.books.find( { title: { $regex: /.*ian/ } } )

오답 분석:
이 쿼리는 title 필드에 'ian'이 어디든 포함되기만 하면 문서를 찾아냅니다. 예를 들어, "The Martian", "Guardians of the Galaxy", "Librarian's Choice"와 같은 제목을 모두 반환할 수 있습니다. 문제에서는 'ian'으로 끝나는 경우만 요구했으므로, 이 쿼리는 너무 광범위한 결과를 반환합니다.

정답
db.books.find( { title: { $regex: /.*ian$/ } } )

정답 해설:
이 쿼리는 $regex 연산자와 함께 정규식 패턴을 사용하여 title 필드가 'ian'으로 끝나는 문서를 정확히 찾아냅니다.

 /.*ian$/: 이 정규식 패턴에서 각 부분의 의미는 다음과 같습니다.

.*: .은 어떤 문자든 하나를 의미하고, *는 0번 이상 반복을 의미합니다. 즉, .*는 'ian' 앞에 어떤 문자열이 오든 상관없다는 뜻입니다.

ian: 'ian'이라는 문자열과 정확히 일치해야 합니다.

$: 이 부분이 핵심입니다. $는 문자열의 끝을 의미하는 **앵커(anchor)**입니다. 따라서 'ian'이 반드시 문자열의 맨 끝에 위치해야만 조건에 부합하게 됩니다.

이 쿼리를 사용하면 "The Martian"은 반환하지만, "Guardians of the Galaxy"나 "Librarian's Choice"는 반환하지 않습니다.

핵심 개념 정리: 정규식의 기본 앵커
정규식에서 특정 위치를 지정하는 문자를 '앵커'라고 합니다.

^: 문자열의 시작을 의미합니다. (예: /^The/ -> 'The'로 시작하는 문자열)

$: 문자열의 끝을 의미합니다. (예: /story$/ -> 'story'로 끝나는 문자열)

10. 추가 개념: 데이터 모델링 - 아웃라이어 패턴 (Outlier Pattern)
문제
소셜 미디어 회사에서 사용자 간의 관계를 설명하는 데이터 모델을 구현해야 합니다. 실제 데이터를 시스템에 로드할 때, 한 사용자가 너무 많은 연락처를 가지고 있어 지정된 배열에 모두 저장할 수 없는 문제가 발생했습니다. 전체 시스템을 재설계하는 대신 어떤 패턴을 사용할 수 있습니까?

출제자 의도
일반적인 규칙에서 벗어나는 예외적인 데이터를 효율적으로 처리하기 위한 고급 데이터 모델링 패턴(아웃라이어 패턴)을 알고 있는지 평가합니다.

나의 오답
The Extended Reference Pattern (확장 참조 패턴)

오답 분석:
확장 참조 패턴은 엔티티 간의 관계가 너무 복잡하여 단순한 참조나 외래 키로 표현하기 어려울 때 사용됩니다. 하지만 이 문제의 핵심은 관계의 복잡성이 아니라, 특정 사용자 한 명의 연락처 데이터 양이 너무 많아 배열의 저장 용량을 초과하는 것입니다. 따라서 이 패턴은 가장 적합한 해결책이 아닙니다.

정답
The Outlier Pattern (아웃라이어 패턴)

정답 해설:
이 패턴은 표준 데이터 모델에 맞지 않는 예외적인 경우, 즉 **'아웃라이어(outlier)'**를 처리하는 데 사용됩니다. 문제의 경우처럼, 대부분의 사용자는 연락처를 배열에 저장할 수 있지만, 유독 한 명의 사용자가 비정상적으로 많은 연락처를 가져서 배열에 담을 수 없을 때 아웃라이어 패턴을 적용할 수 있습니다.

이 패턴은 시스템 전체를 바꾸는 대신, 해당 예외적인 사용자에 대해서만 대체 데이터 저장 방식을 사용하는 방식으로 문제를 해결합니다. 예를 들어, 일반 사용자는 기존처럼 user 문서 내의 contacts 배열에 연락처를 저장하고, 아웃라이어 사용자의 경우 user 문서에 플래그(has_extra_contacts: true)를 추가하고, 실제 연락처 목록은 별도의 컬렉션(user_123_contacts)에 저장하는 방식입니다.

이렇게 하면 99%의 일반적인 케이스는 기존 모델을 그대로 유지하면서, 1%의 특수한 케이스만 효율적으로 처리할 수 있어 시스템 전체의 설계를 변경하는 비용을 피할 수 있습니다.

11. 추가 개념: 배열(Array)에서 특정 값 찾기
문제
movies 컬렉션에 다음과 같은 구조의 문서가 있습니다. 이 컬렉션에서 장르(genres)에 'Crime'이 포함된 모든 영화를 추출하는 올바른 쿼리는 무엇입니까? (2개 선택)

출제자 의도
배열 필드에서 특정 요소를 조회하는 다양한 방법(단순 일치, $in, $all)의 차이점과 올바른 사용법을 이해하고 있는지 평가합니다.

문서 구조:

{
    "_id": ObjectId("..."),
    "genres": [ "Comedy", "Drama", "Family" ],
    "title": "The Poor Little Rich Girl",
    "year": 1917,
    ...
}

정답 및 오답 분석
정답 쿼리 1
db.movies.find( { "genres": "Crime" } )

해설:
가장 간단하고 직관적인 방법입니다. MongoDB에서 배열 필드에 대해 단일 값으로 동등 비교(:)를 수행하면, 해당 값이 배열 안에 하나의 요소로서 포함되어 있는 모든 문서를 찾아줍니다.

정답 쿼리 2
db.movies.find( { "genres": { "$in" : ["Crime"] } } )

해설:
$in 연산자는 필드의 값이 지정된 배열 안의 값 중 하나라도 일치하는 문서를 찾습니다. 이 경우는 ["Crime"] 배열에 있는 'Crime'이라는 값 하나만 확인하므로, 위 쿼리와 동일한 결과를 반환합니다. $in은 'Crime' 또는 'Thriller' 장르를 찾고 싶을 때 ["Crime", "Thriller"] 와 같이 여러 값을 지정하는 데 더 유용합니다.

오답 쿼리 1
db.movies.find( { "genres": { "$all" : ["Crime"] } } )

해설:
$all 연산자는 지정된 배열의 모든 요소를 포함하는 문서를 찾습니다. 'Crime' 하나만 지정했을 때는 $in과 결과가 같지만, 개념적으로는 과하며 혼동을 줄 수 있습니다. $all은 'Crime'과 'Drama' 장르가 둘 다 포함된 영화를 찾을 때 ["Crime", "Drama"]와 같이 사용하는 것이 올바른 용법입니다.

오답 쿼리 2
db.movies.find( { "genres": { "$equal" : ["Crime"] } } )

해설:
MongoDB에는 $equal이라는 쿼리 연산자가 존재하지 않습니다. 동등 비교를 위해서는 $eq를 사용하거나, 위 정답 쿼리 1처럼 :를 사용해야 합니다.

핵심 개념 정리
배열 필드에서 특정 단일 요소를 포함하는 문서를 찾을 때는 find({ array_field: "value" }) 형태의 간단한 쿼리를 사용하는 것이 가장 효율적입니다. $in은 여러 값 중 하나라도 포함되는 경우를 찾을 때, $all은 여러 값이 모두 포함되는 경우를 찾을 때 사용합니다.

12. 추가 개념: 레플리카 셋 (Replica Set)
문제
MongoDB 레플리카 셋은 무엇이며 그 목적은 무엇입니까?

출제자 의도
MongoDB의 고가용성 핵심 기능인 레플리카 셋이 '여러' mongod 인스턴스 그룹이라는 근본적인 개념을 이해하고 있는지 평가합니다.

나의 오답
"MongoDB 레플리카 셋은 노드 장애 시 자동 장애 조치(failover)를 제공하는 단일 mongod 인스턴스입니다. 레플리카 셋의 목적은 독립 실행형 mongod 인스턴스에 대한 이중화 및 고가용성을 제공하는 것입니다."

오답 분석:
가장 결정적인 오해는 레플리카 셋을 단일 mongod 인스턴스라고 생각한 점입니다. 자동 장애 조치와 이중화는 여러 개의 노드가 있어야만 가능하므로, 단일 인스턴스는 레플리카 셋을 구성할 수 없습니다.

정답
"MongoDB 레플리카 셋은 동일한 데이터 셋을 호스팅하는 mongod 인스턴스 그룹입니다. 레플리카 셋의 목적은 이중화(redundancy)와 고가용성(high availability)을 제공하고, 노드 장애 시 자동 장애 조치(failover)를 허용하는 것입니다."

정답 해설:
이 설명은 MongoDB 레플리카 셋을 정확하게 기술합니다. 핵심은 여러 mongod 인스턴스가 하나의 그룹을 이루어 동일한 데이터를 복제함으로써 이중화와 고가용성을 보장한다는 점입니다. 주 노드(Primary)에 장애가 발생하면, 레플리카 셋이 자동으로 다른 노드(Secondary)를 새로운 주 노드로 승격시켜 서비스 중단을 최소화합니다.

핵심 개념 정리
레플리카 셋(Replica Set): 동일한 데이터를 유지하는 둘 이상의 MongoDB 서버(노드)들의 모음입니다.

목적: 데이터 이중화, 고가용성.

구성 요소:

Primary (주 노드): 레플리카 셋에서 오직 하나만 존재하며, 모든 쓰기(write) 작업을 처리합니다.

Secondaries (보조 노드): Primary의 데이터를 비동기적으로 복제(replicate)합니다. 읽기(read) 작업을 분산 처리할 수도 있습니다.

자동 장애 조치(Automatic Failover): Primary 노드가 응답하지 않으면, 남은 Secondary 노드들이 투표를 통해 새로운 Primary를 선출하여 서비스를 계속 이어나갑니다. 이 과정은 애플리케이션의 개입 없이 자동으로 이루어집니다.

13. 추가 개념: Replica Set 연결 URI 구성하기
문제
여러 서버에 분산된 MongoDB 레플리카 셋에 연결해야 하는 JavaScript 애플리케이션을 작업 중입니다. 레플리카 셋은 SSL/TLS 암호화가 필요하며, 애플리케이션이 주 노드에 안전하고 최적으로 연결되도록 해야 합니다. 레플리카 셋의 이름은 myReplica이고, 노드는 node1.example.com, node2.example.com, node3.example.com입니다. 또한 쓰기 고려(write concern)를 majority로 설정하여 쓰기 작업이 레플리카 셋 멤버의 과반수로부터 확인되도록 해야 합니다. 다음 중 MongoClient가 SSL/TLS 및 majority 쓰기 고려로 레플리카 셋에 연결하도록 올바르게 구성하는 URI 문자열은 무엇입니까?

출제자 의도
레플리카 셋 연결 시, 드라이버의 장애 조치 기능을 활성화하는 필수 옵션(replicaSet)을 포함하여 올바른 URI를 구성할 수 있는지 평가합니다.

나의 오답 (예상)
mongodb://node1.example.com,node2.example.com,[node3.example.com/?ssl=true&w=majority](https://node3.example.com/?ssl=true&w=majority)

오답 분석:
이 URI는 SSL과 majority 쓰기 고려를 올바르게 설정했지만, 가장 중요한 replicaSet=myReplica 옵션이 빠져있습니다. 이 옵션이 없으면 드라이버는 이 세 개의 노드를 독립적인 서버로 인식할 뿐, 하나의 레플리카 셋으로 인식하지 못합니다. 따라서 드라이버는 주 노드를 자동으로 찾아내거나 장애 조치를 처리할 수 없게 되어 레플리카 셋의 이점을 전혀 활용하지 못합니다.

정답
mongodb://node1.example.com,node2.example.com,[node3.example.com/?replicaSet=myReplica&ssl=true&w=majority](https://node3.example.com/?replicaSet=myReplica&ssl=true&w=majority)

정답 해설
이 URI 문자열은 주어진 모든 요구사항을 정확하게 충족합니다.

mongodb://node1.example.com,node2.example.com,node3.example.com/: 연결할 레플리카 셋의 멤버(seed list)를 지정합니다. 드라이버는 이 목록을 사용하여 셋의 모든 멤버를 발견하고 현재의 주 노드가 어떤 것인지 확인합니다. 모든 노드를 명시하는 것이 고가용성을 위해 권장됩니다.

?: 호스트 목록이 끝나고 옵션이 시작됨을 나타냅니다.

replicaSet=myReplica: 이 부분이 핵심입니다. 드라이버에게 myReplica라는 이름의 레플리카 셋에 연결하도록 지시합니다. 이 옵션을 통해 드라이버는 주 노드 자동 탐색 및 장애 조치를 수행할 수 있습니다.

&ssl=true: 드라이버와 MongoDB 서버 간의 통신에 SSL/TLS 암호화를 사용하도록 설정합니다. (tls=true도 동일한 의미로 사용됩니다.)

&w=majority: 쓰기 고려(Write Concern)를 majority로 설정합니다. 이 설정은 쓰기 작업이 레플리카 셋의 과반수 노드(주 노드 포함)에 적용되었을 때 애플리케이션에 성공을 알리도록 보장하여 데이터의 내구성을 높입니다.

핵심 개념 정리
MongoDB 레플리카 셋에 연결할 때는 하나 이상의 호스트와 함께 replicaSet 옵션을 반드시 명시해야 합니다. 이를 통해 드라이버는 고가용성 및 장애 조치 기능을 올바르게 활성화할 수 있습니다. 추가적인 보안 및 데이터 내구성 요구사항은 ssl, w와 같은 옵션을 통해 URI에 명시합니다.

14. 추가 개념: 샤딩 키(Shard Key)를 이용한 쿼리 최적화
문제
MongoDB 샤드 클러스터에서 개발자는 여러 샤드에 분산된 대규모 고객 데이터 컬렉션을 가지고 있습니다. 개발자는 문서 필드 중 하나인 고객의 거주 주(state)를 기반으로 문서를 효율적으로 쿼리하고 싶어합니다. 현재 컬렉션은 state 필드로 샤딩되어 있지 않습니다. 개발자는 다음 중 어떤 조치를 취해야 할까요?

출제자 의도
샤드 클러스터에서 쿼리 성능을 좌우하는 샤드 키의 중요성과, 타겟 쿼리를 유도하기 위한 샤드 키 선택의 원리를 이해하는지 평가합니다.

나의 오답
_id와 state 필드에 복합 인덱스(compound index)를 생성해야 한다.

오답 분석:
복합 인덱스는 특정 유형의 쿼리 성능을 향상시킬 수 있지만, 샤드 클러스터에서 샤드 간에 데이터를 분산시키는 데는 도움이 되지 않습니다. 인덱스는 단일 샤드 내에서 데이터를 더 빨리 찾는 데 도움을 주지만, 쿼리가 모든 샤드로 전송되는 것(scatter-gather)을 막지는 못합니다.

정답
state 필드를 기준으로 컬렉션을 샤딩해야 한다.

정답 해설:
state 필드를 기준으로 컬렉션을 샤딩하면 state 값에 따라 문서가 샤드 전체에 분산됩니다. 이렇게 하면 MongoDB는 특정 주에 대한 쿼리를 관련된 샤드에만 직접 보낼 수 있습니다. 예를 들어, "California"에 대한 쿼리는 "California" 데이터를 가지고 있는 샤드로만 라우팅되고, 다른 샤드는 검색할 필요가 없어집니다. 이러한 타겟 쿼리(targeted query)는 불필요한 네트워크 트래픽과 샤드 부하를 줄여 쿼리 성능을 크게 향상시킵니다.

핵심 개념 정리
샤드 키 (Shard Key): MongoDB가 샤드 클러스터에서 문서를 분산시키는 기준이 되는 필드 또는 필드들의 조합입니다.

쿼리 라우터 (Query Router / mongos): 클라이언트의 쿼리를 수신하여 샤드 키를 기반으로 어떤 샤드가 해당 데이터를 가지고 있는지 판단하고, 쿼리를 해당 샤드로만 전달하는 역할을 합니다.

타겟 쿼리 (Targeted Query): 쿼리 조건에 샤드 키가 포함되어 있어 mongos가 특정 샤드로 쿼리를 직접 보낼 수 있는 매우 효율적인 쿼리입니다.

분산/수집 쿼리 (Scatter-Gather Query): 쿼리 조건에 샤드 키가 없으면 mongos는 쿼리를 모든 샤드로 보내고 결과를 취합해야 합니다. 이는 성능이 저하되는 원인이 됩니다.

따라서 샤드 클러스터의 성능을 최적화하려면 자주 사용되는 쿼리 필드를 샤드 키로 선택하는 것이 매우 중요합니다.

15. 추가 개념: 배열 요소(Array Element)를 기준으로 정렬하기
문제
products 컬렉션이 있고, 각 문서에는 정수 배열인 ratings 필드가 포함되어 있습니다. ratings 배열의 첫 번째 요소를 기준으로 제품을 내림차순으로 정렬하고 싶습니다. 다음 중 이를 올바르게 수행하는 쿼리는 무엇입니까?

출제자 의도
배열의 특정 위치에 있는 요소를 기준으로 정렬하기 위해 점 표기법("field.index")을 사용할 수 있다는 것을 알고 있는지 평가합니다.

나의 오답
db.products.aggregate([
  { $sort: { "ratings": -1 } }
])

오답 분석:
집계 파이프라인의 $sort를 전체 배열인 "ratings"에 사용하면 첫 번째 요소를 특정하여 정렬하지 않습니다. MongoDB는 배열 전체를 정렬할 때, 내림차순(-1)의 경우 배열의 가장 큰 요소를 기준으로 정렬하는 등 다른 규칙을 적용합니다. 따라서 이 쿼리는 문제의 요구사항을 충족하지 못합니다.

정답
db.products.find().sort({ "ratings.0": -1 })

정답 해설:
"ratings.0"은 점 표기법(dot notation)을 사용하여 배열의 첫 번째 요소(0번 인덱스)를 구체적으로 지정합니다. MongoDB는 find().sort() 메서드에서 배열 내부 요소에 대한 점 표기법을 완벽하게 지원하므로, 이 쿼리는 ratings 배열의 첫 번째 값을 기준으로 문서를 정확하게 내림차순으로 정렬합니다.

핵심 개념 정리
점 표기법 (Dot Notation) for Arrays: MongoDB에서 배열의 특정 인덱스에 있는 요소에 접근하려면 "배열필드명.인덱스"와 같은 점 표기법을 사용합니다. 이는 쿼리 조건(find), 정렬(sort), 프로젝션(결과 필드 선택) 등 다양한 곳에서 매우 유용하게 사용됩니다.

Array Sort vs. Array Element Sort: 배열 필드 자체("ratings")를 기준으로 정렬하는 것과 배열 내 특정 요소("ratings.0")를 기준으로 정렬하는 것은 완전히 다른 결과를 낳습니다. 원하는 정렬 결과를 얻기 위해서는 의도에 맞게 점 표기법을 정확히 사용해야 합니다.

16. 추가 개념: 데이터 모델링 - 임베딩(Embedding) 패턴
문제
MongoDB 데이터 모델링과 관련하여, 개발자는 블로깅 플랫폼을 위한 데이터 모델을 설계해야 합니다. 각 블로그 게시물은 여러 태그와 여러 댓글을 가질 수 있으며, 각 댓글은 여러 사용자에 의해 추천될 수 있습니다. 다음 중 MongoDB에서 이 데이터를 모델링하는 가장 효율적인 방법은 무엇입니까?

출제자 의도
1:N 관계에서 데이터를 효율적으로 모델링하는 임베딩 패턴과 참조 패턴의 차이점을 이해하고, 언제 임베딩이 유리한지 판단할 수 있는지 평가합니다.

나의 오답
블로그 게시물 문서 내에 태그를 임베드하고, 댓글과 추천은 별도의 컬렉션에 저장한다.

오답 분석: 댓글과 추천을 별도의 컬렉션에 저장하면 데이터 모델이 덜 효율적일 수 있습니다. 게시물 하나를 읽을 때마다 댓글과 추천 정보를 가져오기 위해 여러 번의 추가 쿼리가 필요하기 때문입니다. 또한, 태그는 일반적으로 블로그 게시물의 일부이므로 직접 임베드하는 것이 모델을 최적화할 수 있습니다.

정답
블로그 게시물 문서 내에 댓글과 태그를 임베드하고, 각 댓글 문서 내에 사용자 추천을 저장한다.

정답 해설: MongoDB는 풍부한 구조의 문서(rich documents)를 지원하므로, 댓글, 태그, 추천을 블로그 게시물 문서에 직접 임베드하는 것이 데이터를 모델링하는 효율적인 방법입니다. 이 방법을 사용하면 단일 쿼리로 블로그 게시물에 대한 모든 데이터를 검색할 수 있으며, 게시물, 댓글, 태그, 추천에 대한 업데이트는 단일 문서에만 영향을 미칩니다.

핵심 개념 정리
임베딩 패턴 (Embedding Pattern): 관련된 데이터를 부모 문서 내에 배열이나 하위 문서(sub-document) 형태로 포함시키는 방법입니다. 데이터가 함께 조회되는 경우가 많고, 자식 데이터의 양이 너무 많지 않은 '1 대 소수(one-to-few)' 관계에 적합합니다.

장점: 단일 읽기 작업으로 모든 관련 데이터를 가져올 수 있어 읽기 성능이 매우 좋습니다. 데이터의 원자성(atomic)을 보장하기 쉽습니다.

단점: 문서 크기가 16MB 제한을 넘을 수 있고, 자식 데이터만 개별적으로 자주 업데이트되면 비효율적일 수 있습니다.

참조 패턴 (Reference Pattern): 관련된 데이터의 _id 값만 부모 문서에 저장하고, 실제 데이터는 별도의 컬렉션에 두는 방법입니다. (관계형 데이터베이스의 정규화와 유사) '1 대 다수(one-to-many)' 관계나 데이터가 독립적으로 자주 조회될 때 적합합니다.

장점: 문서 크기 제한을 피할 수 있고, 데이터 중복을 줄일 수 있습니다.

단점: 관련 데이터를 가져오려면 애플리케이션 레벨에서 추가 쿼리($lookup 또는 여러 find)가 필요하여 읽기 성능이 저하될 수 있습니다.

블로그 게시물과 댓글/태그의 관계는 전형적인 '1 대 소수' 관계이므로, 임베딩 패턴이 더 효율적인 선택입니다.

17. 추가 개념: Capped Collection 관리 및 확장
문제
한 회사의 애플리케이션 로그가 appData 데이터베이스의 appLogs라는 Capped Collection에 저장됩니다. 각 문서에는 로그 메시지를 저장하는 event 필드와 로그 생성 시간을 기록하는 timestamp 필드가 있습니다. Capped Collection의 크기 제한은 10GB입니다. 회사는 더 많은 로그 데이터를 생성할 새로운 기능을 도입하면서, 최소한 가장 최근 하루 동안의 로그 데이터가 항상 컬렉션에 있도록 보장하고 싶어합니다. 다음 중 최소 하루 분량의 로그 데이터를 항상 사용할 수 있도록 보장하는 전략은 무엇입니까?

출제자 의도
Capped Collection의 고정 크기(fixed-size) 특성과 크기 조절이 불가능하다는 점, 그리고 TTL 인덱스와는 호환되지 않는다는 점을 이해하는지 평가합니다.

나의 오답
모든 문서에 24시간 후 삭제되도록 표시하는 'expiry' 필드를 새로 생성한다.

오답 분석: 'expiry' 필드를 추가한다고 해서 Capped Collection의 문서가 24시간 후에 삭제되지는 않습니다. 만료 필드를 기반으로 한 자동 삭제는 TTL(Time-To-Live) 인덱스의 기능인데, TTL 인덱스는 Capped Collection에서 지원되지 않습니다.

정답
새롭고 더 큰 Capped Collection으로 마이그레이션하고 모든 기존 문서를 복사한다.

정답 해설: 가장 좋은 해결책은 더 큰 크기의 새로운 Capped Collection을 만들고 기존 문서를 복사하는 것입니다. 이 새로운 컬렉션은 하루 이상의 로그 데이터를 담을 수 있는 충분한 공간을 가지게 됩니다. 데이터는 크기 제한에 도달했을 때 여전히 FIFO(선입선출) 규칙에 따라 가장 오래된 데이터부터 삭제되므로, 가장 최신 로그 데이터가 유지되는 것이 보장됩니다. Capped Collection은 크기 변경이 불가능하므로, 용량을 늘리는 유일한 방법은 새로 더 큰 컬렉션을 만들어 데이터를 이전하는 것입니다.

핵심 개념 정리
Capped Collection의 고정 크기: Capped Collection은 생성 시 지정된 크기가 고정되며, 나중에 크기를 변경할 수 없습니다.

확장 전략: Capped Collection의 용량을 늘려야 할 경우, 원하는 크기로 새 컬렉션을 생성한 다음 기존 데이터를 새 컬렉션으로 마이그레이션(이전)해야 합니다.

TTL 인덱스와의 비호환성: Capped Collection은 TTL 인덱스를 지원하지 않습니다. 데이터 삭제는 오직 컬렉션의 크기나 문서 수 제한에 도달했을 때 FIFO 방식으로만 이루어집니다.

18. 추가 개념: updateOne과 upsert를 이용한 조건부 업데이트/삽입
문제
inventory라는 MongoDB 컬렉션에 제품이 저장된 소매 재고 시스템을 관리하고 있습니다. 각 제품 문서에는 _id, item, quantity, price 필드가 있습니다. 제품이 존재하면 수량을 늘리고, 존재하지 않으면 특정 수량과 가격으로 새 제품을 삽입해야 합니다. 제품은 item 필드로 식별됩니다. 이 작업을 수행하려면 다음 updateOne 명령 중 어떤 것을 사용해야 할까요?

출제자 의도
upsert: true 옵션과 함께 사용될 때, 문서가 업데이트될 때와 삽입될 때의 동작이 다른 $set과 $setOnInsert 연산자의 미묘한 차이를 이해하는지 평가합니다.

나의 오답
db.inventory.updateOne(
  { item: "notebook" },
  { $inc: { quantity: 10 }, $set: { price: 5.99 } },
  { upsert: true }
)

오답 분석:
이 옵션은 quantity에 대해 $inc를 올바르게 사용하지만, $set은 문서가 이미 존재하는 경우에도 항상 price를 업데이트합니다. 가격을 삽입 시에만 설정하려는 의도였다면, 이 동작은 바람직하지 않을 수 있습니다.

정답
db.inventory.updateOne(
  { item: "notebook" },
  { $inc: { quantity: 10 }, $setOnInsert: { price: 5.99 } },
  { upsert: true }
)

정답 해설:
이 옵션은 notebook이 존재하면 $inc를 사용하여 수량을 늘리고, 새 문서가 삽입될 때만 $setOnInsert를 사용하여 가격을 설정합니다. upsert: true 옵션은 item이 컬렉션에 존재하지 않을 경우 새 문서가 삽입되도록 보장합니다. 이는 시나리오에 기반한 정확하고 의도된 동작입니다.

핵심 개념 정리
upsert: true: updateOne이나 updateMany와 함께 사용되는 옵션입니다. 필터와 일치하는 문서가 있으면 업데이트(UPdate)하고, 없으면 새 문서를 삽입(INSERT)합니다.

$inc: 지정된 만큼 필드 값을 증가(INCrement)시킵니다. 필드가 없으면 새로 만들고 지정된 값을 설정합니다.

$set: 필드의 값을 지정된 값으로 설정(SET)합니다. 문서가 업데이트되든 삽입되든 항상 적용됩니다.

$setOnInsert: 필드의 값을 지정된 값으로 설정하되, 오직 새로운 문서가 삽입될 때만(SET on INSERT) 적용됩니다. 기존 문서가 업데이트될 때는 이 연산이 무시됩니다.

19. 추가 개념: 데이터 모델링 - 참조(Reference) 패턴
문제
도서관 시스템을 위한 MongoDB 스키마를 설계하고 있습니다. 시스템에는 Books, Authors, Reviews 세 개의 컬렉션이 있습니다.

Books 컬렉션: 제목, 장르, 출판 연도 및 Authors 컬렉션을 참조하는 authorIds 배열 등 각 책에 대한 정보를 포함합니다.

Authors 컬렉션: 이름, 생년월일, 국적 등 각 저자에 대한 정보를 포함합니다.

Reviews 컬렉션: Books 컬렉션을 참조하는 bookId, reviewText, rating 등 책에 대한 사용자 리뷰를 포함합니다.

이 시나리오에서 Books, Authors, Reviews 컬렉션 간의 관계는 MongoDB에서 어떻게 모델링되어야 할까요?

출제자 의도
데이터 중복과 거대 문서 문제를 피하기 위해, 다대다(M:N) 및 확장 가능한 일대다(1:N) 관계에서 언제 참조(Reference) 패턴을 사용해야 하는지 이해하고 있는지 평가합니다.

나의 오답
Authors를 Books 컬렉션 내에 문서 배열로 직접 임베드한다.

오답 분석:
Authors를 Books에 직접 임베드하는 것은 저자가 여러 권의 책을 집필하는 시나리오에서 문제가 됩니다. 이는 데이터 중복으로 이어지며, 저자 정보를 업데이트해야 할 때 해당 저자가 쓴 모든 책 문서를 찾아서 수정해야 하는 복잡성을 야기합니다.

정답
Books 컬렉션에서 authorIds를 사용하여 Authors를 참조하고, Reviews 컬렉션에서 bookId를 사용하여 Books를 참조한다.

정답 해설:
Books에서 authorIds를 사용하여 Authors를 참조하는 것은 저자가 여러 권의 책을 쓸 수 있고, 책 한 권에 여러 명의 저자가 있을 수 있기 때문에 적절합니다. 이러한 다대다(many-to-many) 관계는 참조로 모델링하는 것이 가장 좋습니다. 마찬가지로, Reviews에서 bookId를 사용하여 Books를 참조하는 것도 올바른 방법입니다. 왜냐하면 한 권의 책에는 수많은 리뷰가 달릴 수 있으며, 모든 리뷰를 책 문서 내에 임베드하면 리뷰 수가 증가함에 따라 문서가 지나치게 커지고 비효율적이 될 수 있기 때문입니다.

핵심 개념 정리
참조(Reference) 패턴의 사용 시점:

다대다(Many-to-Many) 관계: Books와 Authors처럼 양쪽 엔티티가 서로에게 '다수'의 관계를 가질 때 참조를 사용해야 데이터 중복을 피할 수 있습니다.

'1 대 다수(One-to-Many)' 관계: Books와 Reviews처럼 한쪽이 매우 많거나, 그 수가 계속해서 무한정 늘어날 가능성이 있을 때 참조를 사용합니다. 이는 단일 문서 크기 제한(16MB)을 피하고 성능을 유지하는 데 도움이 됩니다.

데이터의 독립적 접근/수정: 참조되는 데이터(예: 저자 정보)가 참조하는 데이터(예: 책)와 별개로 자주 조회되거나 수정될 때 참조 모델이 더 효율적입니다.

20. 추가 개념: MongoDB 뷰(View) 생성하기
문제
다음과 같은 상황을 고려해보세요: 당신은 MongoDB 개발자이며 현재 대량의 데이터에 대한 복잡한 리포팅이 필요한 애플리케이션을 작업하고 있습니다. 애플리케이션은 MongoDB에 데이터를 저장하며, 데이터 양이 상당히 커졌습니다. 효율성과 관리 용이성을 유지하기 위해 MongoDB 뷰를 사용하기로 결정했습니다. Users 컬렉션에서 username, email, createdAt 필드만 포함하는 "UsersView"라는 뷰를 생성하려고 합니다. 다음 중 어떤 명령어를 사용해야 할까요?

출제자 의도
db.createView() 명령어의 정확한 구문을 알고 있는지, 특히 뷰가 컬렉션이 아닌 데이터베이스 수준에서 생성되며 소스 컬렉션을 인자로 받는다는 점을 이해하는지 평가합니다.

나의 오답
db.Users.createView("UsersView", {$project: {username: 1, email: 1, createdAt: 1}})

오답 분석:
이 구문은 createView가 컬렉션("Users")의 메서드가 아니기 때문에 올바르지 않습니다. 또한, createView 메서드는 두 번째 매개변수로 소스 컬렉션을 필요로 합니다.

정답
db.createView("UsersView", "Users", [{$project: {username: 1, email: 1, createdAt: 1}}])

정답 해설:
이것이 뷰를 생성하는 올바른 MongoDB 구문입니다. createView 메서드는 세 가지 인자를 받습니다: 생성할 뷰의 이름("UsersView"), 소스 컬렉션의 이름("Users"), 그리고 집계 파이프라인 단계의 배열([{$project: {username: 1, email: 1, createdAt: 1}}])입니다.

핵심 개념 정리
MongoDB 뷰(View): 뷰는 집계 파이프라인의 결과물 위에 만들어진 가상의 읽기 전용(read-only) 컬렉션입니다. 실제 데이터를 저장하지 않으며, 뷰를 쿼리할 때마다 정의된 파이프라인이 실행됩니다.

데이터베이스 수준 명령어: 뷰는 특정 컬렉션에 종속되지 않고 데이터베이스 수준에서 db.createView() 명령어로 생성됩니다.

db.createView() 구문:

db.createView(<viewName>, <sourceCollection>, <pipeline>, <options>)

<viewName>: 생성할 뷰의 이름 (문자열)

<sourceCollection>: 뷰의 기반이 되는 컬렉션 또는 다른 뷰의 이름 (문자열)

<pipeline>: 뷰의 데이터를 정의하는 집계 파이프라인 단계의 배열

21. 추가 개념: findAndModify를 이용한 원자적 업데이트 및 반환
문제
orders 컬렉션에 다음과 같은 문서가 있습니다.

{
    "_id": 1,
    "product": "apple",
    "quantity": 50,
    "status": "processing"
}

문서의 status를 "completed"로 설정하고 quantity를 10만큼 증가시킨 다음, 업데이트된 상태의 문서를 반환하려고 합니다. 다음 중 이 작업을 수행할 findAndModify 명령어는 무엇입니까?

출제자 의도
findAndModify 명령어의 기본 구조와 업데이트된 문서를 반환하게 하는 new: true 옵션의 역할을 정확히 이해하고 있는지 평가합니다.

정답
db.orders.findAndModify({
    query: { _id: 1 },
    update: { $set: { status: "completed" }, $inc: { quantity: 10 } },
    new: true
});

정답 해설:
query는 업데이트할 문서를 찾고, update 객체 안의 $set 연산자는 status 값을 "completed"로 업데이트하며, $inc 연산자는 quantity를 10만큼 증가시킵니다. 핵심인 new: true 옵션은 이 명령이 업데이트가 완료된 후의 새로운(new) 문서를 반환하도록 지시합니다.

핵심 개념 정리
findAndModify: 문서를 찾아서 수정하는 원자적(atomic) 작업을 수행하는 명령어입니다. (참고: 최신 MongoDB 버전에서는 findOneAndUpdate 또는 findOneAndReplace 사용이 권장됩니다.)

원자성(Atomicity): 찾고 수정하는 전체 과정이 다른 어떤 작업에도 방해받지 않고 하나의 단위로 완료됨을 보장합니다.

new: true vs new: false (기본값):

new: true: 업데이트가 적용된 **후(post-modification)**의 문서를 반환합니다.

new: false (또는 생략 시): 업데이트가 적용되기 **전(pre-modification)**의 원본 문서를 반환합니다.

22. 추가 개념: upsert 시 $set과 $setOnInsert의 차이점
문제
전자 상거래 애플리케이션에서 제품 정보를 products라는 MongoDB 컬렉션에 저장하고 있습니다. 컬렉션의 각 문서에는 _id, name, price, stock 필드가 있습니다. 제품이 존재하면 가격과 재고를 업데이트하고, 존재하지 않으면 새 문서를 삽입해야 합니다. 제품은 name 필드로 식별됩니다. 주어진 시나리오에서, 필요한 upsert 작업을 올바르게 수행하는 updateOne 명령어는 다음 중 무엇입니까?

출제자 의도
upsert 작업에서 문서가 업데이트될 때와 삽입될 때 모두 필요한 필드와, 오직 삽입될 때만 필요한 필드를 구분하여 올바른 연산자($set, $setOnInsert)를 사용할 수 있는지 평가합니다.

나의 오답
db.products.updateOne(
  { name: "Laptop" },
  { $setOnInsert: { price: 1200, stock: 50 } },
  { upsert: true }
)

오답 분석:
$setOnInsert는 새 문서가 삽입될 때만 필드를 설정하는 데 사용됩니다. 하지만 price와 stock은 기존 문서에서도 업데이트되어야 하므로, $setOnInsert만 사용하면 기존 문서의 price나 stock이 업데이트되지 않는 문제가 발생합니다.

정답
db.products.updateOne(
  { name: "Laptop" },
  { $set: { price: 1200, stock: 50 } },
  { upsert: true }
)

정답 해설:
이 명령어는 name 필드로 제품을 정확하게 식별하고, 문서가 존재하는 경우 $set 연산자를 사용하여 price와 stock 필드를 업데이트합니다. upsert: true 옵션은 name 필드와 일치하는 문서가 없을 경우, 지정된 price와 stock으로 새 문서가 삽입되도록 보장합니다. 다른 옵션들은 문서를 올바르게 업데이트하지 못하거나 새 문서의 삽입을 잘못 처리합니다.

핵심 개념 정리
$set in upsert: 문서가 업데이트될 때와 삽입될 때 모두 필드 값을 설정합니다. 시나리오처럼 두 경우 모두 값을 변경하거나 설정해야 할 때 사용합니다.

$setOnInsert in upsert: 오직 문서가 삽입될 때만 필드 값을 설정합니다. 기존 문서가 업데이트될 때는 아무런 작업도 하지 않습니다. 생성 시간(createdAt)처럼 초기 설정 후에는 변경되지 않아야 하는 필드에 유용합니다.

23. 추가 개념: 최대값 자체 구하기 vs 최대값을 가진 문서 구하기
문제
다음과 같은 employees 컬렉션을 생각해보세요. "Sales" 부서 직원들 중 최대 급여(maximum salary)는 얼마인지 찾는 쿼리는 무엇입니까?

데이터 예시:

{ "_id": 1, "name": "John Doe", "department": "Sales", "salary": 5000 },
{ "_id": 2, "name": "Jane Doe", "department": "Marketing", "salary": 6000 },
{ "_id": 3, "name": "Jim Smith", "department": "Sales", "salary": 4500 }

출제자 의도
특정 값 자체를 계산하는 것(Aggregation)과 해당 값을 가진 문서를 찾는 것(find)의 차이를 이해하고, 문제의 요구사항에 맞는 올바른 방법을 선택할 수 있는지 평가합니다.

나의 오답
db.employees.find({department: "Sales"}).sort({salary: -1}).limit(1)

오답 분석:
이 쿼리는 "Sales" 부서의 모든 문서를 찾아 salary 필드를 기준으로 내림차순 정렬한 다음, 첫 번째 문서 하나만 반환합니다. 이 방법은 "Sales" 부서에서 가장 높은 급여를 받는 **'직원 정보(문서 전체)'**를 반환하는 것이지, 문제에서 요구한 '최대 급여액(값)' 자체를 반환하는 것이 아닙니다.

정답
db.employees.aggregate([
  { $match: { department: "Sales" } },
  { $group: { _id: null, max_salary: { $max: "$salary" } } }
])

24. 추가 개념: 복합 인덱스와 정렬 순서
문제
다음과 같은 쿼리가 있습니다. db.coll.find({}).sort({"product": 1, "price": 1}) 이 쿼리의 성능을 가장 크게 향상시키는 인덱스 두 개는 무엇입니까?

출제자 의도
복합 인덱스를 정렬에 활용할 때, 인덱스 필드의 순서와 방향이 쿼리의 정렬 순서와 어떻게 일치해야 하는지를 이해하고 있는지 평가합니다.

나의 오답
{ key: { price: 1, product: 1 } }

오답 분석: 이 인덱스는 쿼리의 정렬 순서와 일치하지 않습니다. 쿼리는 product를 먼저 정렬하고 그 다음에 price를 정렬하지만, 이 인덱스는 price를 먼저 정렬하고 그 다음에 product를 정렬합니다. 따라서 이 인덱스는 해당 쿼리의 정렬 작업에 최적으로 사용될 수 없습니다.

정답
{ key: { product: 1, price: 1 } }

{ key: { product: -1, price: -1 } }

정답 해설:

{ product: 1, price: 1 }: 이 인덱스는 쿼리의 정렬 필드와 순서, 그리고 방향까지 정확하게 일치하므로 쿼리 성능을 향상시킵니다.

{ product: -1, price: -1 }: 이 인덱스는 쿼리의 정렬 필드와 순서는 같지만, 모든 필드의 방향이 정반대입니다. MongoDB는 인덱스를 역순으로도 효율적으로 탐색할 수 있으므로, 이 인덱스 역시 쿼리 성능을 동일하게 향상시킵니다.

핵심 개념 정리
필드 순서: 복합 인덱스가 정렬 연산을 지원하려면, 인덱스에 나열된 필드의 순서가 쿼리의 정렬 필드 순서와 반드시 일치해야 합니다.

정렬 방향: 인덱스의 정렬 방향(오름차순 1, 내림차순 -1)은 쿼리의 정렬 방향과 모두 동일하거나, 모두 정반대여야 합니다. 필드마다 방향이 섞여 있으면({product: 1, price: -1}) 이 쿼리에는 최적으로 사용될 수 없습니다.

25. 추가 개념: MQL에서 $ 기호의 용도
문제
MQL(MongoDB Query Language)에서 $ 기호의 용도 중 일부는 무엇입니까? (2개 선택)

출제자 의도
MQL에서 $ 기호의 두 가지 주요 역할, 즉 연산자 접두사와 집계 표현식에서의 필드 값 참조를 구분할 수 있는지 평가합니다.

나의 오답
$는 쿼리 내에서 문자열을 연결하는 데 사용된다.

오답 분석: MQL에서 문자열 연결에는 $ 기호 자체가 사용되지 않습니다. 대신 $concat과 같은 특정 연산자가 사용됩니다. $ 기호는 주로 연산자의 접두사나 필드 값을 나타내는 데 사용됩니다.

정답
$는 연산자를 나타냅니다 - 모든 MQL 연산자는 $ 접두사를 가집니다.

$가 필드 이름 앞에 접두사로 붙을 때, 해당 필드에 저장된 값을 나타냅니다.

정답 해설:

연산자 접두사: MQL에서 $ 기호는 연산자를 나타내는 데 사용됩니다. 모든 MQL 연산자는 $eq(같음), $gt(보다 큼), $lt(보다 작음) 등과 같이 $ 기호로 시작합니다.

필드 값 참조: 집계 파이프라인과 같은 표현식에서 필드 이름 앞에 $를 붙이면 (예: "$fieldName"), 이는 해당 필드에 저장된 **값(value)**을 의미합니다. 이를 통해 다른 필드의 값과 비교하거나 계산에 사용할 수 있습니다.

핵심 개념 정리
MQL에서 $ 기호는 두 가지 핵심적인 역할을 합니다:

연산자(Operator) 표시: 모든 연산자(예: $set, $match, $group, $gt)는 $로 시작합니다.

필드 경로/값(Field Path/Value) 참조: 주로 집계 파이프라인에서 필드 이름을 문자열로 감싸고 $를 앞에 붙이면(예: "$salary"), 이는 해당 필드의 값을 가리키는 변수처럼 사용됩니다.


## 31\. 추가 개념: `findAndModify`를 이용한 원자적 재고 차감

### 문제

MongoDB 기반 애플리케이션을 개발하고 있습니다. `products` 컬렉션에는 `sku` 필드에 고유 인덱스가 있습니다. 특정 SKU에 대해 현재 재고(`inventory`)가 0보다 큰 경우에만 `inventory` 필드를 1만큼 감소시켜야 합니다. 이 작업을 `findAndModify` 메서드로 수행하는 가장 좋은 방법은 무엇입니까?

### 출제자 의도

> 원자적 연산에서 조건 확인(재고 \> 0)과 업데이트(재고 차감)를 하나의 쿼리에 결합하는 방법을 이해하고, 값을 감소시키는 올바른 연산자(`$inc`)를 알고 있는지 평가합니다.

### 나의 오답

```javascript
db.products.findAndModify({
    query: { sku: "ABC123", inventory: { $gt: 0 } },
    update: { $dec: { inventory: 1 } }
});
```

**오답 분석:**
MongoDB에는 `$dec`라는 연산자가 없습니다. 필드의 값을 감소시키려면 `$inc` 연산자에 음수 값을 사용해야 합니다.

### 정답

```javascript
db.products.findAndModify({
    query: { sku: "ABC123", inventory: { $gt: 0 } },
    update: { $inc: { inventory: -1 } }
});
```

**정답 해설:**
`findAndModify` 메서드는 `products` 컬렉션에서 `sku` 필드가 "ABC123"이고 `inventory` 필드가 0보다 큰 문서를 찾습니다. 그런 다음 `$inc`(증가) 연산자를 사용하여 `inventory` 필드를 -1만큼 증가시켜 효과적으로 값을 1 감소시킵니다.

### 핵심 개념 정리

  * **원자적 조건부 업데이트 (Atomic Conditional Update):** 이 쿼리의 가장 중요한 부분은 `query` 객체 안에 조건(`inventory: { $gt: 0 }`)을 포함시킨 것입니다. 이렇게 하면 MongoDB는 '재고가 0보다 큰 문서를 찾아서' '재고를 1 감소시키는' 두 가지 작업을 다른 어떤 작업에도 방해받지 않는 단일 원자적 연산으로 처리합니다. 이는 여러 요청이 동시에 재고를 차감하려고 할 때 발생하는 경쟁 조건(race condition)을 방지합니다.
  * **`$inc`를 이용한 감소:** MongoDB에서 필드 값을 감소시키는 표준 방법은 `$inc` 연산자와 함께 음수를 사용하는 것입니다. `$dec`와 같은 별도의 감소 연산자는 존재하지 않습니다.


  ## 32. 추가 개념: 일대다(One-to-Many) 관계 모델링

### 문제
MongoDB에서 사용자와 그들의 주문(orders) 간의 일대다 관계를 모델링하는 가장 좋은 방법은 무엇입니까?

### 출제자 의도
> "다수"에 해당하는 쪽(주문)이 무한히 커질 수 있는 일대다 관계에서, 임베딩 대신 참조를 사용하고 각 엔티티를 별도의 컬렉션으로 분리하는 기본 원칙을 이해하는지 평가합니다.

### 나의 오답
사용자와 주문 모두를 위한 단일 컬렉션을 사용하고, 주문 문서의 참조 필드를 사용하여 사용자 문서에 연결한다.

**오답 분석:**
사용자와 주문을 단일 컬렉션에 혼합하면 한 곳에 다른 유형의 문서가 섞이게 되어 유지 관리나 확장성 측면에서 이상적이지 않습니다. 엔티티를 다른 컬렉션으로 분리하고 참조를 통해 관계를 관리하는 것이 좋습니다.

### 정답
사용자 데이터와 주문 데이터를 별도의 컬렉션에 저장하고, 주문 문서의 참조 필드를 사용하여 사용자 문서에 연결한다.

**정답 해설:**
"다수" 측(주문)이 상당히 커질 수 있는 일대다 관계를 모델링하는 가장 좋은 접근 방식이기 때문에 이것이 올바릅니다. 사용자와 주문을 별도의 컬렉션에 저장하면 각 엔티티가 독립적으로 확장될 수 있습니다. 주문 문서의 참조 필드를 사용하여 사용자 문서에 연결하면 문서를 작고 관리하기 쉽게 유지하면서 관계를 유지할 수 있습니다.

### 핵심 개념 정리
* **엔티티별 컬렉션 분리:** 서로 다른 종류의 데이터(사용자, 주문)는 별도의 컬렉션으로 관리하는 것이 기본 원칙입니다. 이는 스키마를 명확하게 하고, 인덱싱과 쿼리를 단순화하며, 유지보수를 용이하게 합니다.
* **'1 대 다수(One-to-Many)' 관계의 참조:** 사용자의 주문처럼 '다수'에 해당하는 데이터가 무한정 늘어날 수 있는 관계에서는 **참조(Reference)** 패턴을 사용합니다. 모든 주문을 사용자 문서에 임베딩하면 문서 크기 제한(16MB)에 도달하거나 성능이 저하될 수 있습니다. 
* **자식 참조 (Child-Referencing):** '다수' 측인 자식 문서(주문)가 부모 문서(사용자)의 `_id`를 참조 필드(예: `userId`)로 가지는 방식입니다. 이 모델은 주문이 계속 추가되어도 사용자 문서의 크기에 영향을 주지 않아 확장성이 뛰어납니다.


## 33\. 추가 개념: 고유 인덱스(Unique Index)와 중복 값 처리

### 문제

고유 인덱스(unique index)가 있는 필드에 중복된 값을 가진 문서를 MongoDB는 어떻게 처리합니까?

### 출제자 의도

> 데이터 무결성을 보장하는 고유 인덱스의 핵심 기능과 제약 조건 위반 시 MongoDB의 동작 방식을 정확히 알고 있는지 평가합니다.

### 나의 오답

MongoDB는 고유 인덱스가 있는 필드에 중복된 값을 가진 여러 문서를 허용한다.

**오답 분석:**
고유 인덱스의 주된 목적은 인덱싱된 필드에 중복된 값이 들어오는 것을 막는 것입니다. MongoDB는 이 제약 조건을 강제하므로, 고유 인덱스가 있는 필드에 중복된 값을 가진 여러 문서를 허용하지 않습니다.

### 정답

MongoDB는 오류를 반환하고 고유 인덱스가 있는 필드에 해당 문서의 삽입을 막습니다.

**정답 해설:**
MongoDB는 인덱싱된 필드의 고유성을 강제합니다. 만약 중복된 값을 가진 문서의 삽입이 시도되면, MongoDB는 오류를 반환하고 문서를 삽입하지 않음으로써 고유성 제약 조건을 유지합니다.

### 예시로 보는 동작 방식

**1. `users` 컬렉션과 고유 인덱스 생성:**
`email` 필드에는 중복된 값이 들어올 수 없도록 고유 인덱스를 생성합니다.

```javascript
// db.users 컬렉션
{ "username": "Alice", "email": "alice@example.com" }

// email 필드에 고유 인덱스 생성
db.users.createIndex({ "email": 1 }, { unique: true })
```

**2. 중복된 이메일로 문서 삽입 시도:**
이미 존재하는 `alice@example.com` 이메일로 새로운 사용자를 추가하려고 시도합니다.

```javascript
db.users.insertOne({ "username": "Alice_2", "email": "alice@example.com" })
```

**3. 결과:**
MongoDB는 이 삽입 작업을 거부하고 다음과 유사한 \*\*중복 키 오류(duplicate key error)\*\*를 반환합니다. "Alice\_2" 사용자는 컬렉션에 추가되지 않습니다.

```
E11000 duplicate key error collection: test.users index: email_1 dup key: { email: "alice@example.com" }
```

### 핵심 개념 정리

  * **고유 인덱스 (Unique Index):** 인덱싱된 필드의 값이 컬렉션 내 모든 문서에서 고유해야 한다는 제약 조건을 강제합니다.
  * **데이터 무결성:** 고유 인덱스는 `_id` 필드 외에도 이메일 주소, 사용자 아이디 등 중복되어서는 안 될 데이터의 무결성을 보장하는 중요한 수단입니다.
  * **오류 처리:** 고유 제약 조건을 위반하는 쓰기 작업(삽입, 업데이트)이 시도되면, 작업은 실패하고 데이터베이스는 오류를 발생시킵니다.



## 37. 추가 개념: `admin` 데이터베이스의 역할

### 문제
MongoDB에 내장된 `admin` 데이터베이스의 용도는 무엇입니까?

### 출제자 의도
> MongoDB의 시스템 데이터베이스 중 인증, 권한 부여 및 서버 수준의 관리 명령을 담당하는 `admin` 데이터베이스의 역할을 이해하고 있는지 평가합니다.

### 정답 및 해설
`admin` 데이터베이스는 인증(authentication)과 권한 부여(authorization) 프로세스에서 중요한 역할을 합니다. 또한 관리자가 수행하는 특정 작업(예: 서버 설정, 사용자 관리)에도 이 데이터베이스에 대한 접근 권한이 필요합니다.

### 핵심 개념 정리
`admin` 데이터베이스는 특정 애플리케이션 데이터를 저장하는 곳이 아니라, MongoDB 서버 인스턴스 전체를 관리하기 위한 특별한 용도의 데이터베이스입니다. 

* **인증 및 권한 부여의 중심:**
    * 모든 데이터베이스의 사용자 정보와 역할(role)은 `admin` 데이터베이스 내의 `system.users`와 `system.roles` 컬렉션에 중앙 집중식으로 저장됩니다.
    * 사용자가 어떤 데이터베이스에 접속하든, 인증 정보는 `admin` 데이터베이스에서 조회됩니다.

* **관리자 전용 명령 실행:**
    * 데이터베이스 목록 보기(`listDatabases`), 서버 종료(`shutdown`), 복제본 세트 상태 확인 등 서버 전체에 영향을 미치는 많은 관리 명령어는 `admin` 데이터베이스에 연결된 상태에서 실행해야 합니다.

* **"루트(Root)" 접근 지점:**
    * `admin` 데이터베이스에 대한 접근 권한이 있다는 것은 사실상 MongoDB 서버 전체에 대한 관리자 권한을 갖는 것과 같습니다. 따라서 이 데이터베이스의 접근은 매우 신중하게 관리되어야 합니다.


## 52\. 추가 개념: `$group` 집계의 올바른 필드명 지정

### 문제

`movies` 컬렉션의 문서들을 `rated` 필드를 기준으로 그룹화하여, 각 등급(`rated`)별 문서의 분포(개수)를 어떻게 추출할 수 있습니까?

**데이터 예시:**

```json
{ "title": "The Great Train Robbery", "rated": "TV-G", ... },
{ "title": "The Land Beyond the Sunset", "rated": "UNRATED", ... },
{ "title": "A Corner in Wheat", "rated": "G", ... }
```

### 출제자 의도

> `$group` 집계 단계에서 결과를 담을 새로운 필드의 이름을 지정하는 올바른 구문을 알고 있는지, 특히 필드 이름이 `$`로 시작하는 연산자가 될 수 없음을 이해하는지 평가합니다.

### 나의 오답

```javascript
db.movies.aggregate( { $group: { _id: '$rated', $count: { $sum: 1 } } } )
```

**오답 분석:**
이 옵션은 구문 오류가 있습니다. `$group` 단계에서 새로 생성되는 필드의 이름(여기서는 `$count`)은 유효한 문자열이어야 하며, `$`로 시작하는 연산자 형태일 수 없습니다.

### 정답

```javascript
db.movies.aggregate( { $group: { _id: '$rated', count: { $sum: 1 } } } )
```

**정답 해설:**
이 옵션은 MongoDB 집계 프레임워크를 사용하여 문서를 `rated` 필드별로 그룹화한 다음, `$sum` 연산자를 사용하여 각 그룹의 문서 수를 계산합니다. 계산된 결과는 `count`라는 이름의 새로운 필드에 저장되며, 최종적으로 `rated` 필드의 분포(각 등급별 영화의 수)를 보여줍니다.

### 핵심 개념 정리

  * **`$group`의 필드명 지정:** `$group` 단계에서 `{ <필드명>: <누산 연산자> }` 형태로 새로운 필드를 생성할 때, `<필드명>`은 반드시 `$`로 시작하지 않는 유효한 문자열이어야 합니다.
  * **필드명 vs. 연산자:** `count`는 개발자가 지정하는 **필드의 이름**이고, `$sum`은 MongoDB가 제공하는 **연산자**입니다. 이 둘의 역할을 혼동해서는 안 됩니다. `$count`는 집계 파이프라인의 **단계(stage)** 이름으로는 존재하지만, `$group` 내에서 필드명이나 연산자로 사용될 수는 없습니다.

  최종 결과
쿼리가 완료되면 MongoDB는 다음과 같은 결과를 반환합니다. _id 필드에는 그룹화의 기준이 된 rated 값이, count 필드에는 각 그룹에 포함된 문서의 총 개수가 표시됩니다.

```json
[
  { "_id": "TV-G", "count": 1 },
  { "_id": "UNRATED", "count": 1 },
  { "_id": "G", "count": 1 }
]
```


네, 알겠습니다. 고유 인덱스와 비고유 인덱스의 차이점을 명확하게 보여주는 예시를 제공해 드리겠습니다.

-----

## 53\. 추가 개념: 고유 인덱스 vs. 비고유 인덱스 (Unique vs. Non-Unique Index)

### 문제

MongoDB에서 고유 인덱스(unique index)와 비고유 인덱스(non-unique index)의 차이점은 무엇입니까?

### 출제자 의도

> 쿼리 성능 향상이라는 공통된 목적 외에, 데이터의 무결성을 강제하는 고유 인덱스와 중복을 허용하는 비고유 인덱스의 근본적인 차이점을 이해하고 있는지 평가합니다.

### 정답

고유 인덱스는 인덱싱된 필드에 대해 고유성 제약 조건을 강제하는 반면, 비고유 인덱스는 인덱싱된 필드에 여러 문서가 동일한 값을 갖도록 허용합니다.

**해설:**
MongoDB의 고유 인덱스는 인덱싱된 필드의 모든 값이 컬렉션의 문서 전체에서 고유함을 보장합니다. 반면에 비고유 인덱스는 이러한 제약 조건을 강제하지 않으므로 인덱싱된 필드에 중복된 값을 허용합니다.

### **예시로 보는 차이점**

간단한 `employees` 컬렉션을 예로 들어 두 인덱스의 동작을 비교해 보겠습니다.

-----

### 1\. 비고유 인덱스 (Non-Unique Index) - **중복 허용**

**상황:** 직원들의 부서(`department`)를 기준으로 검색하는 경우가 많아, 이 필드에 인덱스를 생성하려고 합니다. 여러 직원이 같은 부서에 있을 수 있으므로 비고유 인덱스가 적합합니다.

**인덱스 생성:**

```javascript
// 'department' 필드에 비고유 인덱스를 생성합니다.
db.employees.createIndex({ department: 1 })
```

**데이터 삽입:**

```javascript
db.employees.insertOne({ name: "Alice", department: "Sales" })
// 성공적으로 삽입됩니다.

db.employees.insertOne({ name: "Bob", department: "Marketing" })
// 성공적으로 삽입됩니다.

db.employees.insertOne({ name: "Charlie", department: "Sales" })
// "Sales"는 이미 존재하지만, 비고유 인덱스이므로 문제없이 성공적으로 삽입됩니다.
```

**결과:**
`department` 필드는 중복된 "Sales" 값을 가질 수 있습니다. 이 인덱스는 `db.employees.find({ department: "Sales" })`와 같은 쿼리의 **성능을 향상**시키는 역할만 합니다.

-----

### 2\. 고유 인덱스 (Unique Index) - **중복 금지**

**상황:** 각 직원은 고유한 사번(`employeeId`)을 가져야 합니다. 이 규칙을 데이터베이스 수준에서 강제하고 싶습니다.

**인덱스 생성:**

```javascript
// 'employeeId' 필드에 고유 인덱스를 생성합니다. { unique: true } 옵션이 핵심입니다.
db.employees.createIndex({ employeeId: 1 }, { unique: true })
```

**데이터 삽입:**

```javascript
db.employees.insertOne({ name: "David", employeeId: 101 })
// 성공적으로 삽입됩니다.

db.employees.insertOne({ name: "Eve", employeeId: 102 })
// 성공적으로 삽입됩니다.

db.employees.insertOne({ name: "Frank", employeeId: 101 })
// 실패! employeeId 101은 이미 존재하므로, MongoDB는 이 삽입을 거부하고 오류를 반환합니다.
```

**결과:**
"Frank"의 문서는 삽입되지 않고, 다음과 유사한 \*\*중복 키 오류(duplicate key error)\*\*가 발생합니다. 이 인덱스는 쿼리 성능 향상뿐만 아니라 **데이터의 무결성을 강제하는 규칙**의 역할을 합니다.

### 비교 요약

| 구분 | 비고유 인덱스 (Non-Unique) | 고유 인덱스 (Unique) |
| :--- | :--- | :--- |
| **주요 목적** | 쿼리 성능 향상 | 데이터 무결성 강제 + 쿼리 성능 향상 |
| **중복 값** | **허용** | **금지** |
| **사용 사례** | 부서, 카테고리, 도시 등 중복 가능한 필드 | 이메일, 사용자 ID, 주민등록번호, 사번 등 고유해야 하는 필드 |


36. 추가 개념: $unwind와 $group을 이용한 배열 집계
문제
orders 컬렉션에 다음과 같은 문서들이 있습니다. 각 제품(product_id)별로 주문된 총 수량(quantity)을 찾는 쿼리는 무엇입니까?

데이터 예시:

JSON

// Document 1
{ "customer_id" : "A123", "items" : [ { "product_id" : "P001", "quantity" : 5 }, { "product_id" : "P002", "quantity" : 2 } ] },
// Document 2
{ "customer_id" : "B456", "items" : [ { "product_id" : "P001", "quantity" : 3 }, { "product_id" : "P003", "quantity" : 1 } ] },
// Document 3
{ "customer_id" : "C789", "items" : [ { "product_id" : "P002", "quantity" : 4 } ] }
출제자 의도
배열 내의 데이터를 집계하기 위해 $unwind를 사용한 후, 특정 키를 기준으로 문서를 그룹화하려면 $group 스테이지에서 _id 필드를 명시해야 한다는 점을 이해하고 있는지 평가합니다.

나의 오답
JavaScript

db.orders.aggregate([
   {
      $unwind: "$items"
   },
   {
      $group: {
         total_orders: { $sum: "$items.quantity" }
      }
   }
])
오답 분석:
이 쿼리는 items 배열을 올바르게 분해($unwind)했지만, $group 단계에서 그룹화의 기준이 되는 _id 필드를 지정하지 않았습니다. _id 필드가 없으면 $group은 모든 문서를 단일 그룹으로 결합하여 모든 문서에 걸친 quantity 필드의 총합을 계산합니다. 이는 각 제품별 주문 수량을 제공하는 대신, 전체 제품의 총 주문 수량을 반환하게 됩니다.

정답
JavaScript

db.orders.aggregate([
   {
      $unwind: "$items"
   },
   {
      $group: {
         _id: "$items.product_id",
         total_orders: { $sum: "$items.quantity" }
      }
   }
])
정답 해설:
이 쿼리는 MongoDB Aggregation Framework를 사용하여 각 제품별 주문 수량을 정확하게 계산합니다.

$unwind: "$items": items 배열을 분해하여 각 배열 요소에 대해 별도의 문서를 생성합니다. 3개의 주문 문서가 5개의 개별 품목 문서로 변환됩니다.

$group: { _id: "$items.product_id", ... }: 분해된 문서를 items.product_id 필드를 기준으로 그룹화합니다. 즉, 동일한 product_id를 가진 문서들이 같은 그룹으로 묶입니다.

total_orders: { $sum: "$items.quantity" }: 각 그룹 내에서 quantity 필드의 합계를 계산하여 total_orders라는 필드에 저장합니다.

단계별 실행 과정
1. $unwind 실행 후:

JSON

{ "customer_id" : "A123", "items" : { "product_id" : "P001", "quantity" : 5 } }
{ "customer_id" : "A123", "items" : { "product_id" : "P002", "quantity" : 2 } }
{ "customer_id" : "B456", "items" : { "product_id" : "P001", "quantity" : 3 } }
{ "customer_id" : "B456", "items" : { "product_id" : "P003", "quantity" : 1 } }
{ "customer_id" : "C789", "items" : { "product_id" : "P002", "quantity" : 4 } }
2. $group 실행 후 (최종 결과):

JSON

{ "_id" : "P001", "total_orders" : 8 }  // 5 + 3
{ "_id" : "P003", "total_orders" : 1 }
{ "_id" : "P002", "total_orders" : 6 }  // 2 + 4
핵심 개념 정리
$unwind: 배열 필드를 "풀어서" 각 배열 요소마다 문서를 복제하는 집계 파이프라인 단계입니다. 배열 내 데이터를 다룰 때 거의 항상 첫 단계로 사용됩니다.

$group의 _id 필드: 그룹화의 기준을 정의하는 핵심 필드입니다. 이 필드를 지정하지 않으면 모든 문서가 하나의 그룹으로 처리됩니다.






## 각 데이터의 관계와 모델링 결정
1. 사용자(Users)와 게시물(Posts) → 참조 방식 사용
관계: 한 명의 사용자는 수많은 게시물을 작성할 수 있습니다 (1:N 관계).

왜 임베딩하지 않는가?: 만약 사용자의 모든 게시물을 사용자 문서 안에 배열로 저장(임베딩)한다면, 게시물을 많이 작성하는 사용자의 경우 문서 크기가 계속해서 커집니다. 이는 MongoDB의 단일 문서 크기 제한(16MB)을 초과할 위험이 있고, 문서를 읽고 쓸 때마다 거대한 데이터를 다뤄야 하므로 성능이 저하됩니다. 이를 'Unbounded Array' 문제라고 하며, 이런 경우엔 참조 방식을 사용해야 합니다.

결과: Users 컬렉션과 Posts 컬렉션을 분리합니다. Posts 문서에는 해당 게시물을 작성한 사용자의 ID(userId)를 저장하여 연결합니다.

사용자 프로필 조회: Users 컬렉션에서 해당 사용자 문서 하나만 읽으면 되므로 매우 빠릅니다.

사용자의 모든 게시물 조회: Posts 컬렉션에서 userId 필드를 인덱싱하여 검색하면 효율적입니다.

2. 게시물(Posts)과 댓글(Comments) → 임베딩 방식 사용
관계: 하나의 게시물에는 여러 개의 댓글이 달릴 수 있습니다 (1:N 관계).

왜 임베딩하는가?: 사용자는 언제나 게시물을 볼 때 그 게시물에 달린 댓글을 함께 봅니다. 댓글만 따로 보는 경우는 거의 없습니다. 이렇게 '같이' 조회되는 데이터는 한 문서에 묶어두는 것이 가장 효율적입니다.

결과: Posts 문서 내에 comments라는 배열을 만들고, 각 댓글을 객체 형태로 저장합니다.

게시물과 댓글 조회: 게시물 문서 하나만 DB에서 읽어오면 모든 댓글 정보까지 한 번에 가져올 수 있습니다. 별도의 쿼리나 '조인($lookup)'이 필요 없어 읽기 속도가 매우 빠릅니다.

3. 게시물(Posts)과 좋아요(Likes) → 임베딩 방식 사용
관계: 하나의 게시물에는 여러 명이 '좋아요'를 누를 수 있습니다 (1:N 관계).

왜 임베딩하는가?: '좋아요' 수 계산은 매우 빈번하게 일어나는 작업입니다. 이 정보를 별도 컬렉션으로 분리하면 '좋아요' 수를 셀 때마다 해당 컬렉션 전체를 검색해야 해서 비효율적입니다.

결과: Posts 문서 내에 likes 필드를 만듭니다. 두 가지 방법이 일반적입니다.

카운터 방식: likeCount 필드를 두고, '좋아요'가 눌릴 때마다 숫자를 1씩 증가($inc)시킵니다. 수를 세는 것이 목적이라면 가장 빠릅니다.

배열 방식: likedByUsers 같은 배열을 두고, '좋아요'를 누른 사용자의 ID를 저장합니다. '좋아요' 수는 배열의 크기($size)로 쉽게 알 수 있고, 누가 '좋아요'를 눌렀는지도 알 수 있습니다.

'좋아요' 수 계산: 어떤 방식을 쓰든 게시물 문서 하나만 읽으면 되므로 즉시 계산이 가능합니다.

---
Covered Query란 ?

데이터베이스가 쿼리 결과를 인덱스만으로 모두 처리할 수 있는 경우를 말합니다. 즉, 실제 데이터가 저장된 도큐먼트(document)를 읽을 필요 없이, 인덱스에 있는 정보만으로 사용자에게 필요한 모든 데이터를 반환할 수 있는 매우 효율적인 쿼리입니다. 🚀


예시 💻
users 컬렉션에 다음과 같은 데이터가 있다고 가정해 봅시다.

{ "_id": 1, "name": "Alice", "age": 30, "city": "Seoul" }
{ "_id": 2, "name": "Bob", "age": 25, "city": "Busan" }
그리고 name과 age 필드로 구성된 복합 인덱스를 생성합니다.

db.users.createIndex({ "name": 1, "age": 1 })
1. 커버드 쿼리 예시
아래 쿼리는 name으로 문서를 찾고, 결과로 name과 age 필드만 요청합니다. name과 age는 모두 인덱스에 포함되어 있으므로 커버드 쿼리가 됩니다.

// 쿼리 필드(name), 프로젝션 필드(name, age) 모두 인덱스에 존재
db.users.find(
  { "name": "Alice" },
  { "name": 1, "age": 1, "_id": 0 }
)
이 쿼리는 도큐먼트를 전혀 보지 않고 인덱스만으로 결과를 반환할 수 있습니다.

2. 커버드 쿼리가 아닌 예시
아래 쿼리는 결과로 city 필드를 추가로 요청합니다. 하지만 city 필드는 인덱스에 없기 때문에, MongoDB는 name과 age를 인덱스에서 찾은 후 city 값을 얻기 위해 결국 도큐먼트를 열어봐야 합니다.

// 프로젝션 필드 'city'가 인덱스에 없음
db.users.find(
  { "name": "Alice" },
  { "name": 1, "age": 1, "city": 1, "_id": 0 }
)
