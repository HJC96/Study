## MongoDB 핵심 개념 정리 및 필수 암기 사항

### I. 데이터 모델링 (Data Modeling) 및 관계 설정

MongoDB 데이터 모델링은 애플리케이션의 데이터 접근 패턴을 기반으로 성능과 확장성을 결정하는 데 가장 중요합니다.

#### 1. 임베딩 (Embedding) vs. 참조 (Referencing)

| 구분 | 임베딩 (Embedding/Denormalization) | 참조 (Referencing/Normalization) |
| :--- | :--- | :--- |
| **개념** | 관련된 데이터를 하나의 문서 내부에 하위 문서나 배열로 포함. | 다른 컬렉션의 문서에 대한 `_id` 참조를 저장하여 관계를 설정. |
| **적합한 경우** | 데이터가 **함께** 조회되고, 자식 데이터의 양이 적거나, **1 대 소수(One-to-Few)** 관계일 때. | 데이터가 자주 업데이트되거나, 데이터가 매우 크거나, **1 대 다수(One-to-Many)** 또는 **다대다(M:N)** 관계일 때. |
| **장점** | 단일 쿼리로 모든 정보를 가져와 **읽기 성능이 매우 좋음**. | 문서 크기 제한(16MB)을 피하고, 데이터 중복 및 불일치 문제를 방지함. |
| **단점** | 문서 크기 제한에 걸릴 위험이 있음. 데이터 중복 발생 시 업데이트가 복잡함. | 관련 데이터를 가져오기 위해 **추가적인 쿼리($lookup 등)**가 필요하여 읽기 성능이 저하될 수 있음. |

**📌 외워야 할 사항:**

*   **모델링 황금률:** "함께 읽히는 데이터는 함께 저장하라 (Data that is read together should be stored together)".
*   **안티패턴:** 문서 내 배열이 무한히 커질 수 있는 **무한 배열(Unbounded Array)** 패턴은 피해야 하며, 이 경우 참조(Referencing)를 사용해야 함.
*   **일대일 관계:** 필드를 하위 문서로 임베딩하거나, 다른 컬렉션의 단일 문서에 링크하는 방식으로 모델링 가능.

#### 2. 주요 데이터 모델링 패턴

| 패턴명 | 핵심 아이디어 | 용도 및 특징 |
| :--- | :--- | :--- |
| **Bucket Pattern (버킷 패턴)** | 대량의 시계열 데이터를 묶어 **하나의 '버킷' 문서** 내부에 배열로 저장함. | IoT 센서 데이터, 실시간 로그처럼 문서 수가 폭증하는 경우에 사용. 쓰기/읽기 성능 향상. |
| **Attribute Pattern (애트리뷰트 패턴)** | 유사한 속성들을 **키-값 쌍의 배열**로 그룹화하여 필드 이름에 있던 데이터를 필드 값으로 옮김. | 필드가 너무 많거나, 유연한 쿼리/인덱싱이 필요할 때 유용. |
| **Extended Reference Pattern (확장 참조 패턴)** | 참조 관계에서 조인($lookup) 비용을 줄이기 위해, 자주 쓰는 필드를 원본 문서에 **중복 저장**하여 읽기 성능을 높임. | 데이터 변경 시 중복된 필드를 모두 업데이트해야 하는 단점이 있음. |
| **Outlier Pattern (아웃라이어 패턴)** | 표준 스키마를 따르지 않는 **소수의 예외적인 문서**에 대해 대체 저장 방식을 적용. | 대부분의 사용자는 연락처 배열에 저장 가능하지만, 한 명이 연락처가 너무 많아 배열 용량을 초과할 때. |

### II. 쿼리 (Query) 및 인덱싱 (Indexing) 최적화

#### 1. 쿼리 연산자 및 배열 조회

*   **배열 내 여러 조건 동시 만족 ($elemMatch):** 배열 내의 **단일 객체(요소)**가 여러 조건을 *모두* 동시에 만족해야 하는 경우에만 `$elemMatch`를 사용해야 합니다.
    *   **주의:** 단순 점 표기법을 나열하면 각 조건이 배열의 서로 다른 요소에서 충족되어도 문서를 찾을 수 있으므로 정확하지 않습니다.
*   **배열 내 단일 값 찾기:** 배열 필드에서 특정 단일 요소를 포함하는 문서를 찾을 때는 `db.movies.find({ array_field: "value" })` 형태의 간단한 쿼리가 가장 효율적입니다.
*   **논리 연산자 ($and, $or, $in):**
    *   **암묵적 AND:** 여러 필드에 대한 AND 조건은 쉼표(`,`)로 구분하여 나열하는 것이 가장 일반적이고 권장되는 방식입니다 (예: `{ year: 2000, genres: "Comedy" }`).
    *   **$in:** 동일한 필드의 값이 여러 값 중 하나와 일치하는지 확인할 때 사용합니다 (예: `{ year: { $in:  } }`).
*   **정규식 (Regex):** 정규식에서 문자열의 시작은 `^`로, 끝은 `$`로 표현하는 **앵커(anchor)**가 중요합니다 (예: `/.*ian$/`는 'ian'으로 끝나는 문자열을 찾음).
    *   **인덱스 활용:** `^prefix`와 같이 접두사를 고정하는 정규식은 인덱스를 효율적으로 사용할 수 있지만, 중간 문자열 검색은 인덱스를 사용하기 어렵습니다.

**📌 외워야 할 사항:**

*   **배열 요소 업데이트:** 배열 내 쿼리 조건과 일치하는 요소를 업데이트하려면 `$set` 연산자와 함께 **위치 연산자(`$`)**를 사용해야 합니다 (예: `{ $set: { "projects.$.role": "Senior Lead Developer" } }`).
*   **누락 값 정렬:** 정렬 시 필드가 누락된 문서(missing values)는 `null` 값으로 취급되어 결과 셋의 **가장 앞쪽**에 위치하게 됩니다.

#### 2. 인덱스 유형 및 복합 인덱스 규칙

*   **희소 인덱스 (Sparse Index):** 인덱싱된 필드가 존재하는 문서만 인덱싱하며, 필드가 없는 문서는 인덱스에서 제외됩니다. 인덱스 크기를 줄여 저장 공간을 절약할 수 있습니다.
*   **고유 인덱스 (Unique Index):** 필드 값의 고유성(uniqueness)을 컬렉션 수준에서 강제하며, 중복 값이 들어오면 오류를 반환하고 삽입을 막습니다. (이는 문서 구조를 검사하는 **스키마 유효성 검사**와는 다릅니다).
*   **COLLSCAN vs IXSCAN:** 쿼리 실행 계획에서 **COLLSCAN** (컬렉션 전체 스캔)이 보이면 인덱스가 사용되지 않았다는 뜻이며, 쿼리 성능 최적화를 위해 **IXSCAN** (인덱스 스캔)으로 전환해야 합니다.

**📌 외워야 할 사항 (복합 인덱스):**

*   **필드 순서 (정렬):** 복합 인덱스가 정렬(`sort`)에 사용되려면, 인덱스 필드의 순서가 쿼리의 정렬 필드 순서와 **일치**하거나, **모두 정반대**여야 합니다.
*   **필드 순서 (쿼리):** `find` 쿼리 조건은 인덱스에 정의된 **접두사(prefix)** 필드를 순서대로 포함해야 인덱스를 효율적으로 사용합니다. 하지만 쿼리 객체 `{...}` 내에서 개발자가 필드를 작성하는 순서는 MongoDB 최적화기가 알아서 재배치하므로 중요하지 않습니다.

### III. 집계 (Aggregation) 프레임워크

MongoDB 집계는 데이터 처리 파이프라인(Pipeline) 형태로 동작하며, 각 **스테이지(Stage)**에서 데이터를 변환하고 다음 스테이지로 전달합니다.

*   **$group의 `_id` 필드:**
    *   `_id: null`을 사용하면 컬렉션의 모든 문서를 **단 하나의 그룹**으로 묶어 전체 합계, 전체 평균 등을 계산합니다.
    *   `_id: "$field_name"`은 필드 값을 기준으로 그룹화하여 그룹별 집계를 수행합니다.
*   **$match의 위치:** 파이프라인의 **가장 앞쪽**에 `$match` 스테이지를 배치하여 필터링을 먼저 수행해야, 불필요한 데이터 처리(그룹화, 정렬 등)를 줄여 효율성을 높일 수 있습니다.
*   **$out 스테이지:** 집계 결과를 지정된 컬렉션에 출력하며, 기존 대상 컬렉션의 내용을 **완전히 덮어씁니다(replace)**. 기존 데이터는 삭제됩니다. (데이터를 병합하려면 `$merge` 스테이지를 사용해야 합니다).
*   **$lookup 스테이지:**
    *   다른 컬렉션과 **LEFT OUTER JOIN**을 수행합니다.
    *   $lookup 결과 필드(`as`로 지정된 필드)는 일치하는 문서 수에 관계없이 **항상 배열** 형태로 반환됩니다.
*   **$sample:** 컬렉션에서 무작위로 문서를 선택할 때 사용되는 스테이지입니다 (예: `{ $sample: { size: 10 } }`).

### IV. 쓰기 작업 및 원자성 (Write Operations & Atomicity)

*   **단일 문서 교체:** `updateOne` 사용 시 `$set` 같은 업데이트 연산자 없이 새 문서를 지정하면, `_id`를 제외한 기존 문서의 모든 필드가 **새 문서의 내용으로 완전히 교체**됩니다. 새 문서에 포함되지 않은 필드는 삭제됩니다.
*   **`insertMany` 동작 (ordered: true):**
    *   기본적으로 순차적으로 삽입을 시도합니다.
    *   중간에 중복 키 오류(Duplicate Key Error) 같은 오류가 발생하면 **즉시 작업을 중단**합니다.
    *   **중요:** 오류 발생 전까지 성공적으로 삽입된 문서들은 롤백(취소)되지 않고 그대로 유지됩니다.
*   **`upsert` 옵션 사용 시 $set vs $setOnInsert:**
    *   `$set`: 문서가 존재하여 업데이트되든, 존재하지 않아 삽입되든 **항상** 필드 값을 설정합니다.
    *   `$setOnInsert`: 오직 **새로운 문서가 삽입될 때만** 필드 값을 설정합니다.
*   **원자적 업데이트 및 조회 (`findAndModify`):**
    *   쿼리 조건과 업데이트 작업을 하나의 원자적 작업으로 수행하며, 다른 작업에 방해받지 않고 데이터 일관성을 유지합니다.
    *   `{ new: true }` 옵션은 업데이트가 완료된 **후의 새로운 문서**를 반환하도록 지시합니다.

### V. 관리, 샤딩, 연결 (Administration, Sharding, Connection)

*   **샤딩 (Sharding):** 쓰기 부하가 많은(write-heavy) 대규모 워크로드에서 **수평 확장(Scaling Out)**을 위해 데이터를 여러 서버에 분산시키는 최적의 솔루션입니다.
*   **Change Streams (변경 스트림):** oplog를 직접 다룰 필요 없이, 컬렉션, 데이터베이스 또는 전체 클러스터의 데이터 변경 사항을 **실시간**으로 구독할 수 있게 해주는 기능입니다. 실시간 대시보드 구현에 가장 적합합니다.
*   **읽기 선호도 (Read Preference):**
    *   **secondary:** 시간 집약적인 읽기 작업(예: 집계)을 보조 노드로 오프로드하여 Primary의 부하를 줄일 때 사용합니다 (데이터 신선도 지연 감수).
    *   **primary:** 가장 최신 데이터(fresh data)를 읽어야 할 때 사용합니다.
    *   **nearest:** 네트워크 지연 시간이 가장 낮은 노드를 선택하여 응답 시간을 개선하며, 고가용성 환경에서 읽기 부하 분산에 유리합니다.
*   **관리 명령어:**
    *   컬렉션 삭제: `db.collection.drop()`.
    *   BSON 백업/복원: `mongodump` (BSON 파일 생성), `mongorestore` (BSON 복원).
*   **연결 URI 구성:**
    *   **Connection Pool:** `maxPoolSize` 파라미터를 사용하여 연결 풀의 최대 크기를 제한합니다.
    *   **Replica Set 연결:** 고가용성을 위해 연결 문자열에 `replicaSet=<이름>` 옵션을 **반드시** 명시해야 드라이버가 자동 장애 조치(failover) 기능을 활성화할 수 있습니다.
    *   **인증:** 사용자 계정이 `admin` 데이터베이스에 저장된 경우, 연결 시 `authSource=admin` 옵션을 사용하여 인증 정보가 저장된 위치를 드라이버에게 알려주어야 합니다.
